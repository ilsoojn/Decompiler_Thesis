; ModuleID = 'dct module #0'
source_filename = "dct module #0"

%regset = type { i16, i32, i16, i32, i16, i16, i16, i16, i64, i64, i64, i64, i64, i64, i64, i64, i64, i16, <2 x i64>, <2 x i64>, <2 x i64>, <2 x i64>, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i32, i32, i32, i32, i32, i32, i32, i32, x86_fp80, x86_fp80, x86_fp80, x86_fp80, x86_fp80, x86_fp80, x86_fp80, <64 x i1>, <64 x i1>, <64 x i1>, <64 x i1>, <64 x i1>, <64 x i1>, <64 x i1>, <64 x i1>, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, i64, x86_fp80, x86_fp80, x86_fp80, x86_fp80, x86_fp80, x86_fp80, x86_fp80, x86_fp80, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float>, <16 x float> }

define void @fn_400550(%regset* noalias nocapture) {
entry_fn_400550:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  %RBP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 9
  %RBP_init = load i64, i64* %RBP_ptr
  %RBP = alloca i64
  store i64 %RBP_init, i64* %RBP
  %RSP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 16
  %RSP_init = load i64, i64* %RSP_ptr
  %RSP = alloca i64
  store i64 %RSP_init, i64* %RSP
  %ESP_init = trunc i64 %RSP_init to i32
  %ESP = alloca i32
  store i32 %ESP_init, i32* %ESP
  %SP_init = trunc i64 %RSP_init to i16
  %SP = alloca i16
  store i16 %SP_init, i16* %SP
  %SPL_init = trunc i64 %RSP_init to i8
  %SPL = alloca i8
  store i8 %SPL_init, i8* %SPL
  %EBP_init = trunc i64 %RBP_init to i32
  %EBP = alloca i32
  store i32 %EBP_init, i32* %EBP
  %BP_init = trunc i64 %RBP_init to i16
  %BP = alloca i16
  store i16 %BP_init, i16* %BP
  %BPL_init = trunc i64 %RBP_init to i8
  %BPL = alloca i8
  store i8 %BPL_init, i8* %BPL
  %EFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 3
  %EFLAGS_init = load i32, i32* %EFLAGS_ptr
  %EFLAGS = alloca i32
  store i32 %EFLAGS_init, i32* %EFLAGS
  %ZMM0_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 85
  %ZMM0_init = load <16 x float>, <16 x float>* %ZMM0_ptr
  %ZMM0 = alloca <16 x float>
  store <16 x float> %ZMM0_init, <16 x float>* %ZMM0
  %1 = bitcast <16 x float> %ZMM0_init to i512
  %2 = trunc i512 %1 to i128
  %XMM0_init = bitcast i128 %2 to <4 x float>
  %XMM0 = alloca <4 x float>
  store <4 x float> %XMM0_init, <4 x float>* %XMM0
  %3 = bitcast <16 x float> %ZMM0_init to i512
  %4 = trunc i512 %3 to i256
  %YMM0_init = bitcast i256 %4 to <8 x float>
  %YMM0 = alloca <8 x float>
  store <8 x float> %YMM0_init, <8 x float>* %YMM0
  %RAX_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 8
  %RAX_init = load i64, i64* %RAX_ptr
  %RAX = alloca i64
  store i64 %RAX_init, i64* %RAX
  %EAX_init = trunc i64 %RAX_init to i32
  %EAX = alloca i32
  store i32 %EAX_init, i32* %EAX
  %AX_init = trunc i64 %RAX_init to i16
  %AX = alloca i16
  store i16 %AX_init, i16* %AX
  %AL_init = trunc i64 %RAX_init to i8
  %AL = alloca i8
  store i8 %AL_init, i8* %AL
  %5 = lshr i64 %RAX_init, 8
  %AH_init = trunc i64 %5 to i8
  %AH = alloca i8
  store i8 %AH_init, i8* %AH
  %ZMM1_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 86
  %ZMM1_init = load <16 x float>, <16 x float>* %ZMM1_ptr
  %ZMM1 = alloca <16 x float>
  store <16 x float> %ZMM1_init, <16 x float>* %ZMM1
  %6 = bitcast <16 x float> %ZMM1_init to i512
  %7 = trunc i512 %6 to i128
  %XMM1_init = bitcast i128 %7 to <4 x float>
  %XMM1 = alloca <4 x float>
  store <4 x float> %XMM1_init, <4 x float>* %XMM1
  %8 = bitcast <16 x float> %ZMM1_init to i512
  %9 = trunc i512 %8 to i256
  %YMM1_init = bitcast i256 %9 to <8 x float>
  %YMM1 = alloca <8 x float>
  store <8 x float> %YMM1_init, <8 x float>* %YMM1
  %ZMM2_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 87
  %ZMM2_init = load <16 x float>, <16 x float>* %ZMM2_ptr
  %ZMM2 = alloca <16 x float>
  store <16 x float> %ZMM2_init, <16 x float>* %ZMM2
  %10 = bitcast <16 x float> %ZMM2_init to i512
  %11 = trunc i512 %10 to i128
  %XMM2_init = bitcast i128 %11 to <4 x float>
  %XMM2 = alloca <4 x float>
  store <4 x float> %XMM2_init, <4 x float>* %XMM2
  %12 = bitcast <16 x float> %ZMM2_init to i512
  %13 = trunc i512 %12 to i256
  %YMM2_init = bitcast i256 %13 to <8 x float>
  %YMM2 = alloca <8 x float>
  store <8 x float> %YMM2_init, <8 x float>* %YMM2
  %CtlSysEFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 1
  %CtlSysEFLAGS_init = load i32, i32* %CtlSysEFLAGS_ptr
  %CtlSysEFLAGS = alloca i32
  store i32 %CtlSysEFLAGS_init, i32* %CtlSysEFLAGS
  %RDI_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 12
  %RDI_init = load i64, i64* %RDI_ptr
  %RDI = alloca i64
  store i64 %RDI_init, i64* %RDI
  %EDI_init = trunc i64 %RDI_init to i32
  %EDI = alloca i32
  store i32 %EDI_init, i32* %EDI
  %DI_init = trunc i64 %RDI_init to i16
  %DI = alloca i16
  store i16 %DI_init, i16* %DI
  %DIL_init = trunc i64 %RDI_init to i8
  %DIL = alloca i8
  store i8 %DIL_init, i8* %DIL
  br label %bb_400550

exit_fn_400550:                                   ; preds = %bb_4006BC
  %14 = load i32, i32* %CtlSysEFLAGS
  store i32 %14, i32* %CtlSysEFLAGS_ptr
  %15 = load i32, i32* %EFLAGS
  store i32 %15, i32* %EFLAGS_ptr
  %16 = load i64, i64* %RAX
  store i64 %16, i64* %RAX_ptr
  %17 = load i64, i64* %RBP
  store i64 %17, i64* %RBP_ptr
  %18 = load i64, i64* %RDI
  store i64 %18, i64* %RDI_ptr
  %19 = load i64, i64* %RIP
  store i64 %19, i64* %RIP_ptr
  %20 = load i64, i64* %RSP
  store i64 %20, i64* %RSP_ptr
  %21 = load <16 x float>, <16 x float>* %ZMM0
  store <16 x float> %21, <16 x float>* %ZMM0_ptr
  %22 = load <16 x float>, <16 x float>* %ZMM1
  store <16 x float> %22, <16 x float>* %ZMM1_ptr
  %23 = load <16 x float>, <16 x float>* %ZMM2
  store <16 x float> %23, <16 x float>* %ZMM2_ptr
  ret void

bb_400550:                                        ; preds = %entry_fn_400550
  %RIP_1 = add i64 4195664, 1
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %RBP_0 = load i64, i64* %RBP
  %RSP_0 = load i64, i64* %RSP
  %24 = sub i64 %RSP_0, 8
  %25 = inttoptr i64 %24 to i64*
  store i64 %RBP_0, i64* %25, align 1
  %RSP_1 = sub i64 %RSP_0, 8
  %ESP_0 = trunc i64 %RSP_1 to i32
  %SP_0 = trunc i64 %RSP_1 to i16
  %SPL_0 = trunc i64 %RSP_1 to i8
  %RIP_2 = add i64 %RIP_1, 3
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  %EBP_0 = trunc i64 %RSP_1 to i32
  %BP_0 = trunc i64 %RSP_1 to i16
  %BPL_0 = trunc i64 %RSP_1 to i8
  %RIP_3 = add i64 %RIP_2, 4
  %EIP_2 = trunc i64 %RIP_3 to i32
  %IP_2 = trunc i64 %RIP_3 to i16
  %RSP_2 = sub i64 %RSP_1, 80
  %ESP_1 = trunc i64 %RSP_2 to i32
  %SP_1 = trunc i64 %RSP_2 to i16
  %SPL_1 = trunc i64 %RSP_2 to i8
  %EFLAGS_0 = load i32, i32* %EFLAGS
  %RIP_4 = add i64 %RIP_3, 3
  %EIP_3 = trunc i64 %RIP_4 to i32
  %IP_3 = trunc i64 %RIP_4 to i16
  %ZMM0_0 = load <16 x float>, <16 x float>* %ZMM0
  %26 = bitcast <16 x float> %ZMM0_0 to i512
  %XMM0_0 = trunc i512 %26 to i128
  %27 = bitcast i128 %XMM0_0 to <4 x float>
  %28 = bitcast <4 x float> %27 to <2 x i64>
  %29 = bitcast i128 %XMM0_0 to <4 x float>
  %30 = bitcast <4 x float> %29 to <2 x i64>
  %31 = xor <2 x i64> %28, %30
  %XMM0_1 = bitcast <2 x i64> %31 to i128
  %32 = bitcast <16 x float> %ZMM0_0 to i512
  %YMM0_0 = trunc i512 %32 to i256
  %33 = zext i128 %XMM0_1 to i256
  %34 = and i256 %YMM0_0, -340282366920938463463374607431768211456
  %YMM0_1 = or i256 %33, %34
  %35 = bitcast <16 x float> %ZMM0_0 to i512
  %36 = zext i128 %XMM0_1 to i512
  %37 = and i512 %35, -340282366920938463463374607431768211456
  %ZMM0_1 = or i512 %36, %37
  %RIP_5 = add i64 %RIP_4, 10
  %EIP_4 = trunc i64 %RIP_5 to i32
  %IP_4 = trunc i64 %RIP_5 to i16
  %RIP_6 = add i64 %RIP_5, 5
  %EIP_5 = trunc i64 %RIP_6 to i32
  %IP_5 = trunc i64 %RIP_6 to i16
  %38 = sitofp i64 4003244811 to double
  %39 = bitcast double %38 to i64
  %ZMM1_0 = load <16 x float>, <16 x float>* %ZMM1
  %40 = bitcast <16 x float> %ZMM1_0 to i512
  %XMM1_0 = trunc i512 %40 to i128
  %41 = zext i64 %39 to i128
  %42 = and i128 %XMM1_0, -18446744073709551616
  %XMM1_1 = or i128 %41, %42
  %43 = bitcast <16 x float> %ZMM1_0 to i512
  %YMM1_0 = trunc i512 %43 to i256
  %44 = zext i128 %XMM1_1 to i256
  %45 = and i256 %YMM1_0, -340282366920938463463374607431768211456
  %YMM1_1 = or i256 %44, %45
  %46 = bitcast <16 x float> %ZMM1_0 to i512
  %47 = zext i128 %XMM1_1 to i512
  %48 = and i512 %46, -340282366920938463463374607431768211456
  %ZMM1_1 = or i512 %47, %48
  %RIP_7 = add i64 %RIP_6, 10
  %EIP_6 = trunc i64 %RIP_7 to i32
  %IP_6 = trunc i64 %RIP_7 to i16
  %RIP_8 = add i64 %RIP_7, 5
  %EIP_7 = trunc i64 %RIP_8 to i32
  %IP_7 = trunc i64 %RIP_8 to i16
  %49 = sitofp i64 1336630430 to double
  %50 = bitcast double %49 to i64
  %ZMM2_0 = load <16 x float>, <16 x float>* %ZMM2
  %51 = bitcast <16 x float> %ZMM2_0 to i512
  %XMM2_0 = trunc i512 %51 to i128
  %52 = zext i64 %50 to i128
  %53 = and i128 %XMM2_0, -18446744073709551616
  %XMM2_1 = or i128 %52, %53
  %54 = bitcast <16 x float> %ZMM2_0 to i512
  %YMM2_0 = trunc i512 %54 to i256
  %55 = zext i128 %XMM2_1 to i256
  %56 = and i256 %YMM2_0, -340282366920938463463374607431768211456
  %YMM2_1 = or i256 %55, %56
  %57 = bitcast <16 x float> %ZMM2_0 to i512
  %58 = zext i128 %XMM2_1 to i512
  %59 = and i512 %57, -340282366920938463463374607431768211456
  %ZMM2_1 = or i512 %58, %59
  %RIP_9 = add i64 %RIP_8, 7
  %EIP_8 = trunc i64 %RIP_9 to i32
  %IP_8 = trunc i64 %RIP_9 to i16
  %60 = add i64 %RSP_1, -4
  %61 = inttoptr i64 %60 to i32*
  store i32 0, i32* %61, align 1
  %RIP_10 = add i64 %RIP_9, 5
  %EIP_9 = trunc i64 %RIP_10 to i32
  %IP_9 = trunc i64 %RIP_10 to i16
  %62 = trunc i128 %XMM2_1 to i64
  %63 = bitcast i64 %62 to double
  %64 = add i64 %RSP_1, -24
  %65 = inttoptr i64 %64 to double*
  store double %63, double* %65, align 1
  %RIP_11 = add i64 %RIP_10, 5
  %EIP_10 = trunc i64 %RIP_11 to i32
  %IP_10 = trunc i64 %RIP_11 to i16
  %66 = trunc i128 %XMM1_1 to i64
  %67 = bitcast i64 %66 to double
  %68 = add i64 %RSP_1, -16
  %69 = inttoptr i64 %68 to double*
  store double %67, double* %69, align 1
  %RIP_12 = add i64 %RIP_11, 5
  %EIP_11 = trunc i64 %RIP_12 to i32
  %IP_11 = trunc i64 %RIP_12 to i16
  %70 = add i64 %RSP_1, -16
  %71 = inttoptr i64 %70 to double*
  %72 = load double, double* %71, align 1
  %73 = bitcast double %72 to i64
  %74 = zext i64 %73 to i128
  %75 = and i128 %XMM1_1, -18446744073709551616
  %XMM1_2 = or i128 %74, %75
  %76 = zext i128 %XMM1_2 to i256
  %77 = and i256 %YMM1_1, -340282366920938463463374607431768211456
  %YMM1_2 = or i256 %76, %77
  %78 = zext i128 %XMM1_2 to i512
  %79 = and i512 %ZMM1_1, -340282366920938463463374607431768211456
  %ZMM1_2 = or i512 %78, %79
  %RIP_13 = add i64 %RIP_12, 5
  %EIP_12 = trunc i64 %RIP_13 to i32
  %IP_12 = trunc i64 %RIP_13 to i16
  %80 = trunc i128 %XMM1_2 to i64
  %81 = bitcast i64 %80 to double
  %82 = add i64 %RSP_1, -24
  %83 = inttoptr i64 %82 to double*
  %84 = load double, double* %83, align 1
  %85 = fadd double %81, %84
  %86 = bitcast double %85 to i64
  %87 = zext i64 %86 to i128
  %88 = and i128 %XMM1_2, -18446744073709551616
  %XMM1_3 = or i128 %87, %88
  %89 = zext i128 %XMM1_3 to i256
  %90 = and i256 %YMM1_2, -340282366920938463463374607431768211456
  %YMM1_3 = or i256 %89, %90
  %91 = zext i128 %XMM1_3 to i512
  %92 = and i512 %ZMM1_2, -340282366920938463463374607431768211456
  %ZMM1_3 = or i512 %91, %92
  %RIP_14 = add i64 %RIP_13, 5
  %EIP_13 = trunc i64 %RIP_14 to i32
  %IP_13 = trunc i64 %RIP_14 to i16
  %93 = trunc i128 %XMM1_3 to i64
  %94 = bitcast i64 %93 to double
  %95 = add i64 %RSP_1, -32
  %96 = inttoptr i64 %95 to double*
  store double %94, double* %96, align 1
  %RIP_15 = add i64 %RIP_14, 5
  %EIP_14 = trunc i64 %RIP_15 to i32
  %IP_14 = trunc i64 %RIP_15 to i16
  %97 = add i64 %RSP_1, -16
  %98 = inttoptr i64 %97 to double*
  %99 = load double, double* %98, align 1
  %100 = bitcast double %99 to i64
  %101 = zext i64 %100 to i128
  %102 = and i128 %XMM1_3, -18446744073709551616
  %XMM1_4 = or i128 %101, %102
  %103 = zext i128 %XMM1_4 to i256
  %104 = and i256 %YMM1_3, -340282366920938463463374607431768211456
  %YMM1_4 = or i256 %103, %104
  %105 = zext i128 %XMM1_4 to i512
  %106 = and i512 %ZMM1_3, -340282366920938463463374607431768211456
  %ZMM1_4 = or i512 %105, %106
  %RIP_16 = add i64 %RIP_15, 5
  %EIP_15 = trunc i64 %RIP_16 to i32
  %IP_15 = trunc i64 %RIP_16 to i16
  %107 = trunc i128 %XMM1_4 to i64
  %108 = bitcast i64 %107 to double
  %109 = add i64 %RSP_1, -24
  %110 = inttoptr i64 %109 to double*
  %111 = load double, double* %110, align 1
  %112 = fsub double %108, %111
  %113 = bitcast double %112 to i64
  %114 = zext i64 %113 to i128
  %115 = and i128 %XMM1_4, -18446744073709551616
  %XMM1_5 = or i128 %114, %115
  %116 = zext i128 %XMM1_5 to i256
  %117 = and i256 %YMM1_4, -340282366920938463463374607431768211456
  %YMM1_5 = or i256 %116, %117
  %118 = zext i128 %XMM1_5 to i512
  %119 = and i512 %ZMM1_4, -340282366920938463463374607431768211456
  %ZMM1_5 = or i512 %118, %119
  %RIP_17 = add i64 %RIP_16, 5
  %EIP_16 = trunc i64 %RIP_17 to i32
  %IP_16 = trunc i64 %RIP_17 to i16
  %120 = trunc i128 %XMM1_5 to i64
  %121 = bitcast i64 %120 to double
  %122 = add i64 %RSP_1, -40
  %123 = inttoptr i64 %122 to double*
  store double %121, double* %123, align 1
  %RIP_18 = add i64 %RIP_17, 5
  %EIP_17 = trunc i64 %RIP_18 to i32
  %IP_17 = trunc i64 %RIP_18 to i16
  %124 = add i64 %RSP_1, -16
  %125 = inttoptr i64 %124 to double*
  %126 = load double, double* %125, align 1
  %127 = bitcast double %126 to i64
  %128 = zext i64 %127 to i128
  %129 = and i128 %XMM1_5, -18446744073709551616
  %XMM1_6 = or i128 %128, %129
  %130 = zext i128 %XMM1_6 to i256
  %131 = and i256 %YMM1_5, -340282366920938463463374607431768211456
  %YMM1_6 = or i256 %130, %131
  %132 = zext i128 %XMM1_6 to i512
  %133 = and i512 %ZMM1_5, -340282366920938463463374607431768211456
  %ZMM1_6 = or i512 %132, %133
  %RIP_19 = add i64 %RIP_18, 5
  %EIP_18 = trunc i64 %RIP_19 to i32
  %IP_18 = trunc i64 %RIP_19 to i16
  %134 = trunc i128 %XMM1_6 to i64
  %135 = bitcast i64 %134 to double
  %136 = add i64 %RSP_1, -24
  %137 = inttoptr i64 %136 to double*
  %138 = load double, double* %137, align 1
  %139 = fmul double %135, %138
  %140 = bitcast double %139 to i64
  %141 = zext i64 %140 to i128
  %142 = and i128 %XMM1_6, -18446744073709551616
  %XMM1_7 = or i128 %141, %142
  %143 = zext i128 %XMM1_7 to i256
  %144 = and i256 %YMM1_6, -340282366920938463463374607431768211456
  %YMM1_7 = or i256 %143, %144
  %145 = zext i128 %XMM1_7 to i512
  %146 = and i512 %ZMM1_6, -340282366920938463463374607431768211456
  %ZMM1_7 = or i512 %145, %146
  %RIP_20 = add i64 %RIP_19, 5
  %EIP_19 = trunc i64 %RIP_20 to i32
  %IP_19 = trunc i64 %RIP_20 to i16
  %147 = trunc i128 %XMM1_7 to i64
  %148 = bitcast i64 %147 to double
  %149 = add i64 %RSP_1, -48
  %150 = inttoptr i64 %149 to double*
  store double %148, double* %150, align 1
  %RIP_21 = add i64 %RIP_20, 5
  %EIP_20 = trunc i64 %RIP_21 to i32
  %IP_20 = trunc i64 %RIP_21 to i16
  %151 = add i64 %RSP_1, -16
  %152 = inttoptr i64 %151 to double*
  %153 = load double, double* %152, align 1
  %154 = bitcast double %153 to i64
  %155 = zext i64 %154 to i128
  %156 = and i128 %XMM1_7, -18446744073709551616
  %XMM1_8 = or i128 %155, %156
  %157 = zext i128 %XMM1_8 to i256
  %158 = and i256 %YMM1_7, -340282366920938463463374607431768211456
  %YMM1_8 = or i256 %157, %158
  %159 = zext i128 %XMM1_8 to i512
  %160 = and i512 %ZMM1_7, -340282366920938463463374607431768211456
  %ZMM1_8 = or i512 %159, %160
  %RIP_22 = add i64 %RIP_21, 5
  %EIP_21 = trunc i64 %RIP_22 to i32
  %IP_21 = trunc i64 %RIP_22 to i16
  %161 = trunc i128 %XMM1_8 to i64
  %162 = bitcast i64 %161 to double
  %163 = add i64 %RSP_1, -24
  %164 = inttoptr i64 %163 to double*
  %165 = load double, double* %164, align 1
  %166 = fdiv double %162, %165
  %167 = bitcast double %166 to i64
  %168 = zext i64 %167 to i128
  %169 = and i128 %XMM1_8, -18446744073709551616
  %XMM1_9 = or i128 %168, %169
  %170 = zext i128 %XMM1_9 to i256
  %171 = and i256 %YMM1_8, -340282366920938463463374607431768211456
  %YMM1_9 = or i256 %170, %171
  %172 = zext i128 %XMM1_9 to i512
  %173 = and i512 %ZMM1_8, -340282366920938463463374607431768211456
  %ZMM1_9 = or i512 %172, %173
  %RIP_23 = add i64 %RIP_22, 5
  %EIP_22 = trunc i64 %RIP_23 to i32
  %IP_22 = trunc i64 %RIP_23 to i16
  %174 = trunc i128 %XMM1_9 to i64
  %175 = bitcast i64 %174 to double
  %176 = add i64 %RSP_1, -56
  %177 = inttoptr i64 %176 to double*
  store double %175, double* %177, align 1
  %RIP_24 = add i64 %RIP_23, 5
  %EIP_23 = trunc i64 %RIP_24 to i32
  %IP_23 = trunc i64 %RIP_24 to i16
  %178 = add i64 %RSP_1, -32
  %179 = inttoptr i64 %178 to double*
  %180 = load double, double* %179, align 1
  %181 = bitcast double %180 to i64
  %182 = zext i64 %181 to i128
  %183 = and i128 %XMM1_9, -18446744073709551616
  %XMM1_10 = or i128 %182, %183
  %184 = zext i128 %XMM1_10 to i256
  %185 = and i256 %YMM1_9, -340282366920938463463374607431768211456
  %YMM1_10 = or i256 %184, %185
  %186 = zext i128 %XMM1_10 to i512
  %187 = and i512 %ZMM1_9, -340282366920938463463374607431768211456
  %ZMM1_10 = or i512 %186, %187
  %RIP_25 = add i64 %RIP_24, 5
  %EIP_24 = trunc i64 %RIP_25 to i32
  %IP_24 = trunc i64 %RIP_25 to i16
  %188 = trunc i128 %XMM1_10 to i64
  %189 = bitcast i64 %188 to double
  %190 = add i64 %RSP_1, -40
  %191 = inttoptr i64 %190 to double*
  %192 = load double, double* %191, align 1
  %193 = fmul double %189, %192
  %194 = bitcast double %193 to i64
  %195 = zext i64 %194 to i128
  %196 = and i128 %XMM1_10, -18446744073709551616
  %XMM1_11 = or i128 %195, %196
  %197 = zext i128 %XMM1_11 to i256
  %198 = and i256 %YMM1_10, -340282366920938463463374607431768211456
  %YMM1_11 = or i256 %197, %198
  %199 = zext i128 %XMM1_11 to i512
  %200 = and i512 %ZMM1_10, -340282366920938463463374607431768211456
  %ZMM1_11 = or i512 %199, %200
  %RIP_26 = add i64 %RIP_25, 5
  %EIP_25 = trunc i64 %RIP_26 to i32
  %IP_25 = trunc i64 %RIP_26 to i16
  %201 = trunc i128 %XMM1_11 to i64
  %202 = bitcast i64 %201 to double
  %203 = add i64 %RSP_1, -48
  %204 = inttoptr i64 %203 to double*
  %205 = load double, double* %204, align 1
  %206 = fdiv double %202, %205
  %207 = bitcast double %206 to i64
  %208 = zext i64 %207 to i128
  %209 = and i128 %XMM1_11, -18446744073709551616
  %XMM1_12 = or i128 %208, %209
  %210 = zext i128 %XMM1_12 to i256
  %211 = and i256 %YMM1_11, -340282366920938463463374607431768211456
  %YMM1_12 = or i256 %210, %211
  %212 = zext i128 %XMM1_12 to i512
  %213 = and i512 %ZMM1_11, -340282366920938463463374607431768211456
  %ZMM1_12 = or i512 %212, %213
  %RIP_27 = add i64 %RIP_26, 5
  %EIP_26 = trunc i64 %RIP_27 to i32
  %IP_26 = trunc i64 %RIP_27 to i16
  %214 = trunc i128 %XMM1_12 to i64
  %215 = bitcast i64 %214 to double
  %216 = add i64 %RSP_1, -56
  %217 = inttoptr i64 %216 to double*
  %218 = load double, double* %217, align 1
  %219 = fadd double %215, %218
  %220 = bitcast double %219 to i64
  %221 = zext i64 %220 to i128
  %222 = and i128 %XMM1_12, -18446744073709551616
  %XMM1_13 = or i128 %221, %222
  %223 = zext i128 %XMM1_13 to i256
  %224 = and i256 %YMM1_12, -340282366920938463463374607431768211456
  %YMM1_13 = or i256 %223, %224
  %225 = zext i128 %XMM1_13 to i512
  %226 = and i512 %ZMM1_12, -340282366920938463463374607431768211456
  %ZMM1_13 = or i512 %225, %226
  %RIP_28 = add i64 %RIP_27, 5
  %EIP_27 = trunc i64 %RIP_28 to i32
  %IP_27 = trunc i64 %RIP_28 to i16
  %227 = trunc i128 %XMM1_13 to i64
  %228 = bitcast i64 %227 to double
  %229 = add i64 %RSP_1, -64
  %230 = inttoptr i64 %229 to double*
  store double %228, double* %230, align 1
  %RIP_29 = add i64 %RIP_28, 5
  %EIP_28 = trunc i64 %RIP_29 to i32
  %IP_28 = trunc i64 %RIP_29 to i16
  %231 = trunc i128 %XMM0_1 to i64
  %232 = bitcast i64 %231 to double
  %233 = add i64 %RSP_1, -64
  %234 = inttoptr i64 %233 to double*
  %235 = load double, double* %234, align 1
  %ZF_0 = fcmp ueq double %232, %235
  %PF_0 = fcmp uno double %232, %235
  %CF_0 = fcmp ult double %232, %235
  %CtlSysEFLAGS_0 = load i32, i32* %CtlSysEFLAGS
  %236 = zext i1 %CF_0 to i32
  %237 = shl i32 %236, 0
  %238 = or i32 %237, %CtlSysEFLAGS_0
  %239 = zext i1 %PF_0 to i32
  %240 = shl i32 %239, 2
  %241 = or i32 %240, %238
  %242 = zext i1 false to i32
  %243 = shl i32 %242, 4
  %244 = or i32 %243, %241
  %245 = zext i1 %ZF_0 to i32
  %246 = shl i32 %245, 6
  %247 = or i32 %246, %244
  %248 = zext i1 false to i32
  %249 = shl i32 %248, 7
  %250 = or i32 %249, %247
  %251 = zext i1 false to i32
  %252 = shl i32 %251, 11
  %EFLAGS_1 = or i32 %252, %250
  %RIP_30 = add i64 %RIP_29, 6
  %EIP_29 = trunc i64 %RIP_30 to i32
  %IP_29 = trunc i64 %RIP_30 to i16
  %CC_BE_0 = or i1 %CF_0, %ZF_0
  store i8 92, i8* %AH
  store i8 -98, i8* %AL
  store i16 23710, i16* %AX
  store i16 %BP_0, i16* %BP
  store i8 %BPL_0, i8* %BPL
  store i32 %CtlSysEFLAGS_0, i32* %CtlSysEFLAGS
  store i32 1336630430, i32* %EAX
  store i32 %EBP_0, i32* %EBP
  store i32 %EFLAGS_1, i32* %EFLAGS
  store i32 4195831, i32* %EIP
  store i32 %ESP_1, i32* %ESP
  store i16 1527, i16* %IP
  store i64 1336630430, i64* %RAX
  store i64 %RSP_1, i64* %RBP
  store i64 4195831, i64* %RIP
  store i64 %RSP_2, i64* %RSP
  store i16 %SP_1, i16* %SP
  store i8 %SPL_1, i8* %SPL
  %253 = bitcast i128 %XMM0_1 to <4 x float>
  store <4 x float> %253, <4 x float>* %XMM0
  %254 = bitcast i128 %XMM1_13 to <4 x float>
  store <4 x float> %254, <4 x float>* %XMM1
  %255 = bitcast i128 %XMM2_1 to <4 x float>
  store <4 x float> %255, <4 x float>* %XMM2
  %256 = bitcast i256 %YMM0_1 to <8 x float>
  store <8 x float> %256, <8 x float>* %YMM0
  %257 = bitcast i256 %YMM1_13 to <8 x float>
  store <8 x float> %257, <8 x float>* %YMM1
  %258 = bitcast i256 %YMM2_1 to <8 x float>
  store <8 x float> %258, <8 x float>* %YMM2
  %259 = bitcast i512 %ZMM0_1 to <16 x float>
  store <16 x float> %259, <16 x float>* %ZMM0
  %260 = bitcast i512 %ZMM1_13 to <16 x float>
  store <16 x float> %260, <16 x float>* %ZMM1
  %261 = bitcast i512 %ZMM2_1 to <16 x float>
  store <16 x float> %261, <16 x float>* %ZMM2
  br i1 %CC_BE_0, label %bb_4005F7, label %bb_4005EA

bb_4005EA:                                        ; preds = %bb_400550
  %RIP_33 = add i64 4195818, 5
  %EIP_31 = trunc i64 %RIP_33 to i32
  %IP_31 = trunc i64 %RIP_33 to i16
  %RBP_1 = load i64, i64* %RBP
  %262 = add i64 %RBP_1, -32
  %263 = inttoptr i64 %262 to double*
  %264 = load double, double* %263, align 1
  %EAX_2 = fptosi double %264 to i32
  %RAX_2 = load i64, i64* %RAX
  %RAX_3 = zext i32 %EAX_2 to i64
  %AX_2 = trunc i32 %EAX_2 to i16
  %AL_2 = trunc i32 %EAX_2 to i8
  %265 = lshr i32 %EAX_2, 8
  %AH_2 = trunc i32 %265 to i8
  %RIP_34 = add i64 %RIP_33, 3
  %EIP_32 = trunc i64 %RIP_34 to i32
  %IP_32 = trunc i64 %RIP_34 to i16
  %266 = add i64 %RBP_1, -4
  %267 = inttoptr i64 %266 to i32*
  store i32 %EAX_2, i32* %267, align 1
  %RIP_35 = add i64 %RIP_34, 5
  %EIP_33 = trunc i64 %RIP_35 to i32
  %IP_33 = trunc i64 %RIP_35 to i16
  store i8 %AH_2, i8* %AH
  store i8 %AL_2, i8* %AL
  store i16 %AX_2, i16* %AX
  store i32 %EAX_2, i32* %EAX
  store i32 4196028, i32* %EIP
  store i16 1724, i16* %IP
  store i64 %RAX_3, i64* %RAX
  store i64 %RBP_1, i64* %RBP
  store i64 4196028, i64* %RIP
  br label %bb_4006BC

bb_4005F7:                                        ; preds = %bb_400550
  %RIP_38 = add i64 4195831, 3
  %EIP_35 = trunc i64 %RIP_38 to i32
  %IP_35 = trunc i64 %RIP_38 to i16
  %ZMM0_2 = load <16 x float>, <16 x float>* %ZMM0
  %268 = bitcast <16 x float> %ZMM0_2 to i512
  %XMM0_2 = trunc i512 %268 to i128
  %269 = bitcast i128 %XMM0_2 to <4 x float>
  %270 = bitcast <4 x float> %269 to <2 x i64>
  %271 = bitcast i128 %XMM0_2 to <4 x float>
  %272 = bitcast <4 x float> %271 to <2 x i64>
  %273 = xor <2 x i64> %270, %272
  %XMM0_3 = bitcast <2 x i64> %273 to i128
  %274 = bitcast <16 x float> %ZMM0_2 to i512
  %YMM0_2 = trunc i512 %274 to i256
  %275 = zext i128 %XMM0_3 to i256
  %276 = and i256 %YMM0_2, -340282366920938463463374607431768211456
  %YMM0_3 = or i256 %275, %276
  %277 = bitcast <16 x float> %ZMM0_2 to i512
  %278 = zext i128 %XMM0_3 to i512
  %279 = and i512 %277, -340282366920938463463374607431768211456
  %ZMM0_3 = or i512 %278, %279
  %RIP_39 = add i64 %RIP_38, 5
  %EIP_36 = trunc i64 %RIP_39 to i32
  %IP_36 = trunc i64 %RIP_39 to i16
  %RBP_2 = load i64, i64* %RBP
  %280 = add i64 %RBP_2, -64
  %281 = inttoptr i64 %280 to double*
  %282 = load double, double* %281, align 1
  %283 = bitcast double %282 to i64
  %ZMM1_14 = load <16 x float>, <16 x float>* %ZMM1
  %284 = bitcast <16 x float> %ZMM1_14 to i512
  %XMM1_14 = trunc i512 %284 to i128
  %285 = zext i64 %283 to i128
  %286 = and i128 %XMM1_14, -18446744073709551616
  %XMM1_15 = or i128 %285, %286
  %287 = bitcast <16 x float> %ZMM1_14 to i512
  %YMM1_14 = trunc i512 %287 to i256
  %288 = zext i128 %XMM1_15 to i256
  %289 = and i256 %YMM1_14, -340282366920938463463374607431768211456
  %YMM1_15 = or i256 %288, %289
  %290 = bitcast <16 x float> %ZMM1_14 to i512
  %291 = zext i128 %XMM1_15 to i512
  %292 = and i512 %290, -340282366920938463463374607431768211456
  %ZMM1_15 = or i512 %291, %292
  %RIP_40 = add i64 %RIP_39, 4
  %EIP_37 = trunc i64 %RIP_40 to i32
  %IP_37 = trunc i64 %RIP_40 to i16
  %293 = trunc i128 %XMM1_15 to i64
  %294 = bitcast i64 %293 to double
  %295 = trunc i128 %XMM0_3 to i64
  %296 = bitcast i64 %295 to double
  %ZF_01 = fcmp ueq double %294, %296
  %PF_02 = fcmp uno double %294, %296
  %CF_03 = fcmp ult double %294, %296
  %CtlSysEFLAGS_1 = load i32, i32* %CtlSysEFLAGS
  %297 = zext i1 %CF_03 to i32
  %298 = shl i32 %297, 0
  %299 = or i32 %298, %CtlSysEFLAGS_1
  %300 = zext i1 %PF_02 to i32
  %301 = shl i32 %300, 2
  %302 = or i32 %301, %299
  %303 = zext i1 false to i32
  %304 = shl i32 %303, 4
  %305 = or i32 %304, %302
  %306 = zext i1 %ZF_01 to i32
  %307 = shl i32 %306, 6
  %308 = or i32 %307, %305
  %309 = zext i1 false to i32
  %310 = shl i32 %309, 7
  %311 = or i32 %310, %308
  %312 = zext i1 false to i32
  %313 = shl i32 %312, 11
  %EFLAGS_2 = or i32 %313, %311
  %RIP_41 = add i64 %RIP_40, 6
  %EIP_38 = trunc i64 %RIP_41 to i32
  %IP_38 = trunc i64 %RIP_41 to i16
  store i32 %CtlSysEFLAGS_1, i32* %CtlSysEFLAGS
  store i32 %EFLAGS_2, i32* %EFLAGS
  store i32 4195888, i32* %EIP
  store i16 1584, i16* %IP
  store i64 %RBP_2, i64* %RBP
  store i64 4195888, i64* %RIP
  %314 = bitcast i128 %XMM0_3 to <4 x float>
  store <4 x float> %314, <4 x float>* %XMM0
  %315 = bitcast i128 %XMM1_15 to <4 x float>
  store <4 x float> %315, <4 x float>* %XMM1
  %316 = bitcast i256 %YMM0_3 to <8 x float>
  store <8 x float> %316, <8 x float>* %YMM0
  %317 = bitcast i256 %YMM1_15 to <8 x float>
  store <8 x float> %317, <8 x float>* %YMM1
  %318 = bitcast i512 %ZMM0_3 to <16 x float>
  store <16 x float> %318, <16 x float>* %ZMM0
  %319 = bitcast i512 %ZMM1_15 to <16 x float>
  store <16 x float> %319, <16 x float>* %ZMM1
  br i1 %CF_03, label %bb_400630, label %bb_400609

bb_400609:                                        ; preds = %bb_4005F7
  %RIP_50 = add i64 4195849, 10
  %EIP_45 = trunc i64 %RIP_50 to i32
  %IP_45 = trunc i64 %RIP_50 to i16
  %RIP_51 = add i64 %RIP_50, 5
  %EIP_46 = trunc i64 %RIP_51 to i32
  %IP_46 = trunc i64 %RIP_51 to i16
  %320 = sitofp i64 5 to double
  %321 = bitcast double %320 to i64
  %ZMM0_4 = load <16 x float>, <16 x float>* %ZMM0
  %322 = bitcast <16 x float> %ZMM0_4 to i512
  %XMM0_4 = trunc i512 %322 to i128
  %323 = zext i64 %321 to i128
  %324 = and i128 %XMM0_4, -18446744073709551616
  %XMM0_5 = or i128 %323, %324
  %325 = bitcast <16 x float> %ZMM0_4 to i512
  %YMM0_4 = trunc i512 %325 to i256
  %326 = zext i128 %XMM0_5 to i256
  %327 = and i256 %YMM0_4, -340282366920938463463374607431768211456
  %YMM0_5 = or i256 %326, %327
  %328 = bitcast <16 x float> %ZMM0_4 to i512
  %329 = zext i128 %XMM0_5 to i512
  %330 = and i512 %328, -340282366920938463463374607431768211456
  %ZMM0_5 = or i512 %329, %330
  %RIP_52 = add i64 %RIP_51, 5
  %EIP_47 = trunc i64 %RIP_52 to i32
  %IP_47 = trunc i64 %RIP_52 to i16
  %331 = trunc i128 %XMM0_5 to i64
  %332 = bitcast i64 %331 to double
  %RBP_5 = load i64, i64* %RBP
  %333 = add i64 %RBP_5, -64
  %334 = inttoptr i64 %333 to double*
  %335 = load double, double* %334, align 1
  %ZF_07 = fcmp ueq double %332, %335
  %PF_08 = fcmp uno double %332, %335
  %CF_09 = fcmp ult double %332, %335
  %CtlSysEFLAGS_3 = load i32, i32* %CtlSysEFLAGS
  %336 = zext i1 %CF_09 to i32
  %337 = shl i32 %336, 0
  %338 = or i32 %337, %CtlSysEFLAGS_3
  %339 = zext i1 %PF_08 to i32
  %340 = shl i32 %339, 2
  %341 = or i32 %340, %338
  %342 = zext i1 false to i32
  %343 = shl i32 %342, 4
  %344 = or i32 %343, %341
  %345 = zext i1 %ZF_07 to i32
  %346 = shl i32 %345, 6
  %347 = or i32 %346, %344
  %348 = zext i1 false to i32
  %349 = shl i32 %348, 7
  %350 = or i32 %349, %347
  %351 = zext i1 false to i32
  %352 = shl i32 %351, 11
  %EFLAGS_5 = or i32 %352, %350
  %RIP_53 = add i64 %RIP_52, 6
  %EIP_48 = trunc i64 %RIP_53 to i32
  %IP_48 = trunc i64 %RIP_53 to i16
  %CC_BE_010 = or i1 %CF_09, %ZF_07
  store i8 0, i8* %AH
  store i8 5, i8* %AL
  store i16 5, i16* %AX
  store i32 %CtlSysEFLAGS_3, i32* %CtlSysEFLAGS
  store i32 5, i32* %EAX
  store i32 %EFLAGS_5, i32* %EFLAGS
  store i32 4195888, i32* %EIP
  store i16 1584, i16* %IP
  store i64 5, i64* %RAX
  store i64 %RBP_5, i64* %RBP
  store i64 4195888, i64* %RIP
  %353 = bitcast i128 %XMM0_5 to <4 x float>
  store <4 x float> %353, <4 x float>* %XMM0
  %354 = bitcast i256 %YMM0_5 to <8 x float>
  store <8 x float> %354, <8 x float>* %YMM0
  %355 = bitcast i512 %ZMM0_5 to <16 x float>
  store <16 x float> %355, <16 x float>* %ZMM0
  br i1 %CC_BE_010, label %bb_400630, label %bb_400623

bb_400623:                                        ; preds = %bb_400609
  %RIP_63 = add i64 4195875, 5
  %EIP_56 = trunc i64 %RIP_63 to i32
  %IP_56 = trunc i64 %RIP_63 to i16
  %RBP_7 = load i64, i64* %RBP
  %356 = add i64 %RBP_7, -40
  %357 = inttoptr i64 %356 to double*
  %358 = load double, double* %357, align 1
  %EAX_6 = fptosi double %358 to i32
  %RAX_8 = load i64, i64* %RAX
  %RAX_9 = zext i32 %EAX_6 to i64
  %AX_6 = trunc i32 %EAX_6 to i16
  %AL_6 = trunc i32 %EAX_6 to i8
  %359 = lshr i32 %EAX_6, 8
  %AH_6 = trunc i32 %359 to i8
  %RIP_64 = add i64 %RIP_63, 3
  %EIP_57 = trunc i64 %RIP_64 to i32
  %IP_57 = trunc i64 %RIP_64 to i16
  %360 = add i64 %RBP_7, -4
  %361 = inttoptr i64 %360 to i32*
  store i32 %EAX_6, i32* %361, align 1
  %RIP_65 = add i64 %RIP_64, 5
  %EIP_58 = trunc i64 %RIP_65 to i32
  %IP_58 = trunc i64 %RIP_65 to i16
  store i8 %AH_6, i8* %AH
  store i8 %AL_6, i8* %AL
  store i16 %AX_6, i16* %AX
  store i32 %EAX_6, i32* %EAX
  store i32 4196028, i32* %EIP
  store i16 1724, i16* %IP
  store i64 %RAX_9, i64* %RAX
  store i64 %RBP_7, i64* %RBP
  store i64 4196028, i64* %RIP
  br label %bb_4006BC

bb_400630:                                        ; preds = %bb_400609, %bb_4005F7
  %RIP_56 = add i64 4195888, 10
  %EIP_50 = trunc i64 %RIP_56 to i32
  %IP_50 = trunc i64 %RIP_56 to i16
  %RIP_57 = add i64 %RIP_56, 5
  %EIP_51 = trunc i64 %RIP_57 to i32
  %IP_51 = trunc i64 %RIP_57 to i16
  %362 = sitofp i64 5 to double
  %363 = bitcast double %362 to i64
  %ZMM0_6 = load <16 x float>, <16 x float>* %ZMM0
  %364 = bitcast <16 x float> %ZMM0_6 to i512
  %XMM0_6 = trunc i512 %364 to i128
  %365 = zext i64 %363 to i128
  %366 = and i128 %XMM0_6, -18446744073709551616
  %XMM0_7 = or i128 %365, %366
  %367 = bitcast <16 x float> %ZMM0_6 to i512
  %YMM0_6 = trunc i512 %367 to i256
  %368 = zext i128 %XMM0_7 to i256
  %369 = and i256 %YMM0_6, -340282366920938463463374607431768211456
  %YMM0_7 = or i256 %368, %369
  %370 = bitcast <16 x float> %ZMM0_6 to i512
  %371 = zext i128 %XMM0_7 to i512
  %372 = and i512 %370, -340282366920938463463374607431768211456
  %ZMM0_7 = or i512 %371, %372
  %RIP_58 = add i64 %RIP_57, 5
  %EIP_52 = trunc i64 %RIP_58 to i32
  %IP_52 = trunc i64 %RIP_58 to i16
  %RBP_6 = load i64, i64* %RBP
  %373 = add i64 %RBP_6, -64
  %374 = inttoptr i64 %373 to double*
  %375 = load double, double* %374, align 1
  %376 = bitcast double %375 to i64
  %ZMM1_16 = load <16 x float>, <16 x float>* %ZMM1
  %377 = bitcast <16 x float> %ZMM1_16 to i512
  %XMM1_16 = trunc i512 %377 to i128
  %378 = zext i64 %376 to i128
  %379 = and i128 %XMM1_16, -18446744073709551616
  %XMM1_17 = or i128 %378, %379
  %380 = bitcast <16 x float> %ZMM1_16 to i512
  %YMM1_16 = trunc i512 %380 to i256
  %381 = zext i128 %XMM1_17 to i256
  %382 = and i256 %YMM1_16, -340282366920938463463374607431768211456
  %YMM1_17 = or i256 %381, %382
  %383 = bitcast <16 x float> %ZMM1_16 to i512
  %384 = zext i128 %XMM1_17 to i512
  %385 = and i512 %383, -340282366920938463463374607431768211456
  %ZMM1_17 = or i512 %384, %385
  %RIP_59 = add i64 %RIP_58, 4
  %EIP_53 = trunc i64 %RIP_59 to i32
  %IP_53 = trunc i64 %RIP_59 to i16
  %386 = trunc i128 %XMM1_17 to i64
  %387 = bitcast i64 %386 to double
  %388 = trunc i128 %XMM0_7 to i64
  %389 = bitcast i64 %388 to double
  %ZF_011 = fcmp ueq double %387, %389
  %PF_012 = fcmp uno double %387, %389
  %CF_013 = fcmp ult double %387, %389
  %CtlSysEFLAGS_4 = load i32, i32* %CtlSysEFLAGS
  %390 = zext i1 %CF_013 to i32
  %391 = shl i32 %390, 0
  %392 = or i32 %391, %CtlSysEFLAGS_4
  %393 = zext i1 %PF_012 to i32
  %394 = shl i32 %393, 2
  %395 = or i32 %394, %392
  %396 = zext i1 false to i32
  %397 = shl i32 %396, 4
  %398 = or i32 %397, %395
  %399 = zext i1 %ZF_011 to i32
  %400 = shl i32 %399, 6
  %401 = or i32 %400, %398
  %402 = zext i1 false to i32
  %403 = shl i32 %402, 7
  %404 = or i32 %403, %401
  %405 = zext i1 false to i32
  %406 = shl i32 %405, 11
  %EFLAGS_6 = or i32 %406, %404
  %RIP_60 = add i64 %RIP_59, 6
  %EIP_54 = trunc i64 %RIP_60 to i32
  %IP_54 = trunc i64 %RIP_60 to i16
  %CC_NE_0 = xor i1 %ZF_011, true
  store i8 0, i8* %AH
  store i8 5, i8* %AL
  store i16 5, i16* %AX
  store i32 %CtlSysEFLAGS_4, i32* %CtlSysEFLAGS
  store i32 5, i32* %EAX
  store i32 %EFLAGS_6, i32* %EFLAGS
  store i32 4195937, i32* %EIP
  store i16 1633, i16* %IP
  store i64 5, i64* %RAX
  store i64 %RBP_6, i64* %RBP
  store i64 4195937, i64* %RIP
  %407 = bitcast i128 %XMM0_7 to <4 x float>
  store <4 x float> %407, <4 x float>* %XMM0
  %408 = bitcast i128 %XMM1_17 to <4 x float>
  store <4 x float> %408, <4 x float>* %XMM1
  %409 = bitcast i256 %YMM0_7 to <8 x float>
  store <8 x float> %409, <8 x float>* %YMM0
  %410 = bitcast i256 %YMM1_17 to <8 x float>
  store <8 x float> %410, <8 x float>* %YMM1
  %411 = bitcast i512 %ZMM0_7 to <16 x float>
  store <16 x float> %411, <16 x float>* %ZMM0
  %412 = bitcast i512 %ZMM1_17 to <16 x float>
  store <16 x float> %412, <16 x float>* %ZMM1
  br i1 %CC_NE_0, label %bb_400661, label %bb_40064E

bb_40064E:                                        ; preds = %bb_400630
  %RIP_68 = add i64 4195918, 6
  %EIP_60 = trunc i64 %RIP_68 to i32
  %IP_60 = trunc i64 %RIP_68 to i16
  %EFLAGS_7 = load i32, i32* %EFLAGS
  %413 = lshr i32 %EFLAGS_7, 2
  %PF_014 = trunc i32 %413 to i1
  store i32 %EFLAGS_7, i32* %EFLAGS
  store i32 4195937, i32* %EIP
  store i16 1633, i16* %IP
  store i64 4195937, i64* %RIP
  br i1 %PF_014, label %bb_400661, label %bb_400654

bb_400654:                                        ; preds = %bb_40064E
  %RIP_74 = add i64 4195924, 5
  %EIP_64 = trunc i64 %RIP_74 to i32
  %IP_64 = trunc i64 %RIP_74 to i16
  %RBP_8 = load i64, i64* %RBP
  %414 = add i64 %RBP_8, -48
  %415 = inttoptr i64 %414 to double*
  %416 = load double, double* %415, align 1
  %EAX_7 = fptosi double %416 to i32
  %RAX_10 = load i64, i64* %RAX
  %RAX_11 = zext i32 %EAX_7 to i64
  %AX_7 = trunc i32 %EAX_7 to i16
  %AL_7 = trunc i32 %EAX_7 to i8
  %417 = lshr i32 %EAX_7, 8
  %AH_7 = trunc i32 %417 to i8
  %RIP_75 = add i64 %RIP_74, 3
  %EIP_65 = trunc i64 %RIP_75 to i32
  %IP_65 = trunc i64 %RIP_75 to i16
  %418 = add i64 %RBP_8, -4
  %419 = inttoptr i64 %418 to i32*
  store i32 %EAX_7, i32* %419, align 1
  %RIP_76 = add i64 %RIP_75, 5
  %EIP_66 = trunc i64 %RIP_76 to i32
  %IP_66 = trunc i64 %RIP_76 to i16
  store i8 %AH_7, i8* %AH
  store i8 %AL_7, i8* %AL
  store i16 %AX_7, i16* %AX
  store i32 %EAX_7, i32* %EAX
  store i32 4196028, i32* %EIP
  store i16 1724, i16* %IP
  store i64 %RAX_11, i64* %RAX
  store i64 %RBP_8, i64* %RBP
  store i64 4196028, i64* %RIP
  br label %bb_4006BC

bb_400661:                                        ; preds = %bb_40064E, %bb_400630
  %RIP_71 = add i64 4195937, 5
  %EIP_62 = trunc i64 %RIP_71 to i32
  %IP_62 = trunc i64 %RIP_71 to i16
  store i32 4195942, i32* %EIP
  store i16 1638, i16* %IP
  store i64 4195942, i64* %RIP
  br label %bb_400666

bb_400666:                                        ; preds = %bb_400678, %bb_400661
  %RIP_79 = add i64 4195942, 3
  %EIP_68 = trunc i64 %RIP_79 to i32
  %IP_68 = trunc i64 %RIP_79 to i16
  %ZMM0_8 = load <16 x float>, <16 x float>* %ZMM0
  %420 = bitcast <16 x float> %ZMM0_8 to i512
  %XMM0_8 = trunc i512 %420 to i128
  %421 = bitcast i128 %XMM0_8 to <4 x float>
  %422 = bitcast <4 x float> %421 to <2 x i64>
  %423 = bitcast i128 %XMM0_8 to <4 x float>
  %424 = bitcast <4 x float> %423 to <2 x i64>
  %425 = xor <2 x i64> %422, %424
  %XMM0_9 = bitcast <2 x i64> %425 to i128
  %426 = bitcast <16 x float> %ZMM0_8 to i512
  %YMM0_8 = trunc i512 %426 to i256
  %427 = zext i128 %XMM0_9 to i256
  %428 = and i256 %YMM0_8, -340282366920938463463374607431768211456
  %YMM0_9 = or i256 %427, %428
  %429 = bitcast <16 x float> %ZMM0_8 to i512
  %430 = zext i128 %XMM0_9 to i512
  %431 = and i512 %429, -340282366920938463463374607431768211456
  %ZMM0_9 = or i512 %430, %431
  %RIP_80 = add i64 %RIP_79, 5
  %EIP_69 = trunc i64 %RIP_80 to i32
  %IP_69 = trunc i64 %RIP_80 to i16
  %RBP_9 = load i64, i64* %RBP
  %432 = add i64 %RBP_9, -64
  %433 = inttoptr i64 %432 to double*
  %434 = load double, double* %433, align 1
  %435 = bitcast double %434 to i64
  %ZMM1_18 = load <16 x float>, <16 x float>* %ZMM1
  %436 = bitcast <16 x float> %ZMM1_18 to i512
  %XMM1_18 = trunc i512 %436 to i128
  %437 = zext i64 %435 to i128
  %438 = and i128 %XMM1_18, -18446744073709551616
  %XMM1_19 = or i128 %437, %438
  %439 = bitcast <16 x float> %ZMM1_18 to i512
  %YMM1_18 = trunc i512 %439 to i256
  %440 = zext i128 %XMM1_19 to i256
  %441 = and i256 %YMM1_18, -340282366920938463463374607431768211456
  %YMM1_19 = or i256 %440, %441
  %442 = bitcast <16 x float> %ZMM1_18 to i512
  %443 = zext i128 %XMM1_19 to i512
  %444 = and i512 %442, -340282366920938463463374607431768211456
  %ZMM1_19 = or i512 %443, %444
  %RIP_81 = add i64 %RIP_80, 4
  %EIP_70 = trunc i64 %RIP_81 to i32
  %IP_70 = trunc i64 %RIP_81 to i16
  %445 = trunc i128 %XMM1_19 to i64
  %446 = bitcast i64 %445 to double
  %447 = trunc i128 %XMM0_9 to i64
  %448 = bitcast i64 %447 to double
  %ZF_015 = fcmp ueq double %446, %448
  %PF_016 = fcmp uno double %446, %448
  %CF_017 = fcmp ult double %446, %448
  %CtlSysEFLAGS_5 = load i32, i32* %CtlSysEFLAGS
  %449 = zext i1 %CF_017 to i32
  %450 = shl i32 %449, 0
  %451 = or i32 %450, %CtlSysEFLAGS_5
  %452 = zext i1 %PF_016 to i32
  %453 = shl i32 %452, 2
  %454 = or i32 %453, %451
  %455 = zext i1 false to i32
  %456 = shl i32 %455, 4
  %457 = or i32 %456, %454
  %458 = zext i1 %ZF_015 to i32
  %459 = shl i32 %458, 6
  %460 = or i32 %459, %457
  %461 = zext i1 false to i32
  %462 = shl i32 %461, 7
  %463 = or i32 %462, %460
  %464 = zext i1 false to i32
  %465 = shl i32 %464, 11
  %EFLAGS_8 = or i32 %465, %463
  %RIP_82 = add i64 %RIP_81, 6
  %EIP_71 = trunc i64 %RIP_82 to i32
  %IP_71 = trunc i64 %RIP_82 to i16
  %CC_BE_018 = or i1 %CF_017, %ZF_015
  store i32 %CtlSysEFLAGS_5, i32* %CtlSysEFLAGS
  store i32 %EFLAGS_8, i32* %EFLAGS
  store i32 4196011, i32* %EIP
  store i16 1707, i16* %IP
  store i64 %RBP_9, i64* %RBP
  store i64 4196011, i64* %RIP
  %466 = bitcast i128 %XMM0_9 to <4 x float>
  store <4 x float> %466, <4 x float>* %XMM0
  %467 = bitcast i128 %XMM1_19 to <4 x float>
  store <4 x float> %467, <4 x float>* %XMM1
  %468 = bitcast i256 %YMM0_9 to <8 x float>
  store <8 x float> %468, <8 x float>* %YMM0
  %469 = bitcast i256 %YMM1_19 to <8 x float>
  store <8 x float> %469, <8 x float>* %YMM1
  %470 = bitcast i512 %ZMM0_9 to <16 x float>
  store <16 x float> %470, <16 x float>* %ZMM0
  %471 = bitcast i512 %ZMM1_19 to <16 x float>
  store <16 x float> %471, <16 x float>* %ZMM1
  br i1 %CC_BE_018, label %bb_4006AB, label %bb_400678

bb_400678:                                        ; preds = %bb_400666
  %RIP_85 = add i64 4195960, 8
  %EIP_73 = trunc i64 %RIP_85 to i32
  %IP_73 = trunc i64 %RIP_85 to i16
  %RIP_86 = add i64 %RIP_85, 5
  %EIP_74 = trunc i64 %RIP_86 to i32
  %IP_74 = trunc i64 %RIP_86 to i16
  %RBP_10 = load i64, i64* %RBP
  %472 = add i64 %RBP_10, -64
  %473 = inttoptr i64 %472 to double*
  %474 = load double, double* %473, align 1
  %475 = bitcast double %474 to i64
  %ZMM0_10 = load <16 x float>, <16 x float>* %ZMM0
  %476 = bitcast <16 x float> %ZMM0_10 to i512
  %XMM0_10 = trunc i512 %476 to i128
  %477 = zext i64 %475 to i128
  %478 = and i128 %XMM0_10, -18446744073709551616
  %XMM0_11 = or i128 %477, %478
  %479 = bitcast <16 x float> %ZMM0_10 to i512
  %YMM0_10 = trunc i512 %479 to i256
  %480 = zext i128 %XMM0_11 to i256
  %481 = and i256 %YMM0_10, -340282366920938463463374607431768211456
  %YMM0_11 = or i256 %480, %481
  %482 = bitcast <16 x float> %ZMM0_10 to i512
  %483 = zext i128 %XMM0_11 to i512
  %484 = and i512 %482, -340282366920938463463374607431768211456
  %ZMM0_11 = or i512 %483, %484
  %RIP_87 = add i64 %RIP_86, 2
  %EIP_75 = trunc i64 %RIP_87 to i32
  %IP_75 = trunc i64 %RIP_87 to i16
  %RAX_12 = load i64, i64* %RAX
  %AX_8 = trunc i64 %RAX_12 to i16
  %485 = and i16 %AX_8, -256
  %AX_9 = or i16 1, %485
  %EAX_8 = trunc i64 %RAX_12 to i32
  %486 = and i32 %EAX_8, -256
  %EAX_9 = or i32 1, %486
  %487 = and i64 %RAX_12, -256
  %RAX_13 = or i64 1, %487
  %RIP_88 = add i64 %RIP_87, 5
  %EIP_76 = trunc i64 %RIP_88 to i32
  %IP_76 = trunc i64 %RIP_88 to i16
  %RSP_7 = load i64, i64* %RSP
  %RSP_8 = sub i64 %RSP_7, 8
  %488 = inttoptr i64 %RSP_8 to i64*
  store i64 4195980, i64* %488
  %ESP_5 = trunc i64 %RSP_8 to i32
  %SP_5 = trunc i64 %RSP_8 to i16
  %SPL_5 = trunc i64 %RSP_8 to i8
  store i8 1, i8* %AL
  store i16 %AX_9, i16* %AX
  store i16 1888, i16* %DI
  store i8 96, i8* %DIL
  store i32 %EAX_9, i32* %EAX
  store i32 4196192, i32* %EDI
  store i32 %EIP_76, i32* %EIP
  store i32 %ESP_5, i32* %ESP
  store i16 %IP_76, i16* %IP
  store i64 %RAX_13, i64* %RAX
  store i64 %RBP_10, i64* %RBP
  store i64 4196192, i64* %RDI
  store i64 %RIP_88, i64* %RIP
  store i64 %RSP_8, i64* %RSP
  store i16 %SP_5, i16* %SP
  store i8 %SPL_5, i8* %SPL
  %489 = bitcast i128 %XMM0_11 to <4 x float>
  store <4 x float> %489, <4 x float>* %XMM0
  %490 = bitcast i256 %YMM0_11 to <8 x float>
  store <8 x float> %490, <8 x float>* %YMM0
  %491 = bitcast i512 %ZMM0_11 to <16 x float>
  store <16 x float> %491, <16 x float>* %ZMM0
  %492 = load i32, i32* %CtlSysEFLAGS
  store i32 %492, i32* %CtlSysEFLAGS_ptr
  %493 = load i32, i32* %EFLAGS
  store i32 %493, i32* %EFLAGS_ptr
  %494 = load i64, i64* %RAX
  store i64 %494, i64* %RAX_ptr
  %495 = load i64, i64* %RBP
  store i64 %495, i64* %RBP_ptr
  %496 = load i64, i64* %RDI
  store i64 %496, i64* %RDI_ptr
  %497 = load i64, i64* %RIP
  store i64 %497, i64* %RIP_ptr
  %498 = load i64, i64* %RSP
  store i64 %498, i64* %RSP_ptr
  %499 = load <16 x float>, <16 x float>* %ZMM0
  store <16 x float> %499, <16 x float>* %ZMM0_ptr
  %500 = load <16 x float>, <16 x float>* %ZMM1
  store <16 x float> %500, <16 x float>* %ZMM1_ptr
  %501 = load <16 x float>, <16 x float>* %ZMM2
  store <16 x float> %501, <16 x float>* %ZMM2_ptr
  call void @fn_400410(%regset* %0)
  %502 = load i32, i32* %CtlSysEFLAGS_ptr
  store i32 %502, i32* %CtlSysEFLAGS
  %503 = load i32, i32* %EFLAGS_ptr
  store i32 %503, i32* %EFLAGS
  %504 = load i64, i64* %RAX_ptr
  store i64 %504, i64* %RAX
  %505 = load i64, i64* %RBP_ptr
  store i64 %505, i64* %RBP
  %506 = load i64, i64* %RDI_ptr
  store i64 %506, i64* %RDI
  %507 = load i64, i64* %RIP_ptr
  store i64 %507, i64* %RIP
  %508 = load i64, i64* %RSP_ptr
  store i64 %508, i64* %RSP
  %509 = load <16 x float>, <16 x float>* %ZMM0_ptr
  store <16 x float> %509, <16 x float>* %ZMM0
  %510 = load <16 x float>, <16 x float>* %ZMM1_ptr
  store <16 x float> %510, <16 x float>* %ZMM1
  %511 = load <16 x float>, <16 x float>* %ZMM2_ptr
  store <16 x float> %511, <16 x float>* %ZMM2
  %RIP_89 = load i64, i64* %RIP
  %RIP_90 = add i64 %RIP_89, 9
  %EIP_77 = trunc i64 %RIP_90 to i32
  %IP_77 = trunc i64 %RIP_90 to i16
  %512 = inttoptr i64 4196184 to double*
  %513 = load double, double* %512, align 1
  %514 = bitcast double %513 to i64
  %ZMM0_12 = load <16 x float>, <16 x float>* %ZMM0
  %515 = bitcast <16 x float> %ZMM0_12 to i512
  %XMM0_12 = trunc i512 %515 to i128
  %516 = zext i64 %514 to i128
  %517 = and i128 %XMM0_12, -18446744073709551616
  %XMM0_13 = or i128 %516, %517
  %518 = bitcast <16 x float> %ZMM0_12 to i512
  %YMM0_12 = trunc i512 %518 to i256
  %519 = zext i128 %XMM0_13 to i256
  %520 = and i256 %YMM0_12, -340282366920938463463374607431768211456
  %YMM0_13 = or i256 %519, %520
  %521 = bitcast <16 x float> %ZMM0_12 to i512
  %522 = zext i128 %XMM0_13 to i512
  %523 = and i512 %521, -340282366920938463463374607431768211456
  %ZMM0_13 = or i512 %522, %523
  %RIP_91 = add i64 %RIP_90, 5
  %EIP_78 = trunc i64 %RIP_91 to i32
  %IP_78 = trunc i64 %RIP_91 to i16
  %RBP_11 = load i64, i64* %RBP
  %524 = add i64 %RBP_11, -64
  %525 = inttoptr i64 %524 to double*
  %526 = load double, double* %525, align 1
  %527 = bitcast double %526 to i64
  %ZMM1_20 = load <16 x float>, <16 x float>* %ZMM1
  %528 = bitcast <16 x float> %ZMM1_20 to i512
  %XMM1_20 = trunc i512 %528 to i128
  %529 = zext i64 %527 to i128
  %530 = and i128 %XMM1_20, -18446744073709551616
  %XMM1_21 = or i128 %529, %530
  %531 = bitcast <16 x float> %ZMM1_20 to i512
  %YMM1_20 = trunc i512 %531 to i256
  %532 = zext i128 %XMM1_21 to i256
  %533 = and i256 %YMM1_20, -340282366920938463463374607431768211456
  %YMM1_21 = or i256 %532, %533
  %534 = bitcast <16 x float> %ZMM1_20 to i512
  %535 = zext i128 %XMM1_21 to i512
  %536 = and i512 %534, -340282366920938463463374607431768211456
  %ZMM1_21 = or i512 %535, %536
  %RIP_92 = add i64 %RIP_91, 4
  %EIP_79 = trunc i64 %RIP_92 to i32
  %IP_79 = trunc i64 %RIP_92 to i16
  %537 = trunc i128 %XMM1_21 to i64
  %538 = bitcast i64 %537 to double
  %539 = trunc i128 %XMM0_13 to i64
  %540 = bitcast i64 %539 to double
  %541 = fsub double %538, %540
  %542 = bitcast double %541 to i64
  %543 = zext i64 %542 to i128
  %544 = and i128 %XMM1_21, -18446744073709551616
  %XMM1_22 = or i128 %543, %544
  %545 = zext i128 %XMM1_22 to i256
  %546 = and i256 %YMM1_21, -340282366920938463463374607431768211456
  %YMM1_22 = or i256 %545, %546
  %547 = zext i128 %XMM1_22 to i512
  %548 = and i512 %ZMM1_21, -340282366920938463463374607431768211456
  %ZMM1_22 = or i512 %547, %548
  %RIP_93 = add i64 %RIP_92, 5
  %EIP_80 = trunc i64 %RIP_93 to i32
  %IP_80 = trunc i64 %RIP_93 to i16
  %549 = trunc i128 %XMM1_22 to i64
  %550 = bitcast i64 %549 to double
  %551 = add i64 %RBP_11, -64
  %552 = inttoptr i64 %551 to double*
  store double %550, double* %552, align 1
  %RIP_94 = add i64 %RIP_93, 3
  %EIP_81 = trunc i64 %RIP_94 to i32
  %IP_81 = trunc i64 %RIP_94 to i16
  %RAX_14 = load i64, i64* %RAX
  %EAX_10 = trunc i64 %RAX_14 to i32
  %553 = add i64 %RBP_11, -68
  %554 = inttoptr i64 %553 to i32*
  store i32 %EAX_10, i32* %554, align 1
  %RIP_95 = add i64 %RIP_94, 5
  %EIP_82 = trunc i64 %RIP_95 to i32
  %IP_82 = trunc i64 %RIP_95 to i16
  store i32 %EAX_10, i32* %EAX
  store i32 4195942, i32* %EIP
  store i16 1638, i16* %IP
  store i64 %RAX_14, i64* %RAX
  store i64 %RBP_11, i64* %RBP
  store i64 4195942, i64* %RIP
  %555 = bitcast i128 %XMM0_13 to <4 x float>
  store <4 x float> %555, <4 x float>* %XMM0
  %556 = bitcast i128 %XMM1_22 to <4 x float>
  store <4 x float> %556, <4 x float>* %XMM1
  %557 = bitcast i256 %YMM0_13 to <8 x float>
  store <8 x float> %557, <8 x float>* %YMM0
  %558 = bitcast i256 %YMM1_22 to <8 x float>
  store <8 x float> %558, <8 x float>* %YMM1
  %559 = bitcast i512 %ZMM0_13 to <16 x float>
  store <16 x float> %559, <16 x float>* %ZMM0
  %560 = bitcast i512 %ZMM1_22 to <16 x float>
  store <16 x float> %560, <16 x float>* %ZMM1
  br label %bb_400666

bb_4006AB:                                        ; preds = %bb_400666
  %RIP_98 = add i64 4196011, 5
  %EIP_84 = trunc i64 %RIP_98 to i32
  %IP_84 = trunc i64 %RIP_98 to i16
  %RBP_12 = load i64, i64* %RBP
  %561 = add i64 %RBP_12, -64
  %562 = inttoptr i64 %561 to double*
  %563 = load double, double* %562, align 1
  %564 = bitcast double %563 to i64
  %ZMM0_14 = load <16 x float>, <16 x float>* %ZMM0
  %565 = bitcast <16 x float> %ZMM0_14 to i512
  %XMM0_14 = trunc i512 %565 to i128
  %566 = zext i64 %564 to i128
  %567 = and i128 %XMM0_14, -18446744073709551616
  %XMM0_15 = or i128 %566, %567
  %568 = bitcast <16 x float> %ZMM0_14 to i512
  %YMM0_14 = trunc i512 %568 to i256
  %569 = zext i128 %XMM0_15 to i256
  %570 = and i256 %YMM0_14, -340282366920938463463374607431768211456
  %YMM0_15 = or i256 %569, %570
  %571 = bitcast <16 x float> %ZMM0_14 to i512
  %572 = zext i128 %XMM0_15 to i512
  %573 = and i512 %571, -340282366920938463463374607431768211456
  %ZMM0_15 = or i512 %572, %573
  %RIP_99 = add i64 %RIP_98, 5
  %EIP_85 = trunc i64 %RIP_99 to i32
  %IP_85 = trunc i64 %RIP_99 to i16
  %RSP_9 = load i64, i64* %RSP
  %RSP_10 = sub i64 %RSP_9, 8
  %574 = inttoptr i64 %RSP_10 to i64*
  store i64 4196021, i64* %574
  %ESP_6 = trunc i64 %RSP_10 to i32
  %SP_6 = trunc i64 %RSP_10 to i16
  %SPL_6 = trunc i64 %RSP_10 to i8
  store i32 %EIP_85, i32* %EIP
  store i32 %ESP_6, i32* %ESP
  store i16 %IP_85, i16* %IP
  store i64 %RBP_12, i64* %RBP
  store i64 %RIP_99, i64* %RIP
  store i64 %RSP_10, i64* %RSP
  store i16 %SP_6, i16* %SP
  store i8 %SPL_6, i8* %SPL
  %575 = bitcast i128 %XMM0_15 to <4 x float>
  store <4 x float> %575, <4 x float>* %XMM0
  %576 = bitcast i256 %YMM0_15 to <8 x float>
  store <8 x float> %576, <8 x float>* %YMM0
  %577 = bitcast i512 %ZMM0_15 to <16 x float>
  store <16 x float> %577, <16 x float>* %ZMM0
  %578 = load i32, i32* %CtlSysEFLAGS
  store i32 %578, i32* %CtlSysEFLAGS_ptr
  %579 = load i32, i32* %EFLAGS
  store i32 %579, i32* %EFLAGS_ptr
  %580 = load i64, i64* %RAX
  store i64 %580, i64* %RAX_ptr
  %581 = load i64, i64* %RBP
  store i64 %581, i64* %RBP_ptr
  %582 = load i64, i64* %RDI
  store i64 %582, i64* %RDI_ptr
  %583 = load i64, i64* %RIP
  store i64 %583, i64* %RIP_ptr
  %584 = load i64, i64* %RSP
  store i64 %584, i64* %RSP_ptr
  %585 = load <16 x float>, <16 x float>* %ZMM0
  store <16 x float> %585, <16 x float>* %ZMM0_ptr
  %586 = load <16 x float>, <16 x float>* %ZMM1
  store <16 x float> %586, <16 x float>* %ZMM1_ptr
  %587 = load <16 x float>, <16 x float>* %ZMM2
  store <16 x float> %587, <16 x float>* %ZMM2_ptr
  call void @fn_400530(%regset* %0)
  %588 = load i32, i32* %CtlSysEFLAGS_ptr
  store i32 %588, i32* %CtlSysEFLAGS
  %589 = load i32, i32* %EFLAGS_ptr
  store i32 %589, i32* %EFLAGS
  %590 = load i64, i64* %RAX_ptr
  store i64 %590, i64* %RAX
  %591 = load i64, i64* %RBP_ptr
  store i64 %591, i64* %RBP
  %592 = load i64, i64* %RDI_ptr
  store i64 %592, i64* %RDI
  %593 = load i64, i64* %RIP_ptr
  store i64 %593, i64* %RIP
  %594 = load i64, i64* %RSP_ptr
  store i64 %594, i64* %RSP
  %595 = load <16 x float>, <16 x float>* %ZMM0_ptr
  store <16 x float> %595, <16 x float>* %ZMM0
  %596 = load <16 x float>, <16 x float>* %ZMM1_ptr
  store <16 x float> %596, <16 x float>* %ZMM1
  %597 = load <16 x float>, <16 x float>* %ZMM2_ptr
  store <16 x float> %597, <16 x float>* %ZMM2
  %RIP_100 = load i64, i64* %RIP
  %RIP_101 = add i64 %RIP_100, 4
  %EIP_86 = trunc i64 %RIP_101 to i32
  %IP_86 = trunc i64 %RIP_101 to i16
  %ZMM0_16 = load <16 x float>, <16 x float>* %ZMM0
  %598 = bitcast <16 x float> %ZMM0_16 to i512
  %XMM0_16 = trunc i512 %598 to i128
  %599 = trunc i128 %XMM0_16 to i64
  %600 = bitcast i64 %599 to double
  %EAX_11 = fptosi double %600 to i32
  %RAX_15 = load i64, i64* %RAX
  %RAX_16 = zext i32 %EAX_11 to i64
  %AX_10 = trunc i32 %EAX_11 to i16
  %AL_9 = trunc i32 %EAX_11 to i8
  %601 = lshr i32 %EAX_11, 8
  %AH_8 = trunc i32 %601 to i8
  %RIP_102 = add i64 %RIP_101, 3
  %EIP_87 = trunc i64 %RIP_102 to i32
  %IP_87 = trunc i64 %RIP_102 to i16
  %RBP_13 = load i64, i64* %RBP
  %602 = add i64 %RBP_13, -4
  %603 = inttoptr i64 %602 to i32*
  store i32 %EAX_11, i32* %603, align 1
  store i8 %AH_8, i8* %AH
  store i8 %AL_9, i8* %AL
  store i16 %AX_10, i16* %AX
  store i32 %EAX_11, i32* %EAX
  store i32 %EIP_87, i32* %EIP
  store i16 %IP_87, i16* %IP
  store i64 %RAX_16, i64* %RAX
  store i64 %RBP_13, i64* %RBP
  store i64 %RIP_102, i64* %RIP
  %604 = bitcast i128 %XMM0_16 to <4 x float>
  store <4 x float> %604, <4 x float>* %XMM0
  store <16 x float> %ZMM0_16, <16 x float>* %ZMM0
  br label %bb_4006BC

bb_4006BC:                                        ; preds = %bb_4006AB, %bb_400654, %bb_400623, %bb_4005EA
  %RIP_44 = add i64 4196028, 3
  %EIP_40 = trunc i64 %RIP_44 to i32
  %IP_40 = trunc i64 %RIP_44 to i16
  %RBP_3 = load i64, i64* %RBP
  %605 = add i64 %RBP_3, -4
  %606 = inttoptr i64 %605 to i32*
  %EAX_3 = load i32, i32* %606, align 1
  %RAX_4 = load i64, i64* %RAX
  %RAX_5 = zext i32 %EAX_3 to i64
  %AX_3 = trunc i32 %EAX_3 to i16
  %AL_3 = trunc i32 %EAX_3 to i8
  %607 = lshr i32 %EAX_3, 8
  %AH_3 = trunc i32 %607 to i8
  %RIP_45 = add i64 %RIP_44, 4
  %EIP_41 = trunc i64 %RIP_45 to i32
  %IP_41 = trunc i64 %RIP_45 to i16
  %RSP_3 = load i64, i64* %RSP
  %RSP_4 = add i64 %RSP_3, 80
  %ESP_2 = trunc i64 %RSP_4 to i32
  %SP_2 = trunc i64 %RSP_4 to i16
  %SPL_2 = trunc i64 %RSP_4 to i8
  %EFLAGS_3 = load i32, i32* %EFLAGS
  %RIP_46 = add i64 %RIP_45, 1
  %EIP_42 = trunc i64 %RIP_46 to i32
  %IP_42 = trunc i64 %RIP_46 to i16
  %RSP_5 = add i64 %RSP_4, 8
  %ESP_3 = trunc i64 %RSP_5 to i32
  %SP_3 = trunc i64 %RSP_5 to i16
  %SPL_3 = trunc i64 %RSP_5 to i8
  %608 = sub i64 %RSP_5, 8
  %609 = inttoptr i64 %608 to i64*
  %RBP_4 = load i64, i64* %609, align 1
  %EBP_1 = trunc i64 %RBP_4 to i32
  %BP_1 = trunc i64 %RBP_4 to i16
  %BPL_1 = trunc i64 %RBP_4 to i8
  %RIP_47 = add i64 %RIP_46, 1
  %EIP_43 = trunc i64 %RIP_47 to i32
  %IP_43 = trunc i64 %RIP_47 to i16
  %RSP_6 = add i64 %RSP_5, 8
  %610 = inttoptr i64 %RSP_5 to i64*
  %RIP_48 = load i64, i64* %610
  %ESP_4 = trunc i64 %RSP_6 to i32
  %SP_4 = trunc i64 %RSP_6 to i16
  %SPL_4 = trunc i64 %RSP_6 to i8
  %EIP_44 = trunc i64 %RIP_48 to i32
  %IP_44 = trunc i64 %RIP_48 to i16
  %ZF_04 = icmp eq i64 %RSP_4, 0
  %SF_0 = icmp slt i64 %RSP_4, 0
  %611 = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %RSP_3, i64 80)
  %OF_0 = extractvalue { i64, i1 } %611, 1
  %612 = call { i64, i1 } @llvm.uadd.with.overflow.i64(i64 %RSP_3, i64 80)
  %CF_05 = extractvalue { i64, i1 } %612, 1
  %613 = trunc i64 %RSP_4 to i8
  %614 = call i8 @llvm.ctpop.i8(i8 %613)
  %615 = trunc i8 %614 to i1
  %PF_06 = icmp eq i1 %615, false
  %CtlSysEFLAGS_2 = load i32, i32* %CtlSysEFLAGS
  %616 = zext i1 %CF_05 to i32
  %617 = shl i32 %616, 0
  %618 = or i32 %617, %CtlSysEFLAGS_2
  %619 = zext i1 %PF_06 to i32
  %620 = shl i32 %619, 2
  %621 = or i32 %620, %618
  %622 = zext i1 false to i32
  %623 = shl i32 %622, 4
  %624 = or i32 %623, %621
  %625 = zext i1 %ZF_04 to i32
  %626 = shl i32 %625, 6
  %627 = or i32 %626, %624
  %628 = zext i1 %SF_0 to i32
  %629 = shl i32 %628, 7
  %630 = or i32 %629, %627
  %631 = zext i1 %OF_0 to i32
  %632 = shl i32 %631, 11
  %EFLAGS_4 = or i32 %632, %630
  store i8 %AH_3, i8* %AH
  store i8 %AL_3, i8* %AL
  store i16 %AX_3, i16* %AX
  store i16 %BP_1, i16* %BP
  store i8 %BPL_1, i8* %BPL
  store i32 %CtlSysEFLAGS_2, i32* %CtlSysEFLAGS
  store i32 %EAX_3, i32* %EAX
  store i32 %EBP_1, i32* %EBP
  store i32 %EFLAGS_4, i32* %EFLAGS
  store i32 %EIP_44, i32* %EIP
  store i32 %ESP_4, i32* %ESP
  store i16 %IP_44, i16* %IP
  store i64 %RAX_5, i64* %RAX
  store i64 %RBP_4, i64* %RBP
  store i64 %RIP_48, i64* %RIP
  store i64 %RSP_6, i64* %RSP
  store i16 %SP_4, i16* %SP
  store i8 %SPL_4, i8* %SPL
  br label %exit_fn_400550
}

; Function Attrs: noreturn nounwind
declare void @llvm.trap() #0

; Function Attrs: nounwind readnone speculatable
declare { i64, i1 } @llvm.sadd.with.overflow.i64(i64, i64) #1

; Function Attrs: nounwind readnone speculatable
declare { i64, i1 } @llvm.uadd.with.overflow.i64(i64, i64) #1

; Function Attrs: nounwind readnone speculatable
declare i8 @llvm.ctpop.i8(i8) #1

define void @fn_400410(%regset* noalias nocapture) {
entry_fn_400410:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  br label %bb_400410

exit_fn_400410:                                   ; preds = %bb_400410
  %1 = load i64, i64* %RIP
  store i64 %1, i64* %RIP_ptr
  ret void

bb_400410:                                        ; preds = %entry_fn_400410
  %RIP_1 = add i64 4195344, 6
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %2 = add i64 %RIP_1, 2100226
  %3 = inttoptr i64 %2 to i64*
  %RIP_2 = load i64, i64* %3, align 1
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  %4 = inttoptr i64 %RIP_2 to i8*
  %5 = call i8* @llvm.dc.translate.at(i8* %4)
  %6 = bitcast i8* %5 to void (%regset*)*
  store i32 %EIP_1, i32* %EIP
  store i16 %IP_1, i16* %IP
  store i64 %RIP_2, i64* %RIP
  %7 = load i64, i64* %RIP
  store i64 %7, i64* %RIP_ptr
  call void %6(%regset* %0)
  %8 = load i64, i64* %RIP_ptr
  store i64 %8, i64* %RIP
  br label %exit_fn_400410
}

define void @fn_400530(%regset* noalias nocapture) {
entry_fn_400530:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  %RBP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 9
  %RBP_init = load i64, i64* %RBP_ptr
  %RBP = alloca i64
  store i64 %RBP_init, i64* %RBP
  %RSP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 16
  %RSP_init = load i64, i64* %RSP_ptr
  %RSP = alloca i64
  store i64 %RSP_init, i64* %RSP
  %ESP_init = trunc i64 %RSP_init to i32
  %ESP = alloca i32
  store i32 %ESP_init, i32* %ESP
  %SP_init = trunc i64 %RSP_init to i16
  %SP = alloca i16
  store i16 %SP_init, i16* %SP
  %SPL_init = trunc i64 %RSP_init to i8
  %SPL = alloca i8
  store i8 %SPL_init, i8* %SPL
  %EBP_init = trunc i64 %RBP_init to i32
  %EBP = alloca i32
  store i32 %EBP_init, i32* %EBP
  %BP_init = trunc i64 %RBP_init to i16
  %BP = alloca i16
  store i16 %BP_init, i16* %BP
  %BPL_init = trunc i64 %RBP_init to i8
  %BPL = alloca i8
  store i8 %BPL_init, i8* %BPL
  %ZMM1_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 86
  %ZMM1_init = load <16 x float>, <16 x float>* %ZMM1_ptr
  %ZMM1 = alloca <16 x float>
  store <16 x float> %ZMM1_init, <16 x float>* %ZMM1
  %1 = bitcast <16 x float> %ZMM1_init to i512
  %2 = trunc i512 %1 to i128
  %XMM1_init = bitcast i128 %2 to <4 x float>
  %XMM1 = alloca <4 x float>
  store <4 x float> %XMM1_init, <4 x float>* %XMM1
  %3 = bitcast <16 x float> %ZMM1_init to i512
  %4 = trunc i512 %3 to i256
  %YMM1_init = bitcast i256 %4 to <8 x float>
  %YMM1 = alloca <8 x float>
  store <8 x float> %YMM1_init, <8 x float>* %YMM1
  %ZMM0_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 85
  %ZMM0_init = load <16 x float>, <16 x float>* %ZMM0_ptr
  %ZMM0 = alloca <16 x float>
  store <16 x float> %ZMM0_init, <16 x float>* %ZMM0
  %5 = bitcast <16 x float> %ZMM0_init to i512
  %6 = trunc i512 %5 to i128
  %XMM0_init = bitcast i128 %6 to <4 x float>
  %XMM0 = alloca <4 x float>
  store <4 x float> %XMM0_init, <4 x float>* %XMM0
  %7 = bitcast <16 x float> %ZMM0_init to i512
  %8 = trunc i512 %7 to i256
  %YMM0_init = bitcast i256 %8 to <8 x float>
  %YMM0 = alloca <8 x float>
  store <8 x float> %YMM0_init, <8 x float>* %YMM0
  br label %bb_400530

exit_fn_400530:                                   ; preds = %bb_400530
  %9 = load i64, i64* %RBP
  store i64 %9, i64* %RBP_ptr
  %10 = load i64, i64* %RIP
  store i64 %10, i64* %RIP_ptr
  %11 = load i64, i64* %RSP
  store i64 %11, i64* %RSP_ptr
  %12 = load <16 x float>, <16 x float>* %ZMM0
  store <16 x float> %12, <16 x float>* %ZMM0_ptr
  %13 = load <16 x float>, <16 x float>* %ZMM1
  store <16 x float> %13, <16 x float>* %ZMM1_ptr
  ret void

bb_400530:                                        ; preds = %entry_fn_400530
  %RIP_1 = add i64 4195632, 1
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %RBP_0 = load i64, i64* %RBP
  %RSP_0 = load i64, i64* %RSP
  %14 = sub i64 %RSP_0, 8
  %15 = inttoptr i64 %14 to i64*
  store i64 %RBP_0, i64* %15, align 1
  %RSP_1 = sub i64 %RSP_0, 8
  %ESP_0 = trunc i64 %RSP_1 to i32
  %SP_0 = trunc i64 %RSP_1 to i16
  %SPL_0 = trunc i64 %RSP_1 to i8
  %RIP_2 = add i64 %RIP_1, 3
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  %EBP_0 = trunc i64 %RSP_1 to i32
  %BP_0 = trunc i64 %RSP_1 to i16
  %BPL_0 = trunc i64 %RSP_1 to i8
  %RIP_3 = add i64 %RIP_2, 3
  %EIP_2 = trunc i64 %RIP_3 to i32
  %IP_2 = trunc i64 %RIP_3 to i16
  %ZMM1_0 = load <16 x float>, <16 x float>* %ZMM1
  %16 = bitcast <16 x float> %ZMM1_0 to i512
  %XMM1_0 = trunc i512 %16 to i128
  %17 = bitcast i128 %XMM1_0 to <4 x float>
  %18 = bitcast <4 x float> %17 to <2 x i64>
  %19 = bitcast i128 %XMM1_0 to <4 x float>
  %20 = bitcast <4 x float> %19 to <2 x i64>
  %21 = xor <2 x i64> %18, %20
  %XMM1_1 = bitcast <2 x i64> %21 to i128
  %22 = bitcast <16 x float> %ZMM1_0 to i512
  %YMM1_0 = trunc i512 %22 to i256
  %23 = zext i128 %XMM1_1 to i256
  %24 = and i256 %YMM1_0, -340282366920938463463374607431768211456
  %YMM1_1 = or i256 %23, %24
  %25 = bitcast <16 x float> %ZMM1_0 to i512
  %26 = zext i128 %XMM1_1 to i512
  %27 = and i512 %25, -340282366920938463463374607431768211456
  %ZMM1_1 = or i512 %26, %27
  %RIP_4 = add i64 %RIP_3, 5
  %EIP_3 = trunc i64 %RIP_4 to i32
  %IP_3 = trunc i64 %RIP_4 to i16
  %ZMM0_0 = load <16 x float>, <16 x float>* %ZMM0
  %28 = bitcast <16 x float> %ZMM0_0 to i512
  %XMM0_0 = trunc i512 %28 to i128
  %29 = trunc i128 %XMM0_0 to i64
  %30 = bitcast i64 %29 to double
  %31 = add i64 %RSP_1, -8
  %32 = inttoptr i64 %31 to double*
  store double %30, double* %32, align 1
  %RIP_5 = add i64 %RIP_4, 3
  %EIP_4 = trunc i64 %RIP_5 to i32
  %IP_4 = trunc i64 %RIP_5 to i16
  %33 = bitcast i128 %XMM1_1 to <4 x float>
  %XMM0_1 = bitcast <4 x float> %33 to i128
  %34 = bitcast <16 x float> %ZMM0_0 to i512
  %YMM0_0 = trunc i512 %34 to i256
  %35 = zext i128 %XMM0_1 to i256
  %36 = and i256 %YMM0_0, -340282366920938463463374607431768211456
  %YMM0_1 = or i256 %35, %36
  %37 = bitcast <16 x float> %ZMM0_0 to i512
  %38 = zext i128 %XMM0_1 to i512
  %39 = and i512 %37, -340282366920938463463374607431768211456
  %ZMM0_1 = or i512 %38, %39
  %RIP_6 = add i64 %RIP_5, 1
  %EIP_5 = trunc i64 %RIP_6 to i32
  %IP_5 = trunc i64 %RIP_6 to i16
  %RSP_2 = add i64 %RSP_1, 8
  %ESP_1 = trunc i64 %RSP_2 to i32
  %SP_1 = trunc i64 %RSP_2 to i16
  %SPL_1 = trunc i64 %RSP_2 to i8
  %40 = sub i64 %RSP_2, 8
  %41 = inttoptr i64 %40 to i64*
  %RBP_1 = load i64, i64* %41, align 1
  %EBP_1 = trunc i64 %RBP_1 to i32
  %BP_1 = trunc i64 %RBP_1 to i16
  %BPL_1 = trunc i64 %RBP_1 to i8
  %RIP_7 = add i64 %RIP_6, 1
  %EIP_6 = trunc i64 %RIP_7 to i32
  %IP_6 = trunc i64 %RIP_7 to i16
  %RSP_3 = add i64 %RSP_2, 8
  %42 = inttoptr i64 %RSP_2 to i64*
  %RIP_8 = load i64, i64* %42
  %ESP_2 = trunc i64 %RSP_3 to i32
  %SP_2 = trunc i64 %RSP_3 to i16
  %SPL_2 = trunc i64 %RSP_3 to i8
  %EIP_7 = trunc i64 %RIP_8 to i32
  %IP_7 = trunc i64 %RIP_8 to i16
  store i16 %BP_1, i16* %BP
  store i8 %BPL_1, i8* %BPL
  store i32 %EBP_1, i32* %EBP
  store i32 %EIP_7, i32* %EIP
  store i32 %ESP_2, i32* %ESP
  store i16 %IP_7, i16* %IP
  store i64 %RBP_1, i64* %RBP
  store i64 %RIP_8, i64* %RIP
  store i64 %RSP_3, i64* %RSP
  store i16 %SP_2, i16* %SP
  store i8 %SPL_2, i8* %SPL
  %43 = bitcast i128 %XMM0_1 to <4 x float>
  store <4 x float> %43, <4 x float>* %XMM0
  %44 = bitcast i128 %XMM1_1 to <4 x float>
  store <4 x float> %44, <4 x float>* %XMM1
  %45 = bitcast i256 %YMM0_1 to <8 x float>
  store <8 x float> %45, <8 x float>* %YMM0
  %46 = bitcast i256 %YMM1_1 to <8 x float>
  store <8 x float> %46, <8 x float>* %YMM1
  %47 = bitcast i512 %ZMM0_1 to <16 x float>
  store <16 x float> %47, <16 x float>* %ZMM0
  %48 = bitcast i512 %ZMM1_1 to <16 x float>
  store <16 x float> %48, <16 x float>* %ZMM1
  br label %exit_fn_400530
}

; Function Attrs: nounwind
declare i8* @llvm.dc.translate.at(i8*) #2

define i32 @main(i32, i8**) {
  %3 = alloca %regset, align 64
  %4 = alloca [1024 x i8], align 64
  %5 = getelementptr inbounds [1024 x i8], [1024 x i8]* %4, i32 0, i32 0
  call void @main_init_regset(%regset* %3, i8* %5, i32 1024, i32 %0, i8** %1)
  call void @fn_400550(%regset* %3)
  %6 = call i32 @main_fini_regset(%regset* %3)
  ret i32 %6
}

define void @main_init_regset(%regset*, i8*, i32, i32, i8**) {
  %6 = ptrtoint i8* %1 to i64
  %7 = zext i32 %2 to i64
  %8 = add i64 %6, %7
  %9 = sub i64 %8, 8
  %10 = inttoptr i64 %9 to i64*
  store i64 -1, i64* %10
  %11 = getelementptr inbounds %regset, %regset* %0, i32 0, i32 16
  store i64 %9, i64* %11
  %12 = zext i32 %3 to i64
  %13 = getelementptr inbounds %regset, %regset* %0, i32 0, i32 12
  store i64 %12, i64* %13
  %14 = ptrtoint i8** %4 to i64
  %15 = getelementptr inbounds %regset, %regset* %0, i32 0, i32 15
  store i64 %14, i64* %15
  %16 = getelementptr inbounds %regset, %regset* %0, i32 0, i32 3
  store i32 514, i32* %16
  %17 = getelementptr inbounds %regset, %regset* %0, i32 0, i32 1
  store i32 514, i32* %17
  ret void
}

define i32 @main_fini_regset(%regset*) {
  %2 = getelementptr inbounds %regset, %regset* %0, i32 0, i32 8
  %3 = load i64, i64* %2
  %4 = trunc i64 %3 to i32
  ret i32 %4
}

define void @fn_400470(%regset* noalias nocapture) {
entry_fn_400470:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  %RAX_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 8
  %RAX_init = load i64, i64* %RAX_ptr
  %RAX = alloca i64
  store i64 %RAX_init, i64* %RAX
  %EAX_init = trunc i64 %RAX_init to i32
  %EAX = alloca i32
  store i32 %EAX_init, i32* %EAX
  %AX_init = trunc i64 %RAX_init to i16
  %AX = alloca i16
  store i16 %AX_init, i16* %AX
  %AL_init = trunc i64 %RAX_init to i8
  %AL = alloca i8
  store i8 %AL_init, i8* %AL
  %1 = lshr i64 %RAX_init, 8
  %AH_init = trunc i64 %1 to i8
  %AH = alloca i8
  store i8 %AH_init, i8* %AH
  %RBP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 9
  %RBP_init = load i64, i64* %RBP_ptr
  %RBP = alloca i64
  store i64 %RBP_init, i64* %RBP
  %RSP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 16
  %RSP_init = load i64, i64* %RSP_ptr
  %RSP = alloca i64
  store i64 %RSP_init, i64* %RSP
  %ESP_init = trunc i64 %RSP_init to i32
  %ESP = alloca i32
  store i32 %ESP_init, i32* %ESP
  %SP_init = trunc i64 %RSP_init to i16
  %SP = alloca i16
  store i16 %SP_init, i16* %SP
  %SPL_init = trunc i64 %RSP_init to i8
  %SPL = alloca i8
  store i8 %SPL_init, i8* %SPL
  %EFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 3
  %EFLAGS_init = load i32, i32* %EFLAGS_ptr
  %EFLAGS = alloca i32
  store i32 %EFLAGS_init, i32* %EFLAGS
  %CtlSysEFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 1
  %CtlSysEFLAGS_init = load i32, i32* %CtlSysEFLAGS_ptr
  %CtlSysEFLAGS = alloca i32
  store i32 %CtlSysEFLAGS_init, i32* %CtlSysEFLAGS
  %EBP_init = trunc i64 %RBP_init to i32
  %EBP = alloca i32
  store i32 %EBP_init, i32* %EBP
  %BP_init = trunc i64 %RBP_init to i16
  %BP = alloca i16
  store i16 %BP_init, i16* %BP
  %BPL_init = trunc i64 %RBP_init to i8
  %BPL = alloca i8
  store i8 %BPL_init, i8* %BPL
  %RDI_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 12
  %RDI_init = load i64, i64* %RDI_ptr
  %RDI = alloca i64
  store i64 %RDI_init, i64* %RDI
  %EDI_init = trunc i64 %RDI_init to i32
  %EDI = alloca i32
  store i32 %EDI_init, i32* %EDI
  %DI_init = trunc i64 %RDI_init to i16
  %DI = alloca i16
  store i16 %DI_init, i16* %DI
  %DIL_init = trunc i64 %RDI_init to i8
  %DIL = alloca i8
  store i8 %DIL_init, i8* %DIL
  br label %bb_400470

exit_fn_400470:                                   ; preds = %bb_400491, %bb_400485
  %2 = load i32, i32* %CtlSysEFLAGS
  store i32 %2, i32* %CtlSysEFLAGS_ptr
  %3 = load i32, i32* %EFLAGS
  store i32 %3, i32* %EFLAGS_ptr
  %4 = load i64, i64* %RAX
  store i64 %4, i64* %RAX_ptr
  %5 = load i64, i64* %RBP
  store i64 %5, i64* %RBP_ptr
  %6 = load i64, i64* %RDI
  store i64 %6, i64* %RDI_ptr
  %7 = load i64, i64* %RIP
  store i64 %7, i64* %RIP_ptr
  %8 = load i64, i64* %RSP
  store i64 %8, i64* %RSP_ptr
  ret void

bb_400470:                                        ; preds = %entry_fn_400470
  %RIP_1 = add i64 4195440, 5
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %RAX_0 = load i64, i64* %RAX
  %RIP_2 = add i64 %RIP_1, 1
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  %RBP_0 = load i64, i64* %RBP
  %RSP_0 = load i64, i64* %RSP
  %9 = sub i64 %RSP_0, 8
  %10 = inttoptr i64 %9 to i64*
  store i64 %RBP_0, i64* %10, align 1
  %RSP_1 = sub i64 %RSP_0, 8
  %ESP_0 = trunc i64 %RSP_1 to i32
  %SP_0 = trunc i64 %RSP_1 to i16
  %SPL_0 = trunc i64 %RSP_1 to i8
  %RIP_3 = add i64 %RIP_2, 6
  %EIP_2 = trunc i64 %RIP_3 to i32
  %IP_2 = trunc i64 %RIP_3 to i16
  %RAX_2 = sub i64 6295623, 6295616
  %EAX_1 = trunc i64 %RAX_2 to i32
  %AX_1 = trunc i64 %RAX_2 to i16
  %AL_1 = trunc i64 %RAX_2 to i8
  %11 = lshr i64 %RAX_2, 8
  %AH_1 = trunc i64 %11 to i8
  %EFLAGS_0 = load i32, i32* %EFLAGS
  %RIP_4 = add i64 %RIP_3, 4
  %EIP_3 = trunc i64 %RIP_4 to i32
  %IP_3 = trunc i64 %RIP_4 to i16
  %CC_A_0 = icmp ugt i64 %RAX_2, 14
  %CC_AE_0 = icmp uge i64 %RAX_2, 14
  %CC_B_0 = icmp ult i64 %RAX_2, 14
  %CC_BE_0 = icmp ule i64 %RAX_2, 14
  %CC_L_0 = icmp slt i64 %RAX_2, 14
  %CC_LE_0 = icmp sle i64 %RAX_2, 14
  %CC_G_0 = icmp sgt i64 %RAX_2, 14
  %CC_GE_0 = icmp sge i64 %RAX_2, 14
  %CC_E_0 = icmp eq i64 %RAX_2, 14
  %CC_NE_0 = icmp ne i64 %RAX_2, 14
  %12 = sub i64 %RAX_2, 14
  %ZF_0 = icmp eq i64 %12, 0
  %SF_0 = icmp slt i64 %12, 0
  %13 = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 %RAX_2, i64 14)
  %OF_0 = extractvalue { i64, i1 } %13, 1
  %14 = call { i64, i1 } @llvm.usub.with.overflow.i64(i64 %RAX_2, i64 14)
  %CF_0 = extractvalue { i64, i1 } %14, 1
  %15 = trunc i64 %12 to i8
  %16 = call i8 @llvm.ctpop.i8(i8 %15)
  %17 = trunc i8 %16 to i1
  %PF_0 = icmp eq i1 %17, false
  %CtlSysEFLAGS_0 = load i32, i32* %CtlSysEFLAGS
  %18 = zext i1 %CF_0 to i32
  %19 = shl i32 %18, 0
  %20 = or i32 %19, %CtlSysEFLAGS_0
  %21 = zext i1 %PF_0 to i32
  %22 = shl i32 %21, 2
  %23 = or i32 %22, %20
  %24 = zext i1 false to i32
  %25 = shl i32 %24, 4
  %26 = or i32 %25, %23
  %27 = zext i1 %ZF_0 to i32
  %28 = shl i32 %27, 6
  %29 = or i32 %28, %26
  %30 = zext i1 %SF_0 to i32
  %31 = shl i32 %30, 7
  %32 = or i32 %31, %29
  %33 = zext i1 %OF_0 to i32
  %34 = shl i32 %33, 11
  %EFLAGS_1 = or i32 %34, %32
  %RIP_5 = add i64 %RIP_4, 3
  %EIP_4 = trunc i64 %RIP_5 to i32
  %IP_4 = trunc i64 %RIP_5 to i16
  %EBP_0 = trunc i64 %RSP_1 to i32
  %BP_0 = trunc i64 %RSP_1 to i16
  %BPL_0 = trunc i64 %RSP_1 to i8
  %RIP_6 = add i64 %RIP_5, 2
  %EIP_5 = trunc i64 %RIP_6 to i32
  %IP_5 = trunc i64 %RIP_6 to i16
  store i8 %AH_1, i8* %AH
  store i8 %AL_1, i8* %AL
  store i16 %AX_1, i16* %AX
  store i16 %BP_0, i16* %BP
  store i8 %BPL_0, i8* %BPL
  store i32 %CtlSysEFLAGS_0, i32* %CtlSysEFLAGS
  store i32 %EAX_1, i32* %EAX
  store i32 %EBP_0, i32* %EBP
  store i32 %EFLAGS_1, i32* %EFLAGS
  store i32 4195463, i32* %EIP
  store i32 %ESP_0, i32* %ESP
  store i16 1159, i16* %IP
  store i64 %RAX_2, i64* %RAX
  store i64 %RSP_1, i64* %RBP
  store i64 4195463, i64* %RIP
  store i64 %RSP_1, i64* %RSP
  store i16 %SP_0, i16* %SP
  store i8 %SPL_0, i8* %SPL
  br i1 %CC_A_0, label %bb_400487, label %bb_400485

bb_400485:                                        ; preds = %bb_400487, %bb_400470
  %RIP_9 = add i64 4195461, 1
  %EIP_7 = trunc i64 %RIP_9 to i32
  %IP_7 = trunc i64 %RIP_9 to i16
  %RSP_2 = load i64, i64* %RSP
  %RSP_3 = add i64 %RSP_2, 8
  %ESP_1 = trunc i64 %RSP_3 to i32
  %SP_1 = trunc i64 %RSP_3 to i16
  %SPL_1 = trunc i64 %RSP_3 to i8
  %35 = sub i64 %RSP_3, 8
  %36 = inttoptr i64 %35 to i64*
  %RBP_1 = load i64, i64* %36, align 1
  %EBP_1 = trunc i64 %RBP_1 to i32
  %BP_1 = trunc i64 %RBP_1 to i16
  %BPL_1 = trunc i64 %RBP_1 to i8
  %RIP_10 = add i64 %RIP_9, 1
  %EIP_8 = trunc i64 %RIP_10 to i32
  %IP_8 = trunc i64 %RIP_10 to i16
  %RSP_4 = add i64 %RSP_3, 8
  %37 = inttoptr i64 %RSP_3 to i64*
  %RIP_11 = load i64, i64* %37
  %ESP_2 = trunc i64 %RSP_4 to i32
  %SP_2 = trunc i64 %RSP_4 to i16
  %SPL_2 = trunc i64 %RSP_4 to i8
  %EIP_9 = trunc i64 %RIP_11 to i32
  %IP_9 = trunc i64 %RIP_11 to i16
  store i16 %BP_1, i16* %BP
  store i8 %BPL_1, i8* %BPL
  store i32 %EBP_1, i32* %EBP
  store i32 %EIP_9, i32* %EIP
  store i32 %ESP_2, i32* %ESP
  store i16 %IP_9, i16* %IP
  store i64 %RBP_1, i64* %RBP
  store i64 %RIP_11, i64* %RIP
  store i64 %RSP_4, i64* %RSP
  store i16 %SP_2, i16* %SP
  store i8 %SPL_2, i8* %SPL
  br label %exit_fn_400470

bb_400487:                                        ; preds = %bb_400470
  %RIP_13 = add i64 4195463, 5
  %EIP_10 = trunc i64 %RIP_13 to i32
  %IP_10 = trunc i64 %RIP_13 to i16
  %RAX_3 = load i64, i64* %RAX
  %RIP_14 = add i64 %RIP_13, 3
  %EIP_11 = trunc i64 %RIP_14 to i32
  %IP_11 = trunc i64 %RIP_14 to i16
  %38 = and i64 0, 0
  %CC_A_01 = icmp ugt i64 %38, 0
  %CC_AE_02 = icmp uge i64 %38, 0
  %CC_B_03 = icmp ult i64 %38, 0
  %CC_BE_04 = icmp ule i64 %38, 0
  %CC_L_05 = icmp slt i64 %38, 0
  %CC_LE_06 = icmp sle i64 %38, 0
  %CC_G_07 = icmp sgt i64 %38, 0
  %CC_GE_08 = icmp sge i64 %38, 0
  %CC_E_09 = icmp eq i64 %38, 0
  %CC_NE_010 = icmp ne i64 %38, 0
  %39 = sub i64 %38, 0
  %ZF_011 = icmp eq i64 %39, 0
  %SF_012 = icmp slt i64 %39, 0
  %40 = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 %38, i64 0)
  %OF_013 = extractvalue { i64, i1 } %40, 1
  %41 = call { i64, i1 } @llvm.usub.with.overflow.i64(i64 %38, i64 0)
  %CF_014 = extractvalue { i64, i1 } %41, 1
  %42 = trunc i64 %39 to i8
  %43 = call i8 @llvm.ctpop.i8(i8 %42)
  %44 = trunc i8 %43 to i1
  %PF_015 = icmp eq i1 %44, false
  %CtlSysEFLAGS_1 = load i32, i32* %CtlSysEFLAGS
  %45 = zext i1 %CF_014 to i32
  %46 = shl i32 %45, 0
  %47 = or i32 %46, %CtlSysEFLAGS_1
  %48 = zext i1 %PF_015 to i32
  %49 = shl i32 %48, 2
  %50 = or i32 %49, %47
  %51 = zext i1 false to i32
  %52 = shl i32 %51, 4
  %53 = or i32 %52, %50
  %54 = zext i1 %ZF_011 to i32
  %55 = shl i32 %54, 6
  %56 = or i32 %55, %53
  %57 = zext i1 %SF_012 to i32
  %58 = shl i32 %57, 7
  %59 = or i32 %58, %56
  %60 = zext i1 %OF_013 to i32
  %61 = shl i32 %60, 11
  %EFLAGS_2 = or i32 %61, %59
  %RIP_15 = add i64 %RIP_14, 2
  %EIP_12 = trunc i64 %RIP_15 to i32
  %IP_12 = trunc i64 %RIP_15 to i16
  store i8 0, i8* %AH
  store i8 0, i8* %AL
  store i16 0, i16* %AX
  store i32 %CtlSysEFLAGS_1, i32* %CtlSysEFLAGS
  store i32 0, i32* %EAX
  store i32 %EFLAGS_2, i32* %EFLAGS
  store i32 4195461, i32* %EIP
  store i16 1157, i16* %IP
  store i64 0, i64* %RAX
  store i64 4195461, i64* %RIP
  br i1 %CC_E_09, label %bb_400485, label %bb_400491

bb_400491:                                        ; preds = %bb_400487
  %RIP_18 = add i64 4195473, 1
  %EIP_14 = trunc i64 %RIP_18 to i32
  %IP_14 = trunc i64 %RIP_18 to i16
  %RSP_5 = load i64, i64* %RSP
  %RSP_6 = add i64 %RSP_5, 8
  %ESP_3 = trunc i64 %RSP_6 to i32
  %SP_3 = trunc i64 %RSP_6 to i16
  %SPL_3 = trunc i64 %RSP_6 to i8
  %62 = sub i64 %RSP_6, 8
  %63 = inttoptr i64 %62 to i64*
  %RBP_2 = load i64, i64* %63, align 1
  %EBP_2 = trunc i64 %RBP_2 to i32
  %BP_2 = trunc i64 %RBP_2 to i16
  %BPL_2 = trunc i64 %RBP_2 to i8
  %RIP_19 = add i64 %RIP_18, 5
  %EIP_15 = trunc i64 %RIP_19 to i32
  %IP_15 = trunc i64 %RIP_19 to i16
  %RDI_0 = load i64, i64* %RDI
  %RIP_20 = add i64 %RIP_19, 2
  %EIP_16 = trunc i64 %RIP_20 to i32
  %IP_16 = trunc i64 %RIP_20 to i16
  %RAX_5 = load i64, i64* %RAX
  %EIP_17 = trunc i64 %RAX_5 to i32
  %IP_17 = trunc i64 %RAX_5 to i16
  %64 = inttoptr i64 %RAX_5 to i8*
  %65 = call i8* @llvm.dc.translate.at(i8* %64)
  %66 = bitcast i8* %65 to void (%regset*)*
  store i16 %BP_2, i16* %BP
  store i8 %BPL_2, i8* %BPL
  store i16 4160, i16* %DI
  store i8 64, i8* %DIL
  store i32 %EBP_2, i32* %EBP
  store i32 6295616, i32* %EDI
  store i32 %EIP_17, i32* %EIP
  store i32 %ESP_3, i32* %ESP
  store i16 %IP_17, i16* %IP
  store i64 %RAX_5, i64* %RAX
  store i64 %RBP_2, i64* %RBP
  store i64 6295616, i64* %RDI
  store i64 %RAX_5, i64* %RIP
  store i64 %RSP_6, i64* %RSP
  store i16 %SP_3, i16* %SP
  store i8 %SPL_3, i8* %SPL
  %67 = load i32, i32* %CtlSysEFLAGS
  store i32 %67, i32* %CtlSysEFLAGS_ptr
  %68 = load i32, i32* %EFLAGS
  store i32 %68, i32* %EFLAGS_ptr
  %69 = load i64, i64* %RAX
  store i64 %69, i64* %RAX_ptr
  %70 = load i64, i64* %RBP
  store i64 %70, i64* %RBP_ptr
  %71 = load i64, i64* %RDI
  store i64 %71, i64* %RDI_ptr
  %72 = load i64, i64* %RIP
  store i64 %72, i64* %RIP_ptr
  %73 = load i64, i64* %RSP
  store i64 %73, i64* %RSP_ptr
  call void %66(%regset* %0)
  %74 = load i32, i32* %CtlSysEFLAGS_ptr
  store i32 %74, i32* %CtlSysEFLAGS
  %75 = load i32, i32* %EFLAGS_ptr
  store i32 %75, i32* %EFLAGS
  %76 = load i64, i64* %RAX_ptr
  store i64 %76, i64* %RAX
  %77 = load i64, i64* %RBP_ptr
  store i64 %77, i64* %RBP
  %78 = load i64, i64* %RDI_ptr
  store i64 %78, i64* %RDI
  %79 = load i64, i64* %RIP_ptr
  store i64 %79, i64* %RIP
  %80 = load i64, i64* %RSP_ptr
  store i64 %80, i64* %RSP
  br label %exit_fn_400470
}

; Function Attrs: nounwind readnone speculatable
declare { i64, i1 } @llvm.ssub.with.overflow.i64(i64, i64) #1

; Function Attrs: nounwind readnone speculatable
declare { i64, i1 } @llvm.usub.with.overflow.i64(i64, i64) #1

define void @fn_4004A0(%regset* noalias nocapture) {
entry_fn_4004A0:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  %RAX_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 8
  %RAX_init = load i64, i64* %RAX_ptr
  %RAX = alloca i64
  store i64 %RAX_init, i64* %RAX
  %EAX_init = trunc i64 %RAX_init to i32
  %EAX = alloca i32
  store i32 %EAX_init, i32* %EAX
  %AX_init = trunc i64 %RAX_init to i16
  %AX = alloca i16
  store i16 %AX_init, i16* %AX
  %AL_init = trunc i64 %RAX_init to i8
  %AL = alloca i8
  store i8 %AL_init, i8* %AL
  %1 = lshr i64 %RAX_init, 8
  %AH_init = trunc i64 %1 to i8
  %AH = alloca i8
  store i8 %AH_init, i8* %AH
  %RBP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 9
  %RBP_init = load i64, i64* %RBP_ptr
  %RBP = alloca i64
  store i64 %RBP_init, i64* %RBP
  %RSP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 16
  %RSP_init = load i64, i64* %RSP_ptr
  %RSP = alloca i64
  store i64 %RSP_init, i64* %RSP
  %ESP_init = trunc i64 %RSP_init to i32
  %ESP = alloca i32
  store i32 %ESP_init, i32* %ESP
  %SP_init = trunc i64 %RSP_init to i16
  %SP = alloca i16
  store i16 %SP_init, i16* %SP
  %SPL_init = trunc i64 %RSP_init to i8
  %SPL = alloca i8
  store i8 %SPL_init, i8* %SPL
  %EFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 3
  %EFLAGS_init = load i32, i32* %EFLAGS_ptr
  %EFLAGS = alloca i32
  store i32 %EFLAGS_init, i32* %EFLAGS
  %EBP_init = trunc i64 %RBP_init to i32
  %EBP = alloca i32
  store i32 %EBP_init, i32* %EBP
  %BP_init = trunc i64 %RBP_init to i16
  %BP = alloca i16
  store i16 %BP_init, i16* %BP
  %BPL_init = trunc i64 %RBP_init to i8
  %BPL = alloca i8
  store i8 %BPL_init, i8* %BPL
  %RDX_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 13
  %RDX_init = load i64, i64* %RDX_ptr
  %RDX = alloca i64
  store i64 %RDX_init, i64* %RDX
  %EDX_init = trunc i64 %RDX_init to i32
  %EDX = alloca i32
  store i32 %EDX_init, i32* %EDX
  %DX_init = trunc i64 %RDX_init to i16
  %DX = alloca i16
  store i16 %DX_init, i16* %DX
  %DL_init = trunc i64 %RDX_init to i8
  %DL = alloca i8
  store i8 %DL_init, i8* %DL
  %2 = lshr i64 %RDX_init, 8
  %DH_init = trunc i64 %2 to i8
  %DH = alloca i8
  store i8 %DH_init, i8* %DH
  %CtlSysEFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 1
  %CtlSysEFLAGS_init = load i32, i32* %CtlSysEFLAGS_ptr
  %CtlSysEFLAGS = alloca i32
  store i32 %CtlSysEFLAGS_init, i32* %CtlSysEFLAGS
  %RSI_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 15
  %RSI_init = load i64, i64* %RSI_ptr
  %RSI = alloca i64
  store i64 %RSI_init, i64* %RSI
  %ESI_init = trunc i64 %RSI_init to i32
  %ESI = alloca i32
  store i32 %ESI_init, i32* %ESI
  %SI_init = trunc i64 %RSI_init to i16
  %SI = alloca i16
  store i16 %SI_init, i16* %SI
  %SIL_init = trunc i64 %RSI_init to i8
  %SIL = alloca i8
  store i8 %SIL_init, i8* %SIL
  %RDI_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 12
  %RDI_init = load i64, i64* %RDI_ptr
  %RDI = alloca i64
  store i64 %RDI_init, i64* %RDI
  %EDI_init = trunc i64 %RDI_init to i32
  %EDI = alloca i32
  store i32 %EDI_init, i32* %EDI
  %DI_init = trunc i64 %RDI_init to i16
  %DI = alloca i16
  store i16 %DI_init, i16* %DI
  %DIL_init = trunc i64 %RDI_init to i8
  %DIL = alloca i8
  store i8 %DIL_init, i8* %DIL
  br label %bb_4004A0

exit_fn_4004A0:                                   ; preds = %bb_4004CE, %bb_4004C2
  %3 = load i32, i32* %CtlSysEFLAGS
  store i32 %3, i32* %CtlSysEFLAGS_ptr
  %4 = load i32, i32* %EFLAGS
  store i32 %4, i32* %EFLAGS_ptr
  %5 = load i64, i64* %RAX
  store i64 %5, i64* %RAX_ptr
  %6 = load i64, i64* %RBP
  store i64 %6, i64* %RBP_ptr
  %7 = load i64, i64* %RDI
  store i64 %7, i64* %RDI_ptr
  %8 = load i64, i64* %RDX
  store i64 %8, i64* %RDX_ptr
  %9 = load i64, i64* %RIP
  store i64 %9, i64* %RIP_ptr
  %10 = load i64, i64* %RSI
  store i64 %10, i64* %RSI_ptr
  %11 = load i64, i64* %RSP
  store i64 %11, i64* %RSP_ptr
  ret void

bb_4004A0:                                        ; preds = %entry_fn_4004A0
  %RIP_1 = add i64 4195488, 5
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %RAX_0 = load i64, i64* %RAX
  %RIP_2 = add i64 %RIP_1, 1
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  %RBP_0 = load i64, i64* %RBP
  %RSP_0 = load i64, i64* %RSP
  %12 = sub i64 %RSP_0, 8
  %13 = inttoptr i64 %12 to i64*
  store i64 %RBP_0, i64* %13, align 1
  %RSP_1 = sub i64 %RSP_0, 8
  %ESP_0 = trunc i64 %RSP_1 to i32
  %SP_0 = trunc i64 %RSP_1 to i16
  %SPL_0 = trunc i64 %RSP_1 to i8
  %RIP_3 = add i64 %RIP_2, 6
  %EIP_2 = trunc i64 %RIP_3 to i32
  %IP_2 = trunc i64 %RIP_3 to i16
  %RAX_2 = sub i64 6295616, 6295616
  %EAX_1 = trunc i64 %RAX_2 to i32
  %AX_1 = trunc i64 %RAX_2 to i16
  %AL_1 = trunc i64 %RAX_2 to i8
  %14 = lshr i64 %RAX_2, 8
  %AH_1 = trunc i64 %14 to i8
  %EFLAGS_0 = load i32, i32* %EFLAGS
  %RIP_4 = add i64 %RIP_3, 4
  %EIP_3 = trunc i64 %RIP_4 to i32
  %IP_3 = trunc i64 %RIP_4 to i16
  %15 = zext i8 3 to i64
  %RAX_3 = ashr i64 %RAX_2, %15
  %EAX_2 = trunc i64 %RAX_3 to i32
  %AX_2 = trunc i64 %RAX_3 to i16
  %AL_2 = trunc i64 %RAX_3 to i8
  %16 = lshr i64 %RAX_3, 8
  %AH_2 = trunc i64 %16 to i8
  %RIP_5 = add i64 %RIP_4, 3
  %EIP_4 = trunc i64 %RIP_5 to i32
  %IP_4 = trunc i64 %RIP_5 to i16
  %EBP_0 = trunc i64 %RSP_1 to i32
  %BP_0 = trunc i64 %RSP_1 to i16
  %BPL_0 = trunc i64 %RSP_1 to i8
  %RIP_6 = add i64 %RIP_5, 3
  %EIP_5 = trunc i64 %RIP_6 to i32
  %IP_5 = trunc i64 %RIP_6 to i16
  %EDX_0 = trunc i64 %RAX_3 to i32
  %DX_0 = trunc i64 %RAX_3 to i16
  %DL_0 = trunc i64 %RAX_3 to i8
  %17 = lshr i64 %RAX_3, 8
  %DH_0 = trunc i64 %17 to i8
  %RIP_7 = add i64 %RIP_6, 4
  %EIP_6 = trunc i64 %RIP_7 to i32
  %IP_6 = trunc i64 %RIP_7 to i16
  %18 = zext i8 63 to i64
  %RDX_0 = lshr i64 %RAX_3, %18
  %EDX_1 = trunc i64 %RDX_0 to i32
  %DX_1 = trunc i64 %RDX_0 to i16
  %DL_1 = trunc i64 %RDX_0 to i8
  %19 = lshr i64 %RDX_0, 8
  %DH_1 = trunc i64 %19 to i8
  %RIP_8 = add i64 %RIP_7, 3
  %EIP_7 = trunc i64 %RIP_8 to i32
  %IP_7 = trunc i64 %RIP_8 to i16
  %RAX_4 = add i64 %RAX_3, %RDX_0
  %EAX_3 = trunc i64 %RAX_4 to i32
  %AX_3 = trunc i64 %RAX_4 to i16
  %AL_3 = trunc i64 %RAX_4 to i8
  %20 = lshr i64 %RAX_4, 8
  %AH_3 = trunc i64 %20 to i8
  %RIP_9 = add i64 %RIP_8, 3
  %EIP_8 = trunc i64 %RIP_9 to i32
  %IP_8 = trunc i64 %RIP_9 to i16
  %21 = zext i8 1 to i64
  %RAX_5 = ashr i64 %RAX_4, %21
  %EAX_4 = trunc i64 %RAX_5 to i32
  %AX_4 = trunc i64 %RAX_5 to i16
  %AL_4 = trunc i64 %RAX_5 to i8
  %22 = lshr i64 %RAX_5, 8
  %AH_4 = trunc i64 %22 to i8
  %RIP_10 = add i64 %RIP_9, 2
  %EIP_9 = trunc i64 %RIP_10 to i32
  %IP_9 = trunc i64 %RIP_10 to i16
  %ZF_0 = icmp eq i64 %RAX_5, 0
  %SF_0 = icmp slt i64 %RAX_5, 0
  %23 = trunc i64 %RAX_5 to i8
  %24 = call i8 @llvm.ctpop.i8(i8 %23)
  %25 = trunc i8 %24 to i1
  %PF_0 = icmp eq i1 %25, false
  %CtlSysEFLAGS_0 = load i32, i32* %CtlSysEFLAGS
  %26 = zext i1 false to i32
  %27 = shl i32 %26, 0
  %28 = or i32 %27, %CtlSysEFLAGS_0
  %29 = zext i1 %PF_0 to i32
  %30 = shl i32 %29, 2
  %31 = or i32 %30, %28
  %32 = zext i1 false to i32
  %33 = shl i32 %32, 4
  %34 = or i32 %33, %31
  %35 = zext i1 %ZF_0 to i32
  %36 = shl i32 %35, 6
  %37 = or i32 %36, %34
  %38 = zext i1 %SF_0 to i32
  %39 = shl i32 %38, 7
  %40 = or i32 %39, %37
  %41 = zext i1 false to i32
  %42 = shl i32 %41, 11
  %EFLAGS_1 = or i32 %42, %40
  %43 = lshr i32 %EFLAGS_1, 6
  %ZF_1 = trunc i32 %43 to i1
  %CC_NE_0 = xor i1 %ZF_1, true
  store i8 %AH_4, i8* %AH
  store i8 %AL_4, i8* %AL
  store i16 %AX_4, i16* %AX
  store i16 %BP_0, i16* %BP
  store i8 %BPL_0, i8* %BPL
  store i32 %CtlSysEFLAGS_0, i32* %CtlSysEFLAGS
  store i8 %DH_1, i8* %DH
  store i8 %DL_1, i8* %DL
  store i16 %DX_1, i16* %DX
  store i32 %EAX_4, i32* %EAX
  store i32 %EBP_0, i32* %EBP
  store i32 %EDX_1, i32* %EDX
  store i32 %EFLAGS_1, i32* %EFLAGS
  store i32 4195524, i32* %EIP
  store i32 %ESP_0, i32* %ESP
  store i16 1220, i16* %IP
  store i64 %RAX_5, i64* %RAX
  store i64 %RSP_1, i64* %RBP
  store i64 %RDX_0, i64* %RDX
  store i64 4195524, i64* %RIP
  store i64 %RSP_1, i64* %RSP
  store i16 %SP_0, i16* %SP
  store i8 %SPL_0, i8* %SPL
  br i1 %CC_NE_0, label %bb_4004C4, label %bb_4004C2

bb_4004C2:                                        ; preds = %bb_4004C4, %bb_4004A0
  %RIP_13 = add i64 4195522, 1
  %EIP_11 = trunc i64 %RIP_13 to i32
  %IP_11 = trunc i64 %RIP_13 to i16
  %RSP_2 = load i64, i64* %RSP
  %RSP_3 = add i64 %RSP_2, 8
  %ESP_1 = trunc i64 %RSP_3 to i32
  %SP_1 = trunc i64 %RSP_3 to i16
  %SPL_1 = trunc i64 %RSP_3 to i8
  %44 = sub i64 %RSP_3, 8
  %45 = inttoptr i64 %44 to i64*
  %RBP_1 = load i64, i64* %45, align 1
  %EBP_1 = trunc i64 %RBP_1 to i32
  %BP_1 = trunc i64 %RBP_1 to i16
  %BPL_1 = trunc i64 %RBP_1 to i8
  %RIP_14 = add i64 %RIP_13, 1
  %EIP_12 = trunc i64 %RIP_14 to i32
  %IP_12 = trunc i64 %RIP_14 to i16
  %RSP_4 = add i64 %RSP_3, 8
  %46 = inttoptr i64 %RSP_3 to i64*
  %RIP_15 = load i64, i64* %46
  %ESP_2 = trunc i64 %RSP_4 to i32
  %SP_2 = trunc i64 %RSP_4 to i16
  %SPL_2 = trunc i64 %RSP_4 to i8
  %EIP_13 = trunc i64 %RIP_15 to i32
  %IP_13 = trunc i64 %RIP_15 to i16
  store i16 %BP_1, i16* %BP
  store i8 %BPL_1, i8* %BPL
  store i32 %EBP_1, i32* %EBP
  store i32 %EIP_13, i32* %EIP
  store i32 %ESP_2, i32* %ESP
  store i16 %IP_13, i16* %IP
  store i64 %RBP_1, i64* %RBP
  store i64 %RIP_15, i64* %RIP
  store i64 %RSP_4, i64* %RSP
  store i16 %SP_2, i16* %SP
  store i8 %SPL_2, i8* %SPL
  br label %exit_fn_4004A0

bb_4004C4:                                        ; preds = %bb_4004A0
  %RIP_17 = add i64 4195524, 5
  %EIP_14 = trunc i64 %RIP_17 to i32
  %IP_14 = trunc i64 %RIP_17 to i16
  %RDX_1 = load i64, i64* %RDX
  %RIP_18 = add i64 %RIP_17, 3
  %EIP_15 = trunc i64 %RIP_18 to i32
  %IP_15 = trunc i64 %RIP_18 to i16
  %47 = and i64 0, 0
  %CC_A_0 = icmp ugt i64 %47, 0
  %CC_AE_0 = icmp uge i64 %47, 0
  %CC_B_0 = icmp ult i64 %47, 0
  %CC_BE_0 = icmp ule i64 %47, 0
  %CC_L_0 = icmp slt i64 %47, 0
  %CC_LE_0 = icmp sle i64 %47, 0
  %CC_G_0 = icmp sgt i64 %47, 0
  %CC_GE_0 = icmp sge i64 %47, 0
  %CC_E_0 = icmp eq i64 %47, 0
  %CC_NE_01 = icmp ne i64 %47, 0
  %48 = sub i64 %47, 0
  %ZF_02 = icmp eq i64 %48, 0
  %SF_03 = icmp slt i64 %48, 0
  %49 = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 %47, i64 0)
  %OF_0 = extractvalue { i64, i1 } %49, 1
  %50 = call { i64, i1 } @llvm.usub.with.overflow.i64(i64 %47, i64 0)
  %CF_0 = extractvalue { i64, i1 } %50, 1
  %51 = trunc i64 %48 to i8
  %52 = call i8 @llvm.ctpop.i8(i8 %51)
  %53 = trunc i8 %52 to i1
  %PF_04 = icmp eq i1 %53, false
  %CtlSysEFLAGS_1 = load i32, i32* %CtlSysEFLAGS
  %54 = zext i1 %CF_0 to i32
  %55 = shl i32 %54, 0
  %56 = or i32 %55, %CtlSysEFLAGS_1
  %57 = zext i1 %PF_04 to i32
  %58 = shl i32 %57, 2
  %59 = or i32 %58, %56
  %60 = zext i1 false to i32
  %61 = shl i32 %60, 4
  %62 = or i32 %61, %59
  %63 = zext i1 %ZF_02 to i32
  %64 = shl i32 %63, 6
  %65 = or i32 %64, %62
  %66 = zext i1 %SF_03 to i32
  %67 = shl i32 %66, 7
  %68 = or i32 %67, %65
  %69 = zext i1 %OF_0 to i32
  %70 = shl i32 %69, 11
  %EFLAGS_2 = or i32 %70, %68
  %RIP_19 = add i64 %RIP_18, 2
  %EIP_16 = trunc i64 %RIP_19 to i32
  %IP_16 = trunc i64 %RIP_19 to i16
  store i32 %CtlSysEFLAGS_1, i32* %CtlSysEFLAGS
  store i8 0, i8* %DH
  store i8 0, i8* %DL
  store i16 0, i16* %DX
  store i32 0, i32* %EDX
  store i32 %EFLAGS_2, i32* %EFLAGS
  store i32 4195522, i32* %EIP
  store i16 1218, i16* %IP
  store i64 0, i64* %RDX
  store i64 4195522, i64* %RIP
  br i1 %CC_E_0, label %bb_4004C2, label %bb_4004CE

bb_4004CE:                                        ; preds = %bb_4004C4
  %RIP_22 = add i64 4195534, 1
  %EIP_18 = trunc i64 %RIP_22 to i32
  %IP_18 = trunc i64 %RIP_22 to i16
  %RSP_5 = load i64, i64* %RSP
  %RSP_6 = add i64 %RSP_5, 8
  %ESP_3 = trunc i64 %RSP_6 to i32
  %SP_3 = trunc i64 %RSP_6 to i16
  %SPL_3 = trunc i64 %RSP_6 to i8
  %71 = sub i64 %RSP_6, 8
  %72 = inttoptr i64 %71 to i64*
  %RBP_2 = load i64, i64* %72, align 1
  %EBP_2 = trunc i64 %RBP_2 to i32
  %BP_2 = trunc i64 %RBP_2 to i16
  %BPL_2 = trunc i64 %RBP_2 to i8
  %RIP_23 = add i64 %RIP_22, 3
  %EIP_19 = trunc i64 %RIP_23 to i32
  %IP_19 = trunc i64 %RIP_23 to i16
  %RAX_6 = load i64, i64* %RAX
  %ESI_0 = trunc i64 %RAX_6 to i32
  %SI_0 = trunc i64 %RAX_6 to i16
  %SIL_0 = trunc i64 %RAX_6 to i8
  %RIP_24 = add i64 %RIP_23, 5
  %EIP_20 = trunc i64 %RIP_24 to i32
  %IP_20 = trunc i64 %RIP_24 to i16
  %RDI_0 = load i64, i64* %RDI
  %RIP_25 = add i64 %RIP_24, 2
  %EIP_21 = trunc i64 %RIP_25 to i32
  %IP_21 = trunc i64 %RIP_25 to i16
  %RDX_3 = load i64, i64* %RDX
  %EIP_22 = trunc i64 %RDX_3 to i32
  %IP_22 = trunc i64 %RDX_3 to i16
  %73 = inttoptr i64 %RDX_3 to i8*
  %74 = call i8* @llvm.dc.translate.at(i8* %73)
  %75 = bitcast i8* %74 to void (%regset*)*
  store i16 %BP_2, i16* %BP
  store i8 %BPL_2, i8* %BPL
  store i16 4160, i16* %DI
  store i8 64, i8* %DIL
  store i32 %EBP_2, i32* %EBP
  store i32 6295616, i32* %EDI
  store i32 %EIP_22, i32* %EIP
  store i32 %ESI_0, i32* %ESI
  store i32 %ESP_3, i32* %ESP
  store i16 %IP_22, i16* %IP
  store i64 %RAX_6, i64* %RAX
  store i64 %RBP_2, i64* %RBP
  store i64 6295616, i64* %RDI
  store i64 %RDX_3, i64* %RDX
  store i64 %RDX_3, i64* %RIP
  store i64 %RAX_6, i64* %RSI
  store i64 %RSP_6, i64* %RSP
  store i16 %SI_0, i16* %SI
  store i8 %SIL_0, i8* %SIL
  store i16 %SP_3, i16* %SP
  store i8 %SPL_3, i8* %SPL
  %76 = load i32, i32* %CtlSysEFLAGS
  store i32 %76, i32* %CtlSysEFLAGS_ptr
  %77 = load i32, i32* %EFLAGS
  store i32 %77, i32* %EFLAGS_ptr
  %78 = load i64, i64* %RAX
  store i64 %78, i64* %RAX_ptr
  %79 = load i64, i64* %RBP
  store i64 %79, i64* %RBP_ptr
  %80 = load i64, i64* %RDI
  store i64 %80, i64* %RDI_ptr
  %81 = load i64, i64* %RDX
  store i64 %81, i64* %RDX_ptr
  %82 = load i64, i64* %RIP
  store i64 %82, i64* %RIP_ptr
  %83 = load i64, i64* %RSI
  store i64 %83, i64* %RSI_ptr
  %84 = load i64, i64* %RSP
  store i64 %84, i64* %RSP_ptr
  call void %75(%regset* %0)
  %85 = load i32, i32* %CtlSysEFLAGS_ptr
  store i32 %85, i32* %CtlSysEFLAGS
  %86 = load i32, i32* %EFLAGS_ptr
  store i32 %86, i32* %EFLAGS
  %87 = load i64, i64* %RAX_ptr
  store i64 %87, i64* %RAX
  %88 = load i64, i64* %RBP_ptr
  store i64 %88, i64* %RBP
  %89 = load i64, i64* %RDI_ptr
  store i64 %89, i64* %RDI
  %90 = load i64, i64* %RDX_ptr
  store i64 %90, i64* %RDX
  %91 = load i64, i64* %RIP_ptr
  store i64 %91, i64* %RIP
  %92 = load i64, i64* %RSI_ptr
  store i64 %92, i64* %RSI
  %93 = load i64, i64* %RSP_ptr
  store i64 %93, i64* %RSP
  br label %exit_fn_4004A0
}

define void @fn_4004E0(%regset* noalias nocapture) {
entry_fn_4004E0:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  %CtlSysEFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 1
  %CtlSysEFLAGS_init = load i32, i32* %CtlSysEFLAGS_ptr
  %CtlSysEFLAGS = alloca i32
  store i32 %CtlSysEFLAGS_init, i32* %CtlSysEFLAGS
  %EFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 3
  %EFLAGS_init = load i32, i32* %EFLAGS_ptr
  %EFLAGS = alloca i32
  store i32 %EFLAGS_init, i32* %EFLAGS
  %RBP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 9
  %RBP_init = load i64, i64* %RBP_ptr
  %RBP = alloca i64
  store i64 %RBP_init, i64* %RBP
  %RSP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 16
  %RSP_init = load i64, i64* %RSP_ptr
  %RSP = alloca i64
  store i64 %RSP_init, i64* %RSP
  %ESP_init = trunc i64 %RSP_init to i32
  %ESP = alloca i32
  store i32 %ESP_init, i32* %ESP
  %SP_init = trunc i64 %RSP_init to i16
  %SP = alloca i16
  store i16 %SP_init, i16* %SP
  %SPL_init = trunc i64 %RSP_init to i8
  %SPL = alloca i8
  store i8 %SPL_init, i8* %SPL
  %EBP_init = trunc i64 %RBP_init to i32
  %EBP = alloca i32
  store i32 %EBP_init, i32* %EBP
  %BP_init = trunc i64 %RBP_init to i16
  %BP = alloca i16
  store i16 %BP_init, i16* %BP
  %BPL_init = trunc i64 %RBP_init to i8
  %BPL = alloca i8
  store i8 %BPL_init, i8* %BPL
  br label %bb_4004E0

exit_fn_4004E0:                                   ; preds = %bb_4004FA
  %1 = load i32, i32* %CtlSysEFLAGS
  store i32 %1, i32* %CtlSysEFLAGS_ptr
  %2 = load i32, i32* %EFLAGS
  store i32 %2, i32* %EFLAGS_ptr
  %3 = load i64, i64* %RBP
  store i64 %3, i64* %RBP_ptr
  %4 = load i64, i64* %RIP
  store i64 %4, i64* %RIP_ptr
  %5 = load i64, i64* %RSP
  store i64 %5, i64* %RSP_ptr
  ret void

bb_4004E0:                                        ; preds = %entry_fn_4004E0
  %RIP_1 = add i64 4195552, 7
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %6 = add i64 %RIP_1, 2100057
  %7 = inttoptr i64 %6 to i8*
  %8 = load i8, i8* %7, align 1
  %CC_A_0 = icmp ugt i8 %8, 0
  %CC_AE_0 = icmp uge i8 %8, 0
  %CC_B_0 = icmp ult i8 %8, 0
  %CC_BE_0 = icmp ule i8 %8, 0
  %CC_L_0 = icmp slt i8 %8, 0
  %CC_LE_0 = icmp sle i8 %8, 0
  %CC_G_0 = icmp sgt i8 %8, 0
  %CC_GE_0 = icmp sge i8 %8, 0
  %CC_E_0 = icmp eq i8 %8, 0
  %CC_NE_0 = icmp ne i8 %8, 0
  %9 = sub i8 %8, 0
  %ZF_0 = icmp eq i8 %9, 0
  %SF_0 = icmp slt i8 %9, 0
  %10 = call { i8, i1 } @llvm.ssub.with.overflow.i8(i8 %8, i8 0)
  %OF_0 = extractvalue { i8, i1 } %10, 1
  %11 = call { i8, i1 } @llvm.usub.with.overflow.i8(i8 %8, i8 0)
  %CF_0 = extractvalue { i8, i1 } %11, 1
  %12 = call i8 @llvm.ctpop.i8(i8 %9)
  %13 = trunc i8 %12 to i1
  %PF_0 = icmp eq i1 %13, false
  %CtlSysEFLAGS_0 = load i32, i32* %CtlSysEFLAGS
  %14 = zext i1 %CF_0 to i32
  %15 = shl i32 %14, 0
  %16 = or i32 %15, %CtlSysEFLAGS_0
  %17 = zext i1 %PF_0 to i32
  %18 = shl i32 %17, 2
  %19 = or i32 %18, %16
  %20 = zext i1 false to i32
  %21 = shl i32 %20, 4
  %22 = or i32 %21, %19
  %23 = zext i1 %ZF_0 to i32
  %24 = shl i32 %23, 6
  %25 = or i32 %24, %22
  %26 = zext i1 %SF_0 to i32
  %27 = shl i32 %26, 7
  %28 = or i32 %27, %25
  %29 = zext i1 %OF_0 to i32
  %30 = shl i32 %29, 11
  %EFLAGS_0 = or i32 %30, %28
  %RIP_2 = add i64 %RIP_1, 2
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  store i32 %CtlSysEFLAGS_0, i32* %CtlSysEFLAGS
  store i32 %EFLAGS_0, i32* %EFLAGS
  store i32 4195578, i32* %EIP
  store i16 1274, i16* %IP
  store i64 4195578, i64* %RIP
  br i1 %CC_NE_0, label %bb_4004FA, label %bb_4004E9

bb_4004E9:                                        ; preds = %bb_4004E0
  %RIP_5 = add i64 4195561, 1
  %EIP_3 = trunc i64 %RIP_5 to i32
  %IP_3 = trunc i64 %RIP_5 to i16
  %RBP_0 = load i64, i64* %RBP
  %RSP_0 = load i64, i64* %RSP
  %31 = sub i64 %RSP_0, 8
  %32 = inttoptr i64 %31 to i64*
  store i64 %RBP_0, i64* %32, align 1
  %RSP_1 = sub i64 %RSP_0, 8
  %ESP_0 = trunc i64 %RSP_1 to i32
  %SP_0 = trunc i64 %RSP_1 to i16
  %SPL_0 = trunc i64 %RSP_1 to i8
  %RIP_6 = add i64 %RIP_5, 3
  %EIP_4 = trunc i64 %RIP_6 to i32
  %IP_4 = trunc i64 %RIP_6 to i16
  %EBP_0 = trunc i64 %RSP_1 to i32
  %BP_0 = trunc i64 %RSP_1 to i16
  %BPL_0 = trunc i64 %RSP_1 to i8
  %RIP_7 = add i64 %RIP_6, 5
  %EIP_5 = trunc i64 %RIP_7 to i32
  %IP_5 = trunc i64 %RIP_7 to i16
  %RSP_2 = sub i64 %RSP_1, 8
  %33 = inttoptr i64 %RSP_2 to i64*
  store i64 4195570, i64* %33
  %ESP_1 = trunc i64 %RSP_2 to i32
  %SP_1 = trunc i64 %RSP_2 to i16
  %SPL_1 = trunc i64 %RSP_2 to i8
  store i16 %BP_0, i16* %BP
  store i8 %BPL_0, i8* %BPL
  store i32 %EBP_0, i32* %EBP
  store i32 %EIP_5, i32* %EIP
  store i32 %ESP_1, i32* %ESP
  store i16 %IP_5, i16* %IP
  store i64 %RSP_1, i64* %RBP
  store i64 %RIP_7, i64* %RIP
  store i64 %RSP_2, i64* %RSP
  store i16 %SP_1, i16* %SP
  store i8 %SPL_1, i8* %SPL
  %34 = load i32, i32* %CtlSysEFLAGS
  store i32 %34, i32* %CtlSysEFLAGS_ptr
  %35 = load i32, i32* %EFLAGS
  store i32 %35, i32* %EFLAGS_ptr
  %36 = load i64, i64* %RBP
  store i64 %36, i64* %RBP_ptr
  %37 = load i64, i64* %RIP
  store i64 %37, i64* %RIP_ptr
  %38 = load i64, i64* %RSP
  store i64 %38, i64* %RSP_ptr
  call void @fn_400470(%regset* %0)
  %39 = load i32, i32* %CtlSysEFLAGS_ptr
  store i32 %39, i32* %CtlSysEFLAGS
  %40 = load i32, i32* %EFLAGS_ptr
  store i32 %40, i32* %EFLAGS
  %41 = load i64, i64* %RBP_ptr
  store i64 %41, i64* %RBP
  %42 = load i64, i64* %RIP_ptr
  store i64 %42, i64* %RIP
  %43 = load i64, i64* %RSP_ptr
  store i64 %43, i64* %RSP
  %RIP_8 = load i64, i64* %RIP
  %RIP_9 = add i64 %RIP_8, 1
  %EIP_6 = trunc i64 %RIP_9 to i32
  %IP_6 = trunc i64 %RIP_9 to i16
  %RSP_3 = load i64, i64* %RSP
  %RSP_4 = add i64 %RSP_3, 8
  %ESP_2 = trunc i64 %RSP_4 to i32
  %SP_2 = trunc i64 %RSP_4 to i16
  %SPL_2 = trunc i64 %RSP_4 to i8
  %44 = sub i64 %RSP_4, 8
  %45 = inttoptr i64 %44 to i64*
  %RBP_1 = load i64, i64* %45, align 1
  %EBP_1 = trunc i64 %RBP_1 to i32
  %BP_1 = trunc i64 %RBP_1 to i16
  %BPL_1 = trunc i64 %RBP_1 to i8
  %RIP_10 = add i64 %RIP_9, 7
  %EIP_7 = trunc i64 %RIP_10 to i32
  %IP_7 = trunc i64 %RIP_10 to i16
  %46 = add i64 %RIP_10, 2100038
  %47 = inttoptr i64 %46 to i8*
  store i8 1, i8* %47, align 1
  store i16 %BP_1, i16* %BP
  store i8 %BPL_1, i8* %BPL
  store i32 %EBP_1, i32* %EBP
  store i32 %EIP_7, i32* %EIP
  store i32 %ESP_2, i32* %ESP
  store i16 %IP_7, i16* %IP
  store i64 %RBP_1, i64* %RBP
  store i64 %RIP_10, i64* %RIP
  store i64 %RSP_4, i64* %RSP
  store i16 %SP_2, i16* %SP
  store i8 %SPL_2, i8* %SPL
  br label %bb_4004FA

bb_4004FA:                                        ; preds = %bb_4004E9, %bb_4004E0
  %RIP_12 = add i64 4195578, 1
  %EIP_8 = trunc i64 %RIP_12 to i32
  %IP_8 = trunc i64 %RIP_12 to i16
  %RIP_13 = add i64 %RIP_12, 1
  %EIP_9 = trunc i64 %RIP_13 to i32
  %IP_9 = trunc i64 %RIP_13 to i16
  %RSP_5 = load i64, i64* %RSP
  %RSP_6 = add i64 %RSP_5, 8
  %48 = inttoptr i64 %RSP_5 to i64*
  %RIP_14 = load i64, i64* %48
  %ESP_3 = trunc i64 %RSP_6 to i32
  %SP_3 = trunc i64 %RSP_6 to i16
  %SPL_3 = trunc i64 %RSP_6 to i8
  %EIP_10 = trunc i64 %RIP_14 to i32
  %IP_10 = trunc i64 %RIP_14 to i16
  store i32 %EIP_10, i32* %EIP
  store i32 %ESP_3, i32* %ESP
  store i16 %IP_10, i16* %IP
  store i64 %RIP_14, i64* %RIP
  store i64 %RSP_6, i64* %RSP
  store i16 %SP_3, i16* %SP
  store i8 %SPL_3, i8* %SPL
  br label %exit_fn_4004E0
}

; Function Attrs: nounwind readnone speculatable
declare { i8, i1 } @llvm.ssub.with.overflow.i8(i8, i8) #1

; Function Attrs: nounwind readnone speculatable
declare { i8, i1 } @llvm.usub.with.overflow.i8(i8, i8) #1

define void @fn_400500(%regset* noalias nocapture) {
entry_fn_400500:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  %CtlSysEFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 1
  %CtlSysEFLAGS_init = load i32, i32* %CtlSysEFLAGS_ptr
  %CtlSysEFLAGS = alloca i32
  store i32 %CtlSysEFLAGS_init, i32* %CtlSysEFLAGS
  %EFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 3
  %EFLAGS_init = load i32, i32* %EFLAGS_ptr
  %EFLAGS = alloca i32
  store i32 %EFLAGS_init, i32* %EFLAGS
  %RAX_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 8
  %RAX_init = load i64, i64* %RAX_ptr
  %RAX = alloca i64
  store i64 %RAX_init, i64* %RAX
  %EAX_init = trunc i64 %RAX_init to i32
  %EAX = alloca i32
  store i32 %EAX_init, i32* %EAX
  %AX_init = trunc i64 %RAX_init to i16
  %AX = alloca i16
  store i16 %AX_init, i16* %AX
  %AL_init = trunc i64 %RAX_init to i8
  %AL = alloca i8
  store i8 %AL_init, i8* %AL
  %1 = lshr i64 %RAX_init, 8
  %AH_init = trunc i64 %1 to i8
  %AH = alloca i8
  store i8 %AH_init, i8* %AH
  %RBP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 9
  %RBP_init = load i64, i64* %RBP_ptr
  %RBP = alloca i64
  store i64 %RBP_init, i64* %RBP
  %RSP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 16
  %RSP_init = load i64, i64* %RSP_ptr
  %RSP = alloca i64
  store i64 %RSP_init, i64* %RSP
  %ESP_init = trunc i64 %RSP_init to i32
  %ESP = alloca i32
  store i32 %ESP_init, i32* %ESP
  %SP_init = trunc i64 %RSP_init to i16
  %SP = alloca i16
  store i16 %SP_init, i16* %SP
  %SPL_init = trunc i64 %RSP_init to i8
  %SPL = alloca i8
  store i8 %SPL_init, i8* %SPL
  %RDI_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 12
  %RDI_init = load i64, i64* %RDI_ptr
  %RDI = alloca i64
  store i64 %RDI_init, i64* %RDI
  %EDI_init = trunc i64 %RDI_init to i32
  %EDI = alloca i32
  store i32 %EDI_init, i32* %EDI
  %DI_init = trunc i64 %RDI_init to i16
  %DI = alloca i16
  store i16 %DI_init, i16* %DI
  %DIL_init = trunc i64 %RDI_init to i8
  %DIL = alloca i8
  store i8 %DIL_init, i8* %DIL
  %EBP_init = trunc i64 %RBP_init to i32
  %EBP = alloca i32
  store i32 %EBP_init, i32* %EBP
  %BP_init = trunc i64 %RBP_init to i16
  %BP = alloca i16
  store i16 %BP_init, i16* %BP
  %BPL_init = trunc i64 %RBP_init to i8
  %BPL = alloca i8
  store i8 %BPL_init, i8* %BPL
  %RDX_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 13
  %RDX_init = load i64, i64* %RDX_ptr
  %RDX = alloca i64
  store i64 %RDX_init, i64* %RDX
  %EDX_init = trunc i64 %RDX_init to i32
  %EDX = alloca i32
  store i32 %EDX_init, i32* %EDX
  %DX_init = trunc i64 %RDX_init to i16
  %DX = alloca i16
  store i16 %DX_init, i16* %DX
  %DL_init = trunc i64 %RDX_init to i8
  %DL = alloca i8
  store i8 %DL_init, i8* %DL
  %2 = lshr i64 %RDX_init, 8
  %DH_init = trunc i64 %2 to i8
  %DH = alloca i8
  store i8 %DH_init, i8* %DH
  %RSI_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 15
  %RSI_init = load i64, i64* %RSI_ptr
  %RSI = alloca i64
  store i64 %RSI_init, i64* %RSI
  %ESI_init = trunc i64 %RSI_init to i32
  %ESI = alloca i32
  store i32 %ESI_init, i32* %ESI
  %SI_init = trunc i64 %RSI_init to i16
  %SI = alloca i16
  store i16 %SI_init, i16* %SI
  %SIL_init = trunc i64 %RSI_init to i8
  %SIL = alloca i8
  store i8 %SIL_init, i8* %SIL
  br label %bb_400500

exit_fn_400500:                                   ; preds = %bb_4004CE, %bb_4004C2
  %3 = load i32, i32* %CtlSysEFLAGS
  store i32 %3, i32* %CtlSysEFLAGS_ptr
  %4 = load i32, i32* %EFLAGS
  store i32 %4, i32* %EFLAGS_ptr
  %5 = load i64, i64* %RAX
  store i64 %5, i64* %RAX_ptr
  %6 = load i64, i64* %RBP
  store i64 %6, i64* %RBP_ptr
  %7 = load i64, i64* %RDI
  store i64 %7, i64* %RDI_ptr
  %8 = load i64, i64* %RDX
  store i64 %8, i64* %RDX_ptr
  %9 = load i64, i64* %RIP
  store i64 %9, i64* %RIP_ptr
  %10 = load i64, i64* %RSI
  store i64 %10, i64* %RSI_ptr
  %11 = load i64, i64* %RSP
  store i64 %11, i64* %RSP_ptr
  ret void

bb_400500:                                        ; preds = %entry_fn_400500
  %RIP_1 = add i64 4195584, 8
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %12 = add i64 %RIP_1, 2099480
  %13 = inttoptr i64 %12 to i64*
  %14 = load i64, i64* %13, align 1
  %CC_A_0 = icmp ugt i64 %14, 0
  %CC_AE_0 = icmp uge i64 %14, 0
  %CC_B_0 = icmp ult i64 %14, 0
  %CC_BE_0 = icmp ule i64 %14, 0
  %CC_L_0 = icmp slt i64 %14, 0
  %CC_LE_0 = icmp sle i64 %14, 0
  %CC_G_0 = icmp sgt i64 %14, 0
  %CC_GE_0 = icmp sge i64 %14, 0
  %CC_E_0 = icmp eq i64 %14, 0
  %CC_NE_0 = icmp ne i64 %14, 0
  %15 = sub i64 %14, 0
  %ZF_0 = icmp eq i64 %15, 0
  %SF_0 = icmp slt i64 %15, 0
  %16 = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 %14, i64 0)
  %OF_0 = extractvalue { i64, i1 } %16, 1
  %17 = call { i64, i1 } @llvm.usub.with.overflow.i64(i64 %14, i64 0)
  %CF_0 = extractvalue { i64, i1 } %17, 1
  %18 = trunc i64 %15 to i8
  %19 = call i8 @llvm.ctpop.i8(i8 %18)
  %20 = trunc i8 %19 to i1
  %PF_0 = icmp eq i1 %20, false
  %CtlSysEFLAGS_0 = load i32, i32* %CtlSysEFLAGS
  %21 = zext i1 %CF_0 to i32
  %22 = shl i32 %21, 0
  %23 = or i32 %22, %CtlSysEFLAGS_0
  %24 = zext i1 %PF_0 to i32
  %25 = shl i32 %24, 2
  %26 = or i32 %25, %23
  %27 = zext i1 false to i32
  %28 = shl i32 %27, 4
  %29 = or i32 %28, %26
  %30 = zext i1 %ZF_0 to i32
  %31 = shl i32 %30, 6
  %32 = or i32 %31, %29
  %33 = zext i1 %SF_0 to i32
  %34 = shl i32 %33, 7
  %35 = or i32 %34, %32
  %36 = zext i1 %OF_0 to i32
  %37 = shl i32 %36, 11
  %EFLAGS_0 = or i32 %37, %35
  %RIP_2 = add i64 %RIP_1, 2
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  store i32 %CtlSysEFLAGS_0, i32* %CtlSysEFLAGS
  store i32 %EFLAGS_0, i32* %EFLAGS
  store i32 4195624, i32* %EIP
  store i16 1320, i16* %IP
  store i64 4195624, i64* %RIP
  br i1 %CC_E_0, label %bb_400528, label %bb_40050A

bb_4004A0:                                        ; preds = %bb_400514, %bb_400528
  %RIP_22 = add i64 4195488, 5
  %EIP_16 = trunc i64 %RIP_22 to i32
  %IP_16 = trunc i64 %RIP_22 to i16
  %RAX_3 = load i64, i64* %RAX
  %RIP_23 = add i64 %RIP_22, 1
  %EIP_17 = trunc i64 %RIP_23 to i32
  %IP_17 = trunc i64 %RIP_23 to i16
  %RBP_2 = load i64, i64* %RBP
  %RSP_5 = load i64, i64* %RSP
  %38 = sub i64 %RSP_5, 8
  %39 = inttoptr i64 %38 to i64*
  store i64 %RBP_2, i64* %39, align 1
  %RSP_6 = sub i64 %RSP_5, 8
  %ESP_3 = trunc i64 %RSP_6 to i32
  %SP_3 = trunc i64 %RSP_6 to i16
  %SPL_3 = trunc i64 %RSP_6 to i8
  %RIP_24 = add i64 %RIP_23, 6
  %EIP_18 = trunc i64 %RIP_24 to i32
  %IP_18 = trunc i64 %RIP_24 to i16
  %RAX_5 = sub i64 6295616, 6295616
  %EAX_2 = trunc i64 %RAX_5 to i32
  %AX_2 = trunc i64 %RAX_5 to i16
  %AL_2 = trunc i64 %RAX_5 to i8
  %40 = lshr i64 %RAX_5, 8
  %AH_2 = trunc i64 %40 to i8
  %EFLAGS_2 = load i32, i32* %EFLAGS
  %RIP_25 = add i64 %RIP_24, 4
  %EIP_19 = trunc i64 %RIP_25 to i32
  %IP_19 = trunc i64 %RIP_25 to i16
  %41 = zext i8 3 to i64
  %RAX_6 = ashr i64 %RAX_5, %41
  %EAX_3 = trunc i64 %RAX_6 to i32
  %AX_3 = trunc i64 %RAX_6 to i16
  %AL_3 = trunc i64 %RAX_6 to i8
  %42 = lshr i64 %RAX_6, 8
  %AH_3 = trunc i64 %42 to i8
  %RIP_26 = add i64 %RIP_25, 3
  %EIP_20 = trunc i64 %RIP_26 to i32
  %IP_20 = trunc i64 %RIP_26 to i16
  %EBP_2 = trunc i64 %RSP_6 to i32
  %BP_2 = trunc i64 %RSP_6 to i16
  %BPL_2 = trunc i64 %RSP_6 to i8
  %RIP_27 = add i64 %RIP_26, 3
  %EIP_21 = trunc i64 %RIP_27 to i32
  %IP_21 = trunc i64 %RIP_27 to i16
  %EDX_0 = trunc i64 %RAX_6 to i32
  %DX_0 = trunc i64 %RAX_6 to i16
  %DL_0 = trunc i64 %RAX_6 to i8
  %43 = lshr i64 %RAX_6, 8
  %DH_0 = trunc i64 %43 to i8
  %RIP_28 = add i64 %RIP_27, 4
  %EIP_22 = trunc i64 %RIP_28 to i32
  %IP_22 = trunc i64 %RIP_28 to i16
  %44 = zext i8 63 to i64
  %RDX_0 = lshr i64 %RAX_6, %44
  %EDX_1 = trunc i64 %RDX_0 to i32
  %DX_1 = trunc i64 %RDX_0 to i16
  %DL_1 = trunc i64 %RDX_0 to i8
  %45 = lshr i64 %RDX_0, 8
  %DH_1 = trunc i64 %45 to i8
  %RIP_29 = add i64 %RIP_28, 3
  %EIP_23 = trunc i64 %RIP_29 to i32
  %IP_23 = trunc i64 %RIP_29 to i16
  %RAX_7 = add i64 %RAX_6, %RDX_0
  %EAX_4 = trunc i64 %RAX_7 to i32
  %AX_4 = trunc i64 %RAX_7 to i16
  %AL_4 = trunc i64 %RAX_7 to i8
  %46 = lshr i64 %RAX_7, 8
  %AH_4 = trunc i64 %46 to i8
  %RIP_30 = add i64 %RIP_29, 3
  %EIP_24 = trunc i64 %RIP_30 to i32
  %IP_24 = trunc i64 %RIP_30 to i16
  %47 = zext i8 1 to i64
  %RAX_8 = ashr i64 %RAX_7, %47
  %EAX_5 = trunc i64 %RAX_8 to i32
  %AX_5 = trunc i64 %RAX_8 to i16
  %AL_5 = trunc i64 %RAX_8 to i8
  %48 = lshr i64 %RAX_8, 8
  %AH_5 = trunc i64 %48 to i8
  %RIP_31 = add i64 %RIP_30, 2
  %EIP_25 = trunc i64 %RIP_31 to i32
  %IP_25 = trunc i64 %RIP_31 to i16
  %ZF_016 = icmp eq i64 %RAX_8, 0
  %SF_017 = icmp slt i64 %RAX_8, 0
  %49 = trunc i64 %RAX_8 to i8
  %50 = call i8 @llvm.ctpop.i8(i8 %49)
  %51 = trunc i8 %50 to i1
  %PF_018 = icmp eq i1 %51, false
  %CtlSysEFLAGS_2 = load i32, i32* %CtlSysEFLAGS
  %52 = zext i1 false to i32
  %53 = shl i32 %52, 0
  %54 = or i32 %53, %CtlSysEFLAGS_2
  %55 = zext i1 %PF_018 to i32
  %56 = shl i32 %55, 2
  %57 = or i32 %56, %54
  %58 = zext i1 false to i32
  %59 = shl i32 %58, 4
  %60 = or i32 %59, %57
  %61 = zext i1 %ZF_016 to i32
  %62 = shl i32 %61, 6
  %63 = or i32 %62, %60
  %64 = zext i1 %SF_017 to i32
  %65 = shl i32 %64, 7
  %66 = or i32 %65, %63
  %67 = zext i1 false to i32
  %68 = shl i32 %67, 11
  %EFLAGS_3 = or i32 %68, %66
  %69 = lshr i32 %EFLAGS_3, 6
  %ZF_1 = trunc i32 %69 to i1
  %CC_NE_019 = xor i1 %ZF_1, true
  store i8 %AH_5, i8* %AH
  store i8 %AL_5, i8* %AL
  store i16 %AX_5, i16* %AX
  store i16 %BP_2, i16* %BP
  store i8 %BPL_2, i8* %BPL
  store i32 %CtlSysEFLAGS_2, i32* %CtlSysEFLAGS
  store i8 %DH_1, i8* %DH
  store i8 %DL_1, i8* %DL
  store i16 %DX_1, i16* %DX
  store i32 %EAX_5, i32* %EAX
  store i32 %EBP_2, i32* %EBP
  store i32 %EDX_1, i32* %EDX
  store i32 %EFLAGS_3, i32* %EFLAGS
  store i32 4195524, i32* %EIP
  store i32 %ESP_3, i32* %ESP
  store i16 1220, i16* %IP
  store i64 %RAX_8, i64* %RAX
  store i64 %RSP_6, i64* %RBP
  store i64 %RDX_0, i64* %RDX
  store i64 4195524, i64* %RIP
  store i64 %RSP_6, i64* %RSP
  store i16 %SP_3, i16* %SP
  store i8 %SPL_3, i8* %SPL
  br i1 %CC_NE_019, label %bb_4004C4, label %bb_4004C2

bb_4004C2:                                        ; preds = %bb_4004C4, %bb_4004A0
  %RIP_34 = add i64 4195522, 1
  %EIP_27 = trunc i64 %RIP_34 to i32
  %IP_27 = trunc i64 %RIP_34 to i16
  %RSP_7 = load i64, i64* %RSP
  %RSP_8 = add i64 %RSP_7, 8
  %ESP_4 = trunc i64 %RSP_8 to i32
  %SP_4 = trunc i64 %RSP_8 to i16
  %SPL_4 = trunc i64 %RSP_8 to i8
  %70 = sub i64 %RSP_8, 8
  %71 = inttoptr i64 %70 to i64*
  %RBP_3 = load i64, i64* %71, align 1
  %EBP_3 = trunc i64 %RBP_3 to i32
  %BP_3 = trunc i64 %RBP_3 to i16
  %BPL_3 = trunc i64 %RBP_3 to i8
  %RIP_35 = add i64 %RIP_34, 1
  %EIP_28 = trunc i64 %RIP_35 to i32
  %IP_28 = trunc i64 %RIP_35 to i16
  %RSP_9 = add i64 %RSP_8, 8
  %72 = inttoptr i64 %RSP_8 to i64*
  %RIP_36 = load i64, i64* %72
  %ESP_5 = trunc i64 %RSP_9 to i32
  %SP_5 = trunc i64 %RSP_9 to i16
  %SPL_5 = trunc i64 %RSP_9 to i8
  %EIP_29 = trunc i64 %RIP_36 to i32
  %IP_29 = trunc i64 %RIP_36 to i16
  store i16 %BP_3, i16* %BP
  store i8 %BPL_3, i8* %BPL
  store i32 %EBP_3, i32* %EBP
  store i32 %EIP_29, i32* %EIP
  store i32 %ESP_5, i32* %ESP
  store i16 %IP_29, i16* %IP
  store i64 %RBP_3, i64* %RBP
  store i64 %RIP_36, i64* %RIP
  store i64 %RSP_9, i64* %RSP
  store i16 %SP_5, i16* %SP
  store i8 %SPL_5, i8* %SPL
  br label %exit_fn_400500

bb_4004C4:                                        ; preds = %bb_4004A0
  %RIP_38 = add i64 4195524, 5
  %EIP_30 = trunc i64 %RIP_38 to i32
  %IP_30 = trunc i64 %RIP_38 to i16
  %RDX_1 = load i64, i64* %RDX
  %RIP_39 = add i64 %RIP_38, 3
  %EIP_31 = trunc i64 %RIP_39 to i32
  %IP_31 = trunc i64 %RIP_39 to i16
  %73 = and i64 0, 0
  %CC_A_020 = icmp ugt i64 %73, 0
  %CC_AE_021 = icmp uge i64 %73, 0
  %CC_B_022 = icmp ult i64 %73, 0
  %CC_BE_023 = icmp ule i64 %73, 0
  %CC_L_024 = icmp slt i64 %73, 0
  %CC_LE_025 = icmp sle i64 %73, 0
  %CC_G_026 = icmp sgt i64 %73, 0
  %CC_GE_027 = icmp sge i64 %73, 0
  %CC_E_028 = icmp eq i64 %73, 0
  %CC_NE_029 = icmp ne i64 %73, 0
  %74 = sub i64 %73, 0
  %ZF_030 = icmp eq i64 %74, 0
  %SF_031 = icmp slt i64 %74, 0
  %75 = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 %73, i64 0)
  %OF_032 = extractvalue { i64, i1 } %75, 1
  %76 = call { i64, i1 } @llvm.usub.with.overflow.i64(i64 %73, i64 0)
  %CF_033 = extractvalue { i64, i1 } %76, 1
  %77 = trunc i64 %74 to i8
  %78 = call i8 @llvm.ctpop.i8(i8 %77)
  %79 = trunc i8 %78 to i1
  %PF_034 = icmp eq i1 %79, false
  %CtlSysEFLAGS_3 = load i32, i32* %CtlSysEFLAGS
  %80 = zext i1 %CF_033 to i32
  %81 = shl i32 %80, 0
  %82 = or i32 %81, %CtlSysEFLAGS_3
  %83 = zext i1 %PF_034 to i32
  %84 = shl i32 %83, 2
  %85 = or i32 %84, %82
  %86 = zext i1 false to i32
  %87 = shl i32 %86, 4
  %88 = or i32 %87, %85
  %89 = zext i1 %ZF_030 to i32
  %90 = shl i32 %89, 6
  %91 = or i32 %90, %88
  %92 = zext i1 %SF_031 to i32
  %93 = shl i32 %92, 7
  %94 = or i32 %93, %91
  %95 = zext i1 %OF_032 to i32
  %96 = shl i32 %95, 11
  %EFLAGS_4 = or i32 %96, %94
  %RIP_40 = add i64 %RIP_39, 2
  %EIP_32 = trunc i64 %RIP_40 to i32
  %IP_32 = trunc i64 %RIP_40 to i16
  store i32 %CtlSysEFLAGS_3, i32* %CtlSysEFLAGS
  store i8 0, i8* %DH
  store i8 0, i8* %DL
  store i16 0, i16* %DX
  store i32 0, i32* %EDX
  store i32 %EFLAGS_4, i32* %EFLAGS
  store i32 4195522, i32* %EIP
  store i16 1218, i16* %IP
  store i64 0, i64* %RDX
  store i64 4195522, i64* %RIP
  br i1 %CC_E_028, label %bb_4004C2, label %bb_4004CE

bb_4004CE:                                        ; preds = %bb_4004C4
  %RIP_43 = add i64 4195534, 1
  %EIP_34 = trunc i64 %RIP_43 to i32
  %IP_34 = trunc i64 %RIP_43 to i16
  %RSP_10 = load i64, i64* %RSP
  %RSP_11 = add i64 %RSP_10, 8
  %ESP_6 = trunc i64 %RSP_11 to i32
  %SP_6 = trunc i64 %RSP_11 to i16
  %SPL_6 = trunc i64 %RSP_11 to i8
  %97 = sub i64 %RSP_11, 8
  %98 = inttoptr i64 %97 to i64*
  %RBP_4 = load i64, i64* %98, align 1
  %EBP_4 = trunc i64 %RBP_4 to i32
  %BP_4 = trunc i64 %RBP_4 to i16
  %BPL_4 = trunc i64 %RBP_4 to i8
  %RIP_44 = add i64 %RIP_43, 3
  %EIP_35 = trunc i64 %RIP_44 to i32
  %IP_35 = trunc i64 %RIP_44 to i16
  %RAX_9 = load i64, i64* %RAX
  %ESI_0 = trunc i64 %RAX_9 to i32
  %SI_0 = trunc i64 %RAX_9 to i16
  %SIL_0 = trunc i64 %RAX_9 to i8
  %RIP_45 = add i64 %RIP_44, 5
  %EIP_36 = trunc i64 %RIP_45 to i32
  %IP_36 = trunc i64 %RIP_45 to i16
  %RDI_2 = load i64, i64* %RDI
  %RIP_46 = add i64 %RIP_45, 2
  %EIP_37 = trunc i64 %RIP_46 to i32
  %IP_37 = trunc i64 %RIP_46 to i16
  %RDX_3 = load i64, i64* %RDX
  %EIP_38 = trunc i64 %RDX_3 to i32
  %IP_38 = trunc i64 %RDX_3 to i16
  %99 = inttoptr i64 %RDX_3 to i8*
  %100 = call i8* @llvm.dc.translate.at(i8* %99)
  %101 = bitcast i8* %100 to void (%regset*)*
  store i16 %BP_4, i16* %BP
  store i8 %BPL_4, i8* %BPL
  store i16 4160, i16* %DI
  store i8 64, i8* %DIL
  store i32 %EBP_4, i32* %EBP
  store i32 6295616, i32* %EDI
  store i32 %EIP_38, i32* %EIP
  store i32 %ESI_0, i32* %ESI
  store i32 %ESP_6, i32* %ESP
  store i16 %IP_38, i16* %IP
  store i64 %RAX_9, i64* %RAX
  store i64 %RBP_4, i64* %RBP
  store i64 6295616, i64* %RDI
  store i64 %RDX_3, i64* %RDX
  store i64 %RDX_3, i64* %RIP
  store i64 %RAX_9, i64* %RSI
  store i64 %RSP_11, i64* %RSP
  store i16 %SI_0, i16* %SI
  store i8 %SIL_0, i8* %SIL
  store i16 %SP_6, i16* %SP
  store i8 %SPL_6, i8* %SPL
  %102 = load i32, i32* %CtlSysEFLAGS
  store i32 %102, i32* %CtlSysEFLAGS_ptr
  %103 = load i32, i32* %EFLAGS
  store i32 %103, i32* %EFLAGS_ptr
  %104 = load i64, i64* %RAX
  store i64 %104, i64* %RAX_ptr
  %105 = load i64, i64* %RBP
  store i64 %105, i64* %RBP_ptr
  %106 = load i64, i64* %RDI
  store i64 %106, i64* %RDI_ptr
  %107 = load i64, i64* %RDX
  store i64 %107, i64* %RDX_ptr
  %108 = load i64, i64* %RIP
  store i64 %108, i64* %RIP_ptr
  %109 = load i64, i64* %RSI
  store i64 %109, i64* %RSI_ptr
  %110 = load i64, i64* %RSP
  store i64 %110, i64* %RSP_ptr
  call void %101(%regset* %0)
  %111 = load i32, i32* %CtlSysEFLAGS_ptr
  store i32 %111, i32* %CtlSysEFLAGS
  %112 = load i32, i32* %EFLAGS_ptr
  store i32 %112, i32* %EFLAGS
  %113 = load i64, i64* %RAX_ptr
  store i64 %113, i64* %RAX
  %114 = load i64, i64* %RBP_ptr
  store i64 %114, i64* %RBP
  %115 = load i64, i64* %RDI_ptr
  store i64 %115, i64* %RDI
  %116 = load i64, i64* %RDX_ptr
  store i64 %116, i64* %RDX
  %117 = load i64, i64* %RIP_ptr
  store i64 %117, i64* %RIP
  %118 = load i64, i64* %RSI_ptr
  store i64 %118, i64* %RSI
  %119 = load i64, i64* %RSP_ptr
  store i64 %119, i64* %RSP
  br label %exit_fn_400500

bb_40050A:                                        ; preds = %bb_400500
  %RIP_5 = add i64 4195594, 5
  %EIP_3 = trunc i64 %RIP_5 to i32
  %IP_3 = trunc i64 %RIP_5 to i16
  %RAX_0 = load i64, i64* %RAX
  %RIP_6 = add i64 %RIP_5, 3
  %EIP_4 = trunc i64 %RIP_6 to i32
  %IP_4 = trunc i64 %RIP_6 to i16
  %120 = and i64 0, 0
  %CC_A_01 = icmp ugt i64 %120, 0
  %CC_AE_02 = icmp uge i64 %120, 0
  %CC_B_03 = icmp ult i64 %120, 0
  %CC_BE_04 = icmp ule i64 %120, 0
  %CC_L_05 = icmp slt i64 %120, 0
  %CC_LE_06 = icmp sle i64 %120, 0
  %CC_G_07 = icmp sgt i64 %120, 0
  %CC_GE_08 = icmp sge i64 %120, 0
  %CC_E_09 = icmp eq i64 %120, 0
  %CC_NE_010 = icmp ne i64 %120, 0
  %121 = sub i64 %120, 0
  %ZF_011 = icmp eq i64 %121, 0
  %SF_012 = icmp slt i64 %121, 0
  %122 = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 %120, i64 0)
  %OF_013 = extractvalue { i64, i1 } %122, 1
  %123 = call { i64, i1 } @llvm.usub.with.overflow.i64(i64 %120, i64 0)
  %CF_014 = extractvalue { i64, i1 } %123, 1
  %124 = trunc i64 %121 to i8
  %125 = call i8 @llvm.ctpop.i8(i8 %124)
  %126 = trunc i8 %125 to i1
  %PF_015 = icmp eq i1 %126, false
  %CtlSysEFLAGS_1 = load i32, i32* %CtlSysEFLAGS
  %127 = zext i1 %CF_014 to i32
  %128 = shl i32 %127, 0
  %129 = or i32 %128, %CtlSysEFLAGS_1
  %130 = zext i1 %PF_015 to i32
  %131 = shl i32 %130, 2
  %132 = or i32 %131, %129
  %133 = zext i1 false to i32
  %134 = shl i32 %133, 4
  %135 = or i32 %134, %132
  %136 = zext i1 %ZF_011 to i32
  %137 = shl i32 %136, 6
  %138 = or i32 %137, %135
  %139 = zext i1 %SF_012 to i32
  %140 = shl i32 %139, 7
  %141 = or i32 %140, %138
  %142 = zext i1 %OF_013 to i32
  %143 = shl i32 %142, 11
  %EFLAGS_1 = or i32 %143, %141
  %RIP_7 = add i64 %RIP_6, 2
  %EIP_5 = trunc i64 %RIP_7 to i32
  %IP_5 = trunc i64 %RIP_7 to i16
  store i8 0, i8* %AH
  store i8 0, i8* %AL
  store i16 0, i16* %AX
  store i32 %CtlSysEFLAGS_1, i32* %CtlSysEFLAGS
  store i32 0, i32* %EAX
  store i32 %EFLAGS_1, i32* %EFLAGS
  store i32 4195624, i32* %EIP
  store i16 1320, i16* %IP
  store i64 0, i64* %RAX
  store i64 4195624, i64* %RIP
  br i1 %CC_E_09, label %bb_400528, label %bb_400514

bb_400514:                                        ; preds = %bb_40050A
  %RIP_13 = add i64 4195604, 1
  %EIP_9 = trunc i64 %RIP_13 to i32
  %IP_9 = trunc i64 %RIP_13 to i16
  %RBP_0 = load i64, i64* %RBP
  %RSP_0 = load i64, i64* %RSP
  %144 = sub i64 %RSP_0, 8
  %145 = inttoptr i64 %144 to i64*
  store i64 %RBP_0, i64* %145, align 1
  %RSP_1 = sub i64 %RSP_0, 8
  %ESP_0 = trunc i64 %RSP_1 to i32
  %SP_0 = trunc i64 %RSP_1 to i16
  %SPL_0 = trunc i64 %RSP_1 to i8
  %RIP_14 = add i64 %RIP_13, 5
  %EIP_10 = trunc i64 %RIP_14 to i32
  %IP_10 = trunc i64 %RIP_14 to i16
  %RDI_0 = load i64, i64* %RDI
  %RIP_15 = add i64 %RIP_14, 3
  %EIP_11 = trunc i64 %RIP_15 to i32
  %IP_11 = trunc i64 %RIP_15 to i16
  %EBP_0 = trunc i64 %RSP_1 to i32
  %BP_0 = trunc i64 %RSP_1 to i16
  %BPL_0 = trunc i64 %RSP_1 to i8
  %RIP_16 = add i64 %RIP_15, 2
  %EIP_12 = trunc i64 %RIP_16 to i32
  %IP_12 = trunc i64 %RIP_16 to i16
  %RAX_2 = load i64, i64* %RAX
  %RSP_2 = sub i64 %RSP_1, 8
  %146 = inttoptr i64 %RSP_2 to i64*
  store i64 4195615, i64* %146
  %ESP_1 = trunc i64 %RSP_2 to i32
  %SP_1 = trunc i64 %RSP_2 to i16
  %SPL_1 = trunc i64 %RSP_2 to i8
  %147 = inttoptr i64 %RAX_2 to i8*
  %148 = call i8* @llvm.dc.translate.at(i8* %147)
  %149 = bitcast i8* %148 to void (%regset*)*
  store i16 %BP_0, i16* %BP
  store i8 %BPL_0, i8* %BPL
  store i16 3616, i16* %DI
  store i8 32, i8* %DIL
  store i32 %EBP_0, i32* %EBP
  store i32 6295072, i32* %EDI
  store i32 %EIP_12, i32* %EIP
  store i32 %ESP_1, i32* %ESP
  store i16 %IP_12, i16* %IP
  store i64 %RAX_2, i64* %RAX
  store i64 %RSP_1, i64* %RBP
  store i64 6295072, i64* %RDI
  store i64 %RIP_16, i64* %RIP
  store i64 %RSP_2, i64* %RSP
  store i16 %SP_1, i16* %SP
  store i8 %SPL_1, i8* %SPL
  %150 = load i32, i32* %CtlSysEFLAGS
  store i32 %150, i32* %CtlSysEFLAGS_ptr
  %151 = load i32, i32* %EFLAGS
  store i32 %151, i32* %EFLAGS_ptr
  %152 = load i64, i64* %RAX
  store i64 %152, i64* %RAX_ptr
  %153 = load i64, i64* %RBP
  store i64 %153, i64* %RBP_ptr
  %154 = load i64, i64* %RDI
  store i64 %154, i64* %RDI_ptr
  %155 = load i64, i64* %RDX
  store i64 %155, i64* %RDX_ptr
  %156 = load i64, i64* %RIP
  store i64 %156, i64* %RIP_ptr
  %157 = load i64, i64* %RSI
  store i64 %157, i64* %RSI_ptr
  %158 = load i64, i64* %RSP
  store i64 %158, i64* %RSP_ptr
  call void %149(%regset* %0)
  %159 = load i32, i32* %CtlSysEFLAGS_ptr
  store i32 %159, i32* %CtlSysEFLAGS
  %160 = load i32, i32* %EFLAGS_ptr
  store i32 %160, i32* %EFLAGS
  %161 = load i64, i64* %RAX_ptr
  store i64 %161, i64* %RAX
  %162 = load i64, i64* %RBP_ptr
  store i64 %162, i64* %RBP
  %163 = load i64, i64* %RDI_ptr
  store i64 %163, i64* %RDI
  %164 = load i64, i64* %RDX_ptr
  store i64 %164, i64* %RDX
  %165 = load i64, i64* %RIP_ptr
  store i64 %165, i64* %RIP
  %166 = load i64, i64* %RSI_ptr
  store i64 %166, i64* %RSI
  %167 = load i64, i64* %RSP_ptr
  store i64 %167, i64* %RSP
  %RIP_17 = load i64, i64* %RIP
  %RIP_18 = add i64 %RIP_17, 1
  %EIP_13 = trunc i64 %RIP_18 to i32
  %IP_13 = trunc i64 %RIP_18 to i16
  %RSP_3 = load i64, i64* %RSP
  %RSP_4 = add i64 %RSP_3, 8
  %ESP_2 = trunc i64 %RSP_4 to i32
  %SP_2 = trunc i64 %RSP_4 to i16
  %SPL_2 = trunc i64 %RSP_4 to i8
  %168 = sub i64 %RSP_4, 8
  %169 = inttoptr i64 %168 to i64*
  %RBP_1 = load i64, i64* %169, align 1
  %EBP_1 = trunc i64 %RBP_1 to i32
  %BP_1 = trunc i64 %RBP_1 to i16
  %BPL_1 = trunc i64 %RBP_1 to i8
  %RIP_19 = add i64 %RIP_18, 5
  %EIP_14 = trunc i64 %RIP_19 to i32
  %IP_14 = trunc i64 %RIP_19 to i16
  store i16 %BP_1, i16* %BP
  store i8 %BPL_1, i8* %BPL
  store i32 %EBP_1, i32* %EBP
  store i32 4195488, i32* %EIP
  store i32 %ESP_2, i32* %ESP
  store i16 1184, i16* %IP
  store i64 %RBP_1, i64* %RBP
  store i64 4195488, i64* %RIP
  store i64 %RSP_4, i64* %RSP
  store i16 %SP_2, i16* %SP
  store i8 %SPL_2, i8* %SPL
  br label %bb_4004A0

bb_400528:                                        ; preds = %bb_40050A, %bb_400500
  %RIP_10 = add i64 4195624, 5
  %EIP_7 = trunc i64 %RIP_10 to i32
  %IP_7 = trunc i64 %RIP_10 to i16
  store i32 4195488, i32* %EIP
  store i16 1184, i16* %IP
  store i64 4195488, i64* %RIP
  br label %bb_4004A0
}

define void @fn_400740(%regset* noalias nocapture) {
entry_fn_400740:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  %RSP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 16
  %RSP_init = load i64, i64* %RSP_ptr
  %RSP = alloca i64
  store i64 %RSP_init, i64* %RSP
  %ESP_init = trunc i64 %RSP_init to i32
  %ESP = alloca i32
  store i32 %ESP_init, i32* %ESP
  %SP_init = trunc i64 %RSP_init to i16
  %SP = alloca i16
  store i16 %SP_init, i16* %SP
  %SPL_init = trunc i64 %RSP_init to i8
  %SPL = alloca i8
  store i8 %SPL_init, i8* %SPL
  br label %bb_400740

exit_fn_400740:                                   ; preds = %bb_400740
  %1 = load i64, i64* %RIP
  store i64 %1, i64* %RIP_ptr
  %2 = load i64, i64* %RSP
  store i64 %2, i64* %RSP_ptr
  ret void

bb_400740:                                        ; preds = %entry_fn_400740
  %RIP_1 = add i64 4196160, 1
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %RIP_2 = add i64 %RIP_1, 1
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  %RSP_0 = load i64, i64* %RSP
  %RSP_1 = add i64 %RSP_0, 8
  %3 = inttoptr i64 %RSP_0 to i64*
  %RIP_3 = load i64, i64* %3
  %ESP_0 = trunc i64 %RSP_1 to i32
  %SP_0 = trunc i64 %RSP_1 to i16
  %SPL_0 = trunc i64 %RSP_1 to i8
  %EIP_2 = trunc i64 %RIP_3 to i32
  %IP_2 = trunc i64 %RIP_3 to i16
  store i32 %EIP_2, i32* %EIP
  store i32 %ESP_0, i32* %ESP
  store i16 %IP_2, i16* %IP
  store i64 %RIP_3, i64* %RIP
  store i64 %RSP_1, i64* %RSP
  store i16 %SP_0, i16* %SP
  store i8 %SPL_0, i8* %SPL
  br label %exit_fn_400740
}

define void @fn_400744(%regset* noalias nocapture) {
entry_fn_400744:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  %RSP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 16
  %RSP_init = load i64, i64* %RSP_ptr
  %RSP = alloca i64
  store i64 %RSP_init, i64* %RSP
  %ESP_init = trunc i64 %RSP_init to i32
  %ESP = alloca i32
  store i32 %ESP_init, i32* %ESP
  %SP_init = trunc i64 %RSP_init to i16
  %SP = alloca i16
  store i16 %SP_init, i16* %SP
  %SPL_init = trunc i64 %RSP_init to i8
  %SPL = alloca i8
  store i8 %SPL_init, i8* %SPL
  %EFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 3
  %EFLAGS_init = load i32, i32* %EFLAGS_ptr
  %EFLAGS = alloca i32
  store i32 %EFLAGS_init, i32* %EFLAGS
  %CtlSysEFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 1
  %CtlSysEFLAGS_init = load i32, i32* %CtlSysEFLAGS_ptr
  %CtlSysEFLAGS = alloca i32
  store i32 %CtlSysEFLAGS_init, i32* %CtlSysEFLAGS
  br label %bb_400744

exit_fn_400744:                                   ; preds = %bb_400744
  %1 = load i32, i32* %CtlSysEFLAGS
  store i32 %1, i32* %CtlSysEFLAGS_ptr
  %2 = load i32, i32* %EFLAGS
  store i32 %2, i32* %EFLAGS_ptr
  %3 = load i64, i64* %RIP
  store i64 %3, i64* %RIP_ptr
  %4 = load i64, i64* %RSP
  store i64 %4, i64* %RSP_ptr
  ret void

bb_400744:                                        ; preds = %entry_fn_400744
  %RIP_1 = add i64 4196164, 4
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %RSP_0 = load i64, i64* %RSP
  %RSP_1 = sub i64 %RSP_0, 8
  %ESP_0 = trunc i64 %RSP_1 to i32
  %SP_0 = trunc i64 %RSP_1 to i16
  %SPL_0 = trunc i64 %RSP_1 to i8
  %EFLAGS_0 = load i32, i32* %EFLAGS
  %RIP_2 = add i64 %RIP_1, 4
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  %RSP_2 = add i64 %RSP_1, 8
  %ESP_1 = trunc i64 %RSP_2 to i32
  %SP_1 = trunc i64 %RSP_2 to i16
  %SPL_1 = trunc i64 %RSP_2 to i8
  %RIP_3 = add i64 %RIP_2, 1
  %EIP_2 = trunc i64 %RIP_3 to i32
  %IP_2 = trunc i64 %RIP_3 to i16
  %RSP_3 = add i64 %RSP_2, 8
  %5 = inttoptr i64 %RSP_2 to i64*
  %RIP_4 = load i64, i64* %5
  %ESP_2 = trunc i64 %RSP_3 to i32
  %SP_2 = trunc i64 %RSP_3 to i16
  %SPL_2 = trunc i64 %RSP_3 to i8
  %EIP_3 = trunc i64 %RIP_4 to i32
  %IP_3 = trunc i64 %RIP_4 to i16
  %ZF_0 = icmp eq i64 %RSP_2, 0
  %SF_0 = icmp slt i64 %RSP_2, 0
  %6 = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %RSP_1, i64 8)
  %OF_0 = extractvalue { i64, i1 } %6, 1
  %7 = call { i64, i1 } @llvm.uadd.with.overflow.i64(i64 %RSP_1, i64 8)
  %CF_0 = extractvalue { i64, i1 } %7, 1
  %8 = trunc i64 %RSP_2 to i8
  %9 = call i8 @llvm.ctpop.i8(i8 %8)
  %10 = trunc i8 %9 to i1
  %PF_0 = icmp eq i1 %10, false
  %CtlSysEFLAGS_0 = load i32, i32* %CtlSysEFLAGS
  %11 = zext i1 %CF_0 to i32
  %12 = shl i32 %11, 0
  %13 = or i32 %12, %CtlSysEFLAGS_0
  %14 = zext i1 %PF_0 to i32
  %15 = shl i32 %14, 2
  %16 = or i32 %15, %13
  %17 = zext i1 false to i32
  %18 = shl i32 %17, 4
  %19 = or i32 %18, %16
  %20 = zext i1 %ZF_0 to i32
  %21 = shl i32 %20, 6
  %22 = or i32 %21, %19
  %23 = zext i1 %SF_0 to i32
  %24 = shl i32 %23, 7
  %25 = or i32 %24, %22
  %26 = zext i1 %OF_0 to i32
  %27 = shl i32 %26, 11
  %EFLAGS_1 = or i32 %27, %25
  store i32 %CtlSysEFLAGS_0, i32* %CtlSysEFLAGS
  store i32 %EFLAGS_1, i32* %EFLAGS
  store i32 %EIP_3, i32* %EIP
  store i32 %ESP_2, i32* %ESP
  store i16 %IP_3, i16* %IP
  store i64 %RIP_4, i64* %RIP
  store i64 %RSP_3, i64* %RSP
  store i16 %SP_2, i16* %SP
  store i8 %SPL_2, i8* %SPL
  br label %exit_fn_400744
}

define void @fn_4006D0(%regset* noalias nocapture) {
entry_fn_4006D0:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  %R15_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 76
  %R15_init = load i64, i64* %R15_ptr
  %R15 = alloca i64
  store i64 %R15_init, i64* %R15
  %RSP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 16
  %RSP_init = load i64, i64* %RSP_ptr
  %RSP = alloca i64
  store i64 %RSP_init, i64* %RSP
  %ESP_init = trunc i64 %RSP_init to i32
  %ESP = alloca i32
  store i32 %ESP_init, i32* %ESP
  %SP_init = trunc i64 %RSP_init to i16
  %SP = alloca i16
  store i16 %SP_init, i16* %SP
  %SPL_init = trunc i64 %RSP_init to i8
  %SPL = alloca i8
  store i8 %SPL_init, i8* %SPL
  %RDI_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 12
  %RDI_init = load i64, i64* %RDI_ptr
  %RDI = alloca i64
  store i64 %RDI_init, i64* %RDI
  %EDI_init = trunc i64 %RDI_init to i32
  %EDI = alloca i32
  store i32 %EDI_init, i32* %EDI
  %R15D_init = trunc i64 %R15_init to i32
  %R15D = alloca i32
  store i32 %R15D_init, i32* %R15D
  %R15W_init = trunc i64 %R15_init to i16
  %R15W = alloca i16
  store i16 %R15W_init, i16* %R15W
  %R15B_init = trunc i64 %R15_init to i8
  %R15B = alloca i8
  store i8 %R15B_init, i8* %R15B
  %R14_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 75
  %R14_init = load i64, i64* %R14_ptr
  %R14 = alloca i64
  store i64 %R14_init, i64* %R14
  %RSI_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 15
  %RSI_init = load i64, i64* %RSI_ptr
  %RSI = alloca i64
  store i64 %RSI_init, i64* %RSI
  %R14D_init = trunc i64 %R14_init to i32
  %R14D = alloca i32
  store i32 %R14D_init, i32* %R14D
  %R14W_init = trunc i64 %R14_init to i16
  %R14W = alloca i16
  store i16 %R14W_init, i16* %R14W
  %R14B_init = trunc i64 %R14_init to i8
  %R14B = alloca i8
  store i8 %R14B_init, i8* %R14B
  %R13_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 74
  %R13_init = load i64, i64* %R13_ptr
  %R13 = alloca i64
  store i64 %R13_init, i64* %R13
  %RDX_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 13
  %RDX_init = load i64, i64* %RDX_ptr
  %RDX = alloca i64
  store i64 %RDX_init, i64* %RDX
  %R13D_init = trunc i64 %R13_init to i32
  %R13D = alloca i32
  store i32 %R13D_init, i32* %R13D
  %R13W_init = trunc i64 %R13_init to i16
  %R13W = alloca i16
  store i16 %R13W_init, i16* %R13W
  %R13B_init = trunc i64 %R13_init to i8
  %R13B = alloca i8
  store i8 %R13B_init, i8* %R13B
  %R12_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 73
  %R12_init = load i64, i64* %R12_ptr
  %R12 = alloca i64
  store i64 %R12_init, i64* %R12
  %R12D_init = trunc i64 %R12_init to i32
  %R12D = alloca i32
  store i32 %R12D_init, i32* %R12D
  %R12W_init = trunc i64 %R12_init to i16
  %R12W = alloca i16
  store i16 %R12W_init, i16* %R12W
  %R12B_init = trunc i64 %R12_init to i8
  %R12B = alloca i8
  store i8 %R12B_init, i8* %R12B
  %RBP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 9
  %RBP_init = load i64, i64* %RBP_ptr
  %RBP = alloca i64
  store i64 %RBP_init, i64* %RBP
  %EBP_init = trunc i64 %RBP_init to i32
  %EBP = alloca i32
  store i32 %EBP_init, i32* %EBP
  %BP_init = trunc i64 %RBP_init to i16
  %BP = alloca i16
  store i16 %BP_init, i16* %BP
  %BPL_init = trunc i64 %RBP_init to i8
  %BPL = alloca i8
  store i8 %BPL_init, i8* %BPL
  %RBX_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 10
  %RBX_init = load i64, i64* %RBX_ptr
  %RBX = alloca i64
  store i64 %RBX_init, i64* %RBX
  %EFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 3
  %EFLAGS_init = load i32, i32* %EFLAGS_ptr
  %EFLAGS = alloca i32
  store i32 %EFLAGS_init, i32* %EFLAGS
  %EBX_init = trunc i64 %RBX_init to i32
  %EBX = alloca i32
  store i32 %EBX_init, i32* %EBX
  %BX_init = trunc i64 %RBX_init to i16
  %BX = alloca i16
  store i16 %BX_init, i16* %BX
  %BL_init = trunc i64 %RBX_init to i8
  %BL = alloca i8
  store i8 %BL_init, i8* %BL
  %1 = lshr i64 %RBX_init, 8
  %BH_init = trunc i64 %1 to i8
  %BH = alloca i8
  store i8 %BH_init, i8* %BH
  %CtlSysEFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 1
  %CtlSysEFLAGS_init = load i32, i32* %CtlSysEFLAGS_ptr
  %CtlSysEFLAGS = alloca i32
  store i32 %CtlSysEFLAGS_init, i32* %CtlSysEFLAGS
  %EDX_init = trunc i64 %RDX_init to i32
  %EDX = alloca i32
  store i32 %EDX_init, i32* %EDX
  %DX_init = trunc i64 %RDX_init to i16
  %DX = alloca i16
  store i16 %DX_init, i16* %DX
  %DL_init = trunc i64 %RDX_init to i8
  %DL = alloca i8
  store i8 %DL_init, i8* %DL
  %2 = lshr i64 %RDX_init, 8
  %DH_init = trunc i64 %2 to i8
  %DH = alloca i8
  store i8 %DH_init, i8* %DH
  %ESI_init = trunc i64 %RSI_init to i32
  %ESI = alloca i32
  store i32 %ESI_init, i32* %ESI
  %SI_init = trunc i64 %RSI_init to i16
  %SI = alloca i16
  store i16 %SI_init, i16* %SI
  %SIL_init = trunc i64 %RSI_init to i8
  %SIL = alloca i8
  store i8 %SIL_init, i8* %SIL
  %DI_init = trunc i64 %RDI_init to i16
  %DI = alloca i16
  store i16 %DI_init, i16* %DI
  %DIL_init = trunc i64 %RDI_init to i8
  %DIL = alloca i8
  store i8 %DIL_init, i8* %DIL
  br label %bb_4006D0

exit_fn_4006D0:                                   ; preds = %bb_400726
  %3 = load i32, i32* %CtlSysEFLAGS
  store i32 %3, i32* %CtlSysEFLAGS_ptr
  %4 = load i32, i32* %EFLAGS
  store i32 %4, i32* %EFLAGS_ptr
  %5 = load i64, i64* %RBP
  store i64 %5, i64* %RBP_ptr
  %6 = load i64, i64* %RBX
  store i64 %6, i64* %RBX_ptr
  %7 = load i64, i64* %RDI
  store i64 %7, i64* %RDI_ptr
  %8 = load i64, i64* %RDX
  store i64 %8, i64* %RDX_ptr
  %9 = load i64, i64* %RIP
  store i64 %9, i64* %RIP_ptr
  %10 = load i64, i64* %RSI
  store i64 %10, i64* %RSI_ptr
  %11 = load i64, i64* %RSP
  store i64 %11, i64* %RSP_ptr
  %12 = load i64, i64* %R12
  store i64 %12, i64* %R12_ptr
  %13 = load i64, i64* %R13
  store i64 %13, i64* %R13_ptr
  %14 = load i64, i64* %R14
  store i64 %14, i64* %R14_ptr
  %15 = load i64, i64* %R15
  store i64 %15, i64* %R15_ptr
  ret void

bb_4006D0:                                        ; preds = %entry_fn_4006D0
  %RIP_1 = add i64 4196048, 2
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %R15_0 = load i64, i64* %R15
  %RSP_0 = load i64, i64* %RSP
  %16 = sub i64 %RSP_0, 8
  %17 = inttoptr i64 %16 to i64*
  store i64 %R15_0, i64* %17, align 1
  %RSP_1 = sub i64 %RSP_0, 8
  %ESP_0 = trunc i64 %RSP_1 to i32
  %SP_0 = trunc i64 %RSP_1 to i16
  %SPL_0 = trunc i64 %RSP_1 to i8
  %RIP_2 = add i64 %RIP_1, 3
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  %RDI_0 = load i64, i64* %RDI
  %EDI_0 = trunc i64 %RDI_0 to i32
  %R15_1 = zext i32 %EDI_0 to i64
  %R15W_0 = trunc i32 %EDI_0 to i16
  %R15B_0 = trunc i32 %EDI_0 to i8
  %RIP_3 = add i64 %RIP_2, 2
  %EIP_2 = trunc i64 %RIP_3 to i32
  %IP_2 = trunc i64 %RIP_3 to i16
  %R14_0 = load i64, i64* %R14
  %18 = sub i64 %RSP_1, 8
  %19 = inttoptr i64 %18 to i64*
  store i64 %R14_0, i64* %19, align 1
  %RSP_2 = sub i64 %RSP_1, 8
  %ESP_1 = trunc i64 %RSP_2 to i32
  %SP_1 = trunc i64 %RSP_2 to i16
  %SPL_1 = trunc i64 %RSP_2 to i8
  %RIP_4 = add i64 %RIP_3, 3
  %EIP_3 = trunc i64 %RIP_4 to i32
  %IP_3 = trunc i64 %RIP_4 to i16
  %RSI_0 = load i64, i64* %RSI
  %R14D_0 = trunc i64 %RSI_0 to i32
  %R14W_0 = trunc i64 %RSI_0 to i16
  %R14B_0 = trunc i64 %RSI_0 to i8
  %RIP_5 = add i64 %RIP_4, 2
  %EIP_4 = trunc i64 %RIP_5 to i32
  %IP_4 = trunc i64 %RIP_5 to i16
  %R13_0 = load i64, i64* %R13
  %20 = sub i64 %RSP_2, 8
  %21 = inttoptr i64 %20 to i64*
  store i64 %R13_0, i64* %21, align 1
  %RSP_3 = sub i64 %RSP_2, 8
  %ESP_2 = trunc i64 %RSP_3 to i32
  %SP_2 = trunc i64 %RSP_3 to i16
  %SPL_2 = trunc i64 %RSP_3 to i8
  %RIP_6 = add i64 %RIP_5, 3
  %EIP_5 = trunc i64 %RIP_6 to i32
  %IP_5 = trunc i64 %RIP_6 to i16
  %RDX_0 = load i64, i64* %RDX
  %R13D_0 = trunc i64 %RDX_0 to i32
  %R13W_0 = trunc i64 %RDX_0 to i16
  %R13B_0 = trunc i64 %RDX_0 to i8
  %RIP_7 = add i64 %RIP_6, 2
  %EIP_6 = trunc i64 %RIP_7 to i32
  %IP_6 = trunc i64 %RIP_7 to i16
  %R12_0 = load i64, i64* %R12
  %22 = sub i64 %RSP_3, 8
  %23 = inttoptr i64 %22 to i64*
  store i64 %R12_0, i64* %23, align 1
  %RSP_4 = sub i64 %RSP_3, 8
  %ESP_3 = trunc i64 %RSP_4 to i32
  %SP_3 = trunc i64 %RSP_4 to i16
  %SPL_3 = trunc i64 %RSP_4 to i8
  %RIP_8 = add i64 %RIP_7, 7
  %EIP_7 = trunc i64 %RIP_8 to i32
  %IP_7 = trunc i64 %RIP_8 to i16
  %R12_1 = add i64 %RIP_8, 2098984
  %R12D_0 = trunc i64 %R12_1 to i32
  %R12W_0 = trunc i64 %R12_1 to i16
  %R12B_0 = trunc i64 %R12_1 to i8
  %RIP_9 = add i64 %RIP_8, 1
  %EIP_8 = trunc i64 %RIP_9 to i32
  %IP_8 = trunc i64 %RIP_9 to i16
  %RBP_0 = load i64, i64* %RBP
  %24 = sub i64 %RSP_4, 8
  %25 = inttoptr i64 %24 to i64*
  store i64 %RBP_0, i64* %25, align 1
  %RSP_5 = sub i64 %RSP_4, 8
  %ESP_4 = trunc i64 %RSP_5 to i32
  %SP_4 = trunc i64 %RSP_5 to i16
  %SPL_4 = trunc i64 %RSP_5 to i8
  %RIP_10 = add i64 %RIP_9, 7
  %EIP_9 = trunc i64 %RIP_10 to i32
  %IP_9 = trunc i64 %RIP_10 to i16
  %RBP_1 = add i64 %RIP_10, 2098984
  %EBP_0 = trunc i64 %RBP_1 to i32
  %BP_0 = trunc i64 %RBP_1 to i16
  %BPL_0 = trunc i64 %RBP_1 to i8
  %RIP_11 = add i64 %RIP_10, 1
  %EIP_10 = trunc i64 %RIP_11 to i32
  %IP_10 = trunc i64 %RIP_11 to i16
  %RBX_0 = load i64, i64* %RBX
  %26 = sub i64 %RSP_5, 8
  %27 = inttoptr i64 %26 to i64*
  store i64 %RBX_0, i64* %27, align 1
  %RSP_6 = sub i64 %RSP_5, 8
  %ESP_5 = trunc i64 %RSP_6 to i32
  %SP_5 = trunc i64 %RSP_6 to i16
  %SPL_5 = trunc i64 %RSP_6 to i8
  %RIP_12 = add i64 %RIP_11, 3
  %EIP_11 = trunc i64 %RIP_12 to i32
  %IP_11 = trunc i64 %RIP_12 to i16
  %RBP_2 = sub i64 %RBP_1, %R12_1
  %EBP_1 = trunc i64 %RBP_2 to i32
  %BP_1 = trunc i64 %RBP_2 to i16
  %BPL_1 = trunc i64 %RBP_2 to i8
  %EFLAGS_0 = load i32, i32* %EFLAGS
  %RIP_13 = add i64 %RIP_12, 2
  %EIP_12 = trunc i64 %RIP_13 to i32
  %IP_12 = trunc i64 %RIP_13 to i16
  %EBX_0 = trunc i64 %RBX_0 to i32
  %EBX_1 = xor i32 %EBX_0, %EBX_0
  %RBX_1 = zext i32 %EBX_1 to i64
  %BX_0 = trunc i32 %EBX_1 to i16
  %BL_0 = trunc i32 %EBX_1 to i8
  %28 = lshr i32 %EBX_1, 8
  %BH_0 = trunc i32 %28 to i8
  %RIP_14 = add i64 %RIP_13, 4
  %EIP_13 = trunc i64 %RIP_14 to i32
  %IP_13 = trunc i64 %RIP_14 to i16
  %29 = zext i8 3 to i64
  %RBP_3 = ashr i64 %RBP_2, %29
  %EBP_2 = trunc i64 %RBP_3 to i32
  %BP_2 = trunc i64 %RBP_3 to i16
  %BPL_2 = trunc i64 %RBP_3 to i8
  %RIP_15 = add i64 %RIP_14, 4
  %EIP_14 = trunc i64 %RIP_15 to i32
  %IP_14 = trunc i64 %RIP_15 to i16
  %RSP_7 = sub i64 %RSP_6, 8
  %ESP_6 = trunc i64 %RSP_7 to i32
  %SP_6 = trunc i64 %RSP_7 to i16
  %SPL_6 = trunc i64 %RSP_7 to i8
  %RIP_16 = add i64 %RIP_15, 5
  %EIP_15 = trunc i64 %RIP_16 to i32
  %IP_15 = trunc i64 %RIP_16 to i16
  %RSP_8 = sub i64 %RSP_7, 8
  %30 = inttoptr i64 %RSP_8 to i64*
  store i64 4196099, i64* %30
  %ESP_7 = trunc i64 %RSP_8 to i32
  %SP_7 = trunc i64 %RSP_8 to i16
  %SPL_7 = trunc i64 %RSP_8 to i8
  store i8 %BH_0, i8* %BH
  store i8 %BL_0, i8* %BL
  store i16 %BP_2, i16* %BP
  store i8 %BPL_2, i8* %BPL
  store i16 %BX_0, i16* %BX
  store i32 %EBP_2, i32* %EBP
  store i32 %EBX_1, i32* %EBX
  store i32 %EDI_0, i32* %EDI
  %ZF_0 = icmp eq i64 %RSP_7, 0
  %SF_0 = icmp slt i64 %RSP_7, 0
  %31 = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 %RSP_6, i64 8)
  %OF_0 = extractvalue { i64, i1 } %31, 1
  %32 = call { i64, i1 } @llvm.usub.with.overflow.i64(i64 %RSP_6, i64 8)
  %CF_0 = extractvalue { i64, i1 } %32, 1
  %33 = trunc i64 %RSP_7 to i8
  %34 = call i8 @llvm.ctpop.i8(i8 %33)
  %35 = trunc i8 %34 to i1
  %PF_0 = icmp eq i1 %35, false
  %CtlSysEFLAGS_0 = load i32, i32* %CtlSysEFLAGS
  %36 = zext i1 %CF_0 to i32
  %37 = shl i32 %36, 0
  %38 = or i32 %37, %CtlSysEFLAGS_0
  %39 = zext i1 %PF_0 to i32
  %40 = shl i32 %39, 2
  %41 = or i32 %40, %38
  %42 = zext i1 false to i32
  %43 = shl i32 %42, 4
  %44 = or i32 %43, %41
  %45 = zext i1 %ZF_0 to i32
  %46 = shl i32 %45, 6
  %47 = or i32 %46, %44
  %48 = zext i1 %SF_0 to i32
  %49 = shl i32 %48, 7
  %50 = or i32 %49, %47
  %51 = zext i1 %OF_0 to i32
  %52 = shl i32 %51, 11
  %EFLAGS_1 = or i32 %52, %50
  store i32 %EFLAGS_1, i32* %EFLAGS
  store i32 %EIP_15, i32* %EIP
  store i32 %ESP_7, i32* %ESP
  store i16 %IP_15, i16* %IP
  store i64 %RBP_3, i64* %RBP
  store i64 %RBX_1, i64* %RBX
  store i64 %RDI_0, i64* %RDI
  store i64 %RDX_0, i64* %RDX
  store i64 %RIP_16, i64* %RIP
  store i64 %RSI_0, i64* %RSI
  store i64 %RSP_8, i64* %RSP
  store i16 %SP_7, i16* %SP
  store i8 %SPL_7, i8* %SPL
  store i64 %R12_1, i64* %R12
  store i64 %RDX_0, i64* %R13
  store i64 %RSI_0, i64* %R14
  store i64 %R15_1, i64* %R15
  store i8 %R12B_0, i8* %R12B
  store i8 %R13B_0, i8* %R13B
  store i8 %R14B_0, i8* %R14B
  store i8 %R15B_0, i8* %R15B
  store i32 %R12D_0, i32* %R12D
  store i32 %R13D_0, i32* %R13D
  store i32 %R14D_0, i32* %R14D
  store i32 %EDI_0, i32* %R15D
  store i16 %R12W_0, i16* %R12W
  store i16 %R13W_0, i16* %R13W
  store i16 %R14W_0, i16* %R14W
  store i16 %R15W_0, i16* %R15W
  %53 = load i32, i32* %CtlSysEFLAGS
  store i32 %53, i32* %CtlSysEFLAGS_ptr
  %54 = load i32, i32* %EFLAGS
  store i32 %54, i32* %EFLAGS_ptr
  %55 = load i64, i64* %RBP
  store i64 %55, i64* %RBP_ptr
  %56 = load i64, i64* %RBX
  store i64 %56, i64* %RBX_ptr
  %57 = load i64, i64* %RDI
  store i64 %57, i64* %RDI_ptr
  %58 = load i64, i64* %RDX
  store i64 %58, i64* %RDX_ptr
  %59 = load i64, i64* %RIP
  store i64 %59, i64* %RIP_ptr
  %60 = load i64, i64* %RSI
  store i64 %60, i64* %RSI_ptr
  %61 = load i64, i64* %RSP
  store i64 %61, i64* %RSP_ptr
  %62 = load i64, i64* %R12
  store i64 %62, i64* %R12_ptr
  %63 = load i64, i64* %R13
  store i64 %63, i64* %R13_ptr
  %64 = load i64, i64* %R14
  store i64 %64, i64* %R14_ptr
  %65 = load i64, i64* %R15
  store i64 %65, i64* %R15_ptr
  call void @fn_4003E0(%regset* %0)
  %66 = load i32, i32* %CtlSysEFLAGS_ptr
  store i32 %66, i32* %CtlSysEFLAGS
  %67 = load i32, i32* %EFLAGS_ptr
  store i32 %67, i32* %EFLAGS
  %68 = load i64, i64* %RBP_ptr
  store i64 %68, i64* %RBP
  %69 = load i64, i64* %RBX_ptr
  store i64 %69, i64* %RBX
  %70 = load i64, i64* %RDI_ptr
  store i64 %70, i64* %RDI
  %71 = load i64, i64* %RDX_ptr
  store i64 %71, i64* %RDX
  %72 = load i64, i64* %RIP_ptr
  store i64 %72, i64* %RIP
  %73 = load i64, i64* %RSI_ptr
  store i64 %73, i64* %RSI
  %74 = load i64, i64* %RSP_ptr
  store i64 %74, i64* %RSP
  %75 = load i64, i64* %R12_ptr
  store i64 %75, i64* %R12
  %76 = load i64, i64* %R13_ptr
  store i64 %76, i64* %R13
  %77 = load i64, i64* %R14_ptr
  store i64 %77, i64* %R14
  %78 = load i64, i64* %R15_ptr
  store i64 %78, i64* %R15
  %RIP_17 = load i64, i64* %RIP
  %RIP_18 = add i64 %RIP_17, 3
  %EIP_16 = trunc i64 %RIP_18 to i32
  %IP_16 = trunc i64 %RIP_18 to i16
  %RBP_4 = load i64, i64* %RBP
  %79 = and i64 %RBP_4, %RBP_4
  %CC_A_0 = icmp ugt i64 %79, 0
  %CC_AE_0 = icmp uge i64 %79, 0
  %CC_B_0 = icmp ult i64 %79, 0
  %CC_BE_0 = icmp ule i64 %79, 0
  %CC_L_0 = icmp slt i64 %79, 0
  %CC_LE_0 = icmp sle i64 %79, 0
  %CC_G_0 = icmp sgt i64 %79, 0
  %CC_GE_0 = icmp sge i64 %79, 0
  %CC_E_0 = icmp eq i64 %79, 0
  %CC_NE_0 = icmp ne i64 %79, 0
  %80 = sub i64 %79, 0
  %ZF_1 = icmp eq i64 %80, 0
  %SF_1 = icmp slt i64 %80, 0
  %81 = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 %79, i64 0)
  %OF_1 = extractvalue { i64, i1 } %81, 1
  %82 = call { i64, i1 } @llvm.usub.with.overflow.i64(i64 %79, i64 0)
  %CF_1 = extractvalue { i64, i1 } %82, 1
  %83 = trunc i64 %80 to i8
  %84 = call i8 @llvm.ctpop.i8(i8 %83)
  %85 = trunc i8 %84 to i1
  %PF_1 = icmp eq i1 %85, false
  %86 = zext i1 %CF_1 to i32
  %87 = shl i32 %86, 0
  %88 = or i32 %87, %CtlSysEFLAGS_0
  %89 = zext i1 %PF_1 to i32
  %90 = shl i32 %89, 2
  %91 = or i32 %90, %88
  %92 = zext i1 false to i32
  %93 = shl i32 %92, 4
  %94 = or i32 %93, %91
  %95 = zext i1 %ZF_1 to i32
  %96 = shl i32 %95, 6
  %97 = or i32 %96, %94
  %98 = zext i1 %SF_1 to i32
  %99 = shl i32 %98, 7
  %100 = or i32 %99, %97
  %101 = zext i1 %OF_1 to i32
  %102 = shl i32 %101, 11
  %EFLAGS_2 = or i32 %102, %100
  %RIP_19 = add i64 %RIP_18, 2
  %EIP_17 = trunc i64 %RIP_19 to i32
  %IP_17 = trunc i64 %RIP_19 to i16
  store i32 %CtlSysEFLAGS_0, i32* %CtlSysEFLAGS
  store i32 %EFLAGS_2, i32* %EFLAGS
  store i32 4196134, i32* %EIP
  store i16 1830, i16* %IP
  store i64 %RBP_4, i64* %RBP
  store i64 4196134, i64* %RIP
  br i1 %CC_E_0, label %bb_400726, label %bb_400708

bb_400708:                                        ; preds = %bb_4006D0
  %RIP_22 = add i64 4196104, 8
  %EIP_19 = trunc i64 %RIP_22 to i32
  %IP_19 = trunc i64 %RIP_22 to i16
  store i32 %EIP_19, i32* %EIP
  store i16 %IP_19, i16* %IP
  store i64 %RIP_22, i64* %RIP
  br label %bb_400710

bb_400710:                                        ; preds = %bb_400710, %bb_400708
  %RIP_34 = add i64 4196112, 3
  %EIP_29 = trunc i64 %RIP_34 to i32
  %IP_29 = trunc i64 %RIP_34 to i16
  %R13_2 = load i64, i64* %R13
  %EDX_0 = trunc i64 %R13_2 to i32
  %DX_0 = trunc i64 %R13_2 to i16
  %DL_0 = trunc i64 %R13_2 to i8
  %103 = lshr i64 %R13_2, 8
  %DH_0 = trunc i64 %103 to i8
  %RIP_35 = add i64 %RIP_34, 3
  %EIP_30 = trunc i64 %RIP_35 to i32
  %IP_30 = trunc i64 %RIP_35 to i16
  %R14_2 = load i64, i64* %R14
  %ESI_0 = trunc i64 %R14_2 to i32
  %SI_0 = trunc i64 %R14_2 to i16
  %SIL_0 = trunc i64 %R14_2 to i8
  %RIP_36 = add i64 %RIP_35, 3
  %EIP_31 = trunc i64 %RIP_36 to i32
  %IP_31 = trunc i64 %RIP_36 to i16
  %R15_3 = load i64, i64* %R15
  %R15D_1 = trunc i64 %R15_3 to i32
  %RDI_1 = load i64, i64* %RDI
  %RDI_2 = zext i32 %R15D_1 to i64
  %DI_0 = trunc i32 %R15D_1 to i16
  %DIL_0 = trunc i32 %R15D_1 to i8
  %RIP_37 = add i64 %RIP_36, 4
  %EIP_32 = trunc i64 %RIP_37 to i32
  %IP_32 = trunc i64 %RIP_37 to i16
  %R12_3 = load i64, i64* %R12
  %RBX_3 = load i64, i64* %RBX
  %104 = mul i64 %RBX_3, 8
  %105 = add i64 %R12_3, %104
  %106 = inttoptr i64 %105 to i64*
  %107 = load i64, i64* %106, align 1
  %RSP_18 = load i64, i64* %RSP
  %RSP_19 = sub i64 %RSP_18, 8
  %108 = inttoptr i64 %RSP_19 to i64*
  store i64 4196125, i64* %108
  %ESP_16 = trunc i64 %RSP_19 to i32
  %SP_16 = trunc i64 %RSP_19 to i16
  %SPL_16 = trunc i64 %RSP_19 to i8
  %109 = inttoptr i64 %107 to i8*
  %110 = call i8* @llvm.dc.translate.at(i8* %109)
  %111 = bitcast i8* %110 to void (%regset*)*
  store i8 %DH_0, i8* %DH
  store i16 %DI_0, i16* %DI
  store i8 %DIL_0, i8* %DIL
  store i8 %DL_0, i8* %DL
  store i16 %DX_0, i16* %DX
  store i32 %R15D_1, i32* %EDI
  store i32 %EDX_0, i32* %EDX
  store i32 %EIP_32, i32* %EIP
  store i32 %ESI_0, i32* %ESI
  store i32 %ESP_16, i32* %ESP
  store i16 %IP_32, i16* %IP
  store i64 %RBX_3, i64* %RBX
  store i64 %RDI_2, i64* %RDI
  store i64 %R13_2, i64* %RDX
  store i64 %RIP_37, i64* %RIP
  store i64 %R14_2, i64* %RSI
  store i64 %RSP_19, i64* %RSP
  store i16 %SI_0, i16* %SI
  store i8 %SIL_0, i8* %SIL
  store i16 %SP_16, i16* %SP
  store i8 %SPL_16, i8* %SPL
  store i64 %R12_3, i64* %R12
  store i64 %R13_2, i64* %R13
  store i64 %R14_2, i64* %R14
  store i64 %R15_3, i64* %R15
  store i32 %R15D_1, i32* %R15D
  %112 = load i32, i32* %CtlSysEFLAGS
  store i32 %112, i32* %CtlSysEFLAGS_ptr
  %113 = load i32, i32* %EFLAGS
  store i32 %113, i32* %EFLAGS_ptr
  %114 = load i64, i64* %RBP
  store i64 %114, i64* %RBP_ptr
  %115 = load i64, i64* %RBX
  store i64 %115, i64* %RBX_ptr
  %116 = load i64, i64* %RDI
  store i64 %116, i64* %RDI_ptr
  %117 = load i64, i64* %RDX
  store i64 %117, i64* %RDX_ptr
  %118 = load i64, i64* %RIP
  store i64 %118, i64* %RIP_ptr
  %119 = load i64, i64* %RSI
  store i64 %119, i64* %RSI_ptr
  %120 = load i64, i64* %RSP
  store i64 %120, i64* %RSP_ptr
  %121 = load i64, i64* %R12
  store i64 %121, i64* %R12_ptr
  %122 = load i64, i64* %R13
  store i64 %122, i64* %R13_ptr
  %123 = load i64, i64* %R14
  store i64 %123, i64* %R14_ptr
  %124 = load i64, i64* %R15
  store i64 %124, i64* %R15_ptr
  call void %111(%regset* %0)
  %125 = load i32, i32* %CtlSysEFLAGS_ptr
  store i32 %125, i32* %CtlSysEFLAGS
  %126 = load i32, i32* %EFLAGS_ptr
  store i32 %126, i32* %EFLAGS
  %127 = load i64, i64* %RBP_ptr
  store i64 %127, i64* %RBP
  %128 = load i64, i64* %RBX_ptr
  store i64 %128, i64* %RBX
  %129 = load i64, i64* %RDI_ptr
  store i64 %129, i64* %RDI
  %130 = load i64, i64* %RDX_ptr
  store i64 %130, i64* %RDX
  %131 = load i64, i64* %RIP_ptr
  store i64 %131, i64* %RIP
  %132 = load i64, i64* %RSI_ptr
  store i64 %132, i64* %RSI
  %133 = load i64, i64* %RSP_ptr
  store i64 %133, i64* %RSP
  %134 = load i64, i64* %R12_ptr
  store i64 %134, i64* %R12
  %135 = load i64, i64* %R13_ptr
  store i64 %135, i64* %R13
  %136 = load i64, i64* %R14_ptr
  store i64 %136, i64* %R14
  %137 = load i64, i64* %R15_ptr
  store i64 %137, i64* %R15
  %RIP_38 = load i64, i64* %RIP
  %RIP_39 = add i64 %RIP_38, 4
  %EIP_33 = trunc i64 %RIP_39 to i32
  %IP_33 = trunc i64 %RIP_39 to i16
  %RBX_4 = load i64, i64* %RBX
  %RBX_5 = add i64 %RBX_4, 1
  %EBX_3 = trunc i64 %RBX_5 to i32
  %BX_2 = trunc i64 %RBX_5 to i16
  %BL_2 = trunc i64 %RBX_5 to i8
  %138 = lshr i64 %RBX_5, 8
  %BH_2 = trunc i64 %138 to i8
  %EFLAGS_5 = load i32, i32* %EFLAGS
  %RIP_40 = add i64 %RIP_39, 3
  %EIP_34 = trunc i64 %RIP_40 to i32
  %IP_34 = trunc i64 %RIP_40 to i16
  %RBP_6 = load i64, i64* %RBP
  %CC_A_06 = icmp ugt i64 %RBX_5, %RBP_6
  %CC_AE_07 = icmp uge i64 %RBX_5, %RBP_6
  %CC_B_08 = icmp ult i64 %RBX_5, %RBP_6
  %CC_BE_09 = icmp ule i64 %RBX_5, %RBP_6
  %CC_L_010 = icmp slt i64 %RBX_5, %RBP_6
  %CC_LE_011 = icmp sle i64 %RBX_5, %RBP_6
  %CC_G_012 = icmp sgt i64 %RBX_5, %RBP_6
  %CC_GE_013 = icmp sge i64 %RBX_5, %RBP_6
  %CC_E_014 = icmp eq i64 %RBX_5, %RBP_6
  %CC_NE_015 = icmp ne i64 %RBX_5, %RBP_6
  %139 = sub i64 %RBX_5, %RBP_6
  %ZF_016 = icmp eq i64 %139, 0
  %SF_017 = icmp slt i64 %139, 0
  %140 = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 %RBX_5, i64 %RBP_6)
  %OF_018 = extractvalue { i64, i1 } %140, 1
  %141 = call { i64, i1 } @llvm.usub.with.overflow.i64(i64 %RBX_5, i64 %RBP_6)
  %CF_019 = extractvalue { i64, i1 } %141, 1
  %142 = trunc i64 %139 to i8
  %143 = call i8 @llvm.ctpop.i8(i8 %142)
  %144 = trunc i8 %143 to i1
  %PF_020 = icmp eq i1 %144, false
  %CtlSysEFLAGS_2 = load i32, i32* %CtlSysEFLAGS
  %145 = zext i1 %CF_019 to i32
  %146 = shl i32 %145, 0
  %147 = or i32 %146, %CtlSysEFLAGS_2
  %148 = zext i1 %PF_020 to i32
  %149 = shl i32 %148, 2
  %150 = or i32 %149, %147
  %151 = zext i1 false to i32
  %152 = shl i32 %151, 4
  %153 = or i32 %152, %150
  %154 = zext i1 %ZF_016 to i32
  %155 = shl i32 %154, 6
  %156 = or i32 %155, %153
  %157 = zext i1 %SF_017 to i32
  %158 = shl i32 %157, 7
  %159 = or i32 %158, %156
  %160 = zext i1 %OF_018 to i32
  %161 = shl i32 %160, 11
  %EFLAGS_6 = or i32 %161, %159
  %RIP_41 = add i64 %RIP_40, 2
  %EIP_35 = trunc i64 %RIP_41 to i32
  %IP_35 = trunc i64 %RIP_41 to i16
  store i8 %BH_2, i8* %BH
  store i8 %BL_2, i8* %BL
  store i16 %BX_2, i16* %BX
  store i32 %CtlSysEFLAGS_2, i32* %CtlSysEFLAGS
  store i32 %EBX_3, i32* %EBX
  store i32 %EFLAGS_6, i32* %EFLAGS
  store i32 4196112, i32* %EIP
  store i16 1808, i16* %IP
  store i64 %RBP_6, i64* %RBP
  store i64 %RBX_5, i64* %RBX
  store i64 4196112, i64* %RIP
  br i1 %CC_NE_015, label %bb_400710, label %bb_400726

bb_400726:                                        ; preds = %bb_400710, %bb_4006D0
  %RIP_24 = add i64 4196134, 4
  %EIP_20 = trunc i64 %RIP_24 to i32
  %IP_20 = trunc i64 %RIP_24 to i16
  %RSP_9 = load i64, i64* %RSP
  %RSP_10 = add i64 %RSP_9, 8
  %ESP_8 = trunc i64 %RSP_10 to i32
  %SP_8 = trunc i64 %RSP_10 to i16
  %SPL_8 = trunc i64 %RSP_10 to i8
  %EFLAGS_3 = load i32, i32* %EFLAGS
  %RIP_25 = add i64 %RIP_24, 1
  %EIP_21 = trunc i64 %RIP_25 to i32
  %IP_21 = trunc i64 %RIP_25 to i16
  %RSP_11 = add i64 %RSP_10, 8
  %ESP_9 = trunc i64 %RSP_11 to i32
  %SP_9 = trunc i64 %RSP_11 to i16
  %SPL_9 = trunc i64 %RSP_11 to i8
  %162 = sub i64 %RSP_11, 8
  %163 = inttoptr i64 %162 to i64*
  %RBX_2 = load i64, i64* %163, align 1
  %EBX_2 = trunc i64 %RBX_2 to i32
  %BX_1 = trunc i64 %RBX_2 to i16
  %BL_1 = trunc i64 %RBX_2 to i8
  %164 = lshr i64 %RBX_2, 8
  %BH_1 = trunc i64 %164 to i8
  %RIP_26 = add i64 %RIP_25, 1
  %EIP_22 = trunc i64 %RIP_26 to i32
  %IP_22 = trunc i64 %RIP_26 to i16
  %RSP_12 = add i64 %RSP_11, 8
  %ESP_10 = trunc i64 %RSP_12 to i32
  %SP_10 = trunc i64 %RSP_12 to i16
  %SPL_10 = trunc i64 %RSP_12 to i8
  %165 = sub i64 %RSP_12, 8
  %166 = inttoptr i64 %165 to i64*
  %RBP_5 = load i64, i64* %166, align 1
  %EBP_3 = trunc i64 %RBP_5 to i32
  %BP_3 = trunc i64 %RBP_5 to i16
  %BPL_3 = trunc i64 %RBP_5 to i8
  %RIP_27 = add i64 %RIP_26, 2
  %EIP_23 = trunc i64 %RIP_27 to i32
  %IP_23 = trunc i64 %RIP_27 to i16
  %RSP_13 = add i64 %RSP_12, 8
  %ESP_11 = trunc i64 %RSP_13 to i32
  %SP_11 = trunc i64 %RSP_13 to i16
  %SPL_11 = trunc i64 %RSP_13 to i8
  %167 = sub i64 %RSP_13, 8
  %168 = inttoptr i64 %167 to i64*
  %R12_2 = load i64, i64* %168, align 1
  %R12D_1 = trunc i64 %R12_2 to i32
  %R12W_1 = trunc i64 %R12_2 to i16
  %R12B_1 = trunc i64 %R12_2 to i8
  %RIP_28 = add i64 %RIP_27, 2
  %EIP_24 = trunc i64 %RIP_28 to i32
  %IP_24 = trunc i64 %RIP_28 to i16
  %RSP_14 = add i64 %RSP_13, 8
  %ESP_12 = trunc i64 %RSP_14 to i32
  %SP_12 = trunc i64 %RSP_14 to i16
  %SPL_12 = trunc i64 %RSP_14 to i8
  %169 = sub i64 %RSP_14, 8
  %170 = inttoptr i64 %169 to i64*
  %R13_1 = load i64, i64* %170, align 1
  %R13D_1 = trunc i64 %R13_1 to i32
  %R13W_1 = trunc i64 %R13_1 to i16
  %R13B_1 = trunc i64 %R13_1 to i8
  %RIP_29 = add i64 %RIP_28, 2
  %EIP_25 = trunc i64 %RIP_29 to i32
  %IP_25 = trunc i64 %RIP_29 to i16
  %RSP_15 = add i64 %RSP_14, 8
  %ESP_13 = trunc i64 %RSP_15 to i32
  %SP_13 = trunc i64 %RSP_15 to i16
  %SPL_13 = trunc i64 %RSP_15 to i8
  %171 = sub i64 %RSP_15, 8
  %172 = inttoptr i64 %171 to i64*
  %R14_1 = load i64, i64* %172, align 1
  %R14D_1 = trunc i64 %R14_1 to i32
  %R14W_1 = trunc i64 %R14_1 to i16
  %R14B_1 = trunc i64 %R14_1 to i8
  %RIP_30 = add i64 %RIP_29, 2
  %EIP_26 = trunc i64 %RIP_30 to i32
  %IP_26 = trunc i64 %RIP_30 to i16
  %RSP_16 = add i64 %RSP_15, 8
  %ESP_14 = trunc i64 %RSP_16 to i32
  %SP_14 = trunc i64 %RSP_16 to i16
  %SPL_14 = trunc i64 %RSP_16 to i8
  %173 = sub i64 %RSP_16, 8
  %174 = inttoptr i64 %173 to i64*
  %R15_2 = load i64, i64* %174, align 1
  %R15D_0 = trunc i64 %R15_2 to i32
  %R15W_1 = trunc i64 %R15_2 to i16
  %R15B_1 = trunc i64 %R15_2 to i8
  %RIP_31 = add i64 %RIP_30, 1
  %EIP_27 = trunc i64 %RIP_31 to i32
  %IP_27 = trunc i64 %RIP_31 to i16
  %RSP_17 = add i64 %RSP_16, 8
  %175 = inttoptr i64 %RSP_16 to i64*
  %RIP_32 = load i64, i64* %175
  %ESP_15 = trunc i64 %RSP_17 to i32
  %SP_15 = trunc i64 %RSP_17 to i16
  %SPL_15 = trunc i64 %RSP_17 to i8
  %EIP_28 = trunc i64 %RIP_32 to i32
  %IP_28 = trunc i64 %RIP_32 to i16
  %ZF_01 = icmp eq i64 %RSP_10, 0
  %SF_02 = icmp slt i64 %RSP_10, 0
  %176 = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %RSP_9, i64 8)
  %OF_03 = extractvalue { i64, i1 } %176, 1
  %177 = call { i64, i1 } @llvm.uadd.with.overflow.i64(i64 %RSP_9, i64 8)
  %CF_04 = extractvalue { i64, i1 } %177, 1
  %178 = trunc i64 %RSP_10 to i8
  %179 = call i8 @llvm.ctpop.i8(i8 %178)
  %180 = trunc i8 %179 to i1
  %PF_05 = icmp eq i1 %180, false
  %CtlSysEFLAGS_1 = load i32, i32* %CtlSysEFLAGS
  %181 = zext i1 %CF_04 to i32
  %182 = shl i32 %181, 0
  %183 = or i32 %182, %CtlSysEFLAGS_1
  %184 = zext i1 %PF_05 to i32
  %185 = shl i32 %184, 2
  %186 = or i32 %185, %183
  %187 = zext i1 false to i32
  %188 = shl i32 %187, 4
  %189 = or i32 %188, %186
  %190 = zext i1 %ZF_01 to i32
  %191 = shl i32 %190, 6
  %192 = or i32 %191, %189
  %193 = zext i1 %SF_02 to i32
  %194 = shl i32 %193, 7
  %195 = or i32 %194, %192
  %196 = zext i1 %OF_03 to i32
  %197 = shl i32 %196, 11
  %EFLAGS_4 = or i32 %197, %195
  store i8 %BH_1, i8* %BH
  store i8 %BL_1, i8* %BL
  store i16 %BP_3, i16* %BP
  store i8 %BPL_3, i8* %BPL
  store i16 %BX_1, i16* %BX
  store i32 %CtlSysEFLAGS_1, i32* %CtlSysEFLAGS
  store i32 %EBP_3, i32* %EBP
  store i32 %EBX_2, i32* %EBX
  store i32 %EFLAGS_4, i32* %EFLAGS
  store i32 %EIP_28, i32* %EIP
  store i32 %ESP_15, i32* %ESP
  store i16 %IP_28, i16* %IP
  store i64 %RBP_5, i64* %RBP
  store i64 %RBX_2, i64* %RBX
  store i64 %RIP_32, i64* %RIP
  store i64 %RSP_17, i64* %RSP
  store i16 %SP_15, i16* %SP
  store i8 %SPL_15, i8* %SPL
  store i64 %R12_2, i64* %R12
  store i64 %R13_1, i64* %R13
  store i64 %R14_1, i64* %R14
  store i64 %R15_2, i64* %R15
  store i8 %R12B_1, i8* %R12B
  store i8 %R13B_1, i8* %R13B
  store i8 %R14B_1, i8* %R14B
  store i8 %R15B_1, i8* %R15B
  store i32 %R12D_1, i32* %R12D
  store i32 %R13D_1, i32* %R13D
  store i32 %R14D_1, i32* %R14D
  store i32 %R15D_0, i32* %R15D
  store i16 %R12W_1, i16* %R12W
  store i16 %R13W_1, i16* %R13W
  store i16 %R14W_1, i16* %R14W
  store i16 %R15W_1, i16* %R15W
  br label %exit_fn_4006D0
}

define void @fn_4003E0(%regset* noalias nocapture) {
entry_fn_4003E0:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  %RSP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 16
  %RSP_init = load i64, i64* %RSP_ptr
  %RSP = alloca i64
  store i64 %RSP_init, i64* %RSP
  %ESP_init = trunc i64 %RSP_init to i32
  %ESP = alloca i32
  store i32 %ESP_init, i32* %ESP
  %SP_init = trunc i64 %RSP_init to i16
  %SP = alloca i16
  store i16 %SP_init, i16* %SP
  %SPL_init = trunc i64 %RSP_init to i8
  %SPL = alloca i8
  store i8 %SPL_init, i8* %SPL
  %EFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 3
  %EFLAGS_init = load i32, i32* %EFLAGS_ptr
  %EFLAGS = alloca i32
  store i32 %EFLAGS_init, i32* %EFLAGS
  %RAX_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 8
  %RAX_init = load i64, i64* %RAX_ptr
  %RAX = alloca i64
  store i64 %RAX_init, i64* %RAX
  %EAX_init = trunc i64 %RAX_init to i32
  %EAX = alloca i32
  store i32 %EAX_init, i32* %EAX
  %AX_init = trunc i64 %RAX_init to i16
  %AX = alloca i16
  store i16 %AX_init, i16* %AX
  %AL_init = trunc i64 %RAX_init to i8
  %AL = alloca i8
  store i8 %AL_init, i8* %AL
  %1 = lshr i64 %RAX_init, 8
  %AH_init = trunc i64 %1 to i8
  %AH = alloca i8
  store i8 %AH_init, i8* %AH
  %CtlSysEFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 1
  %CtlSysEFLAGS_init = load i32, i32* %CtlSysEFLAGS_ptr
  %CtlSysEFLAGS = alloca i32
  store i32 %CtlSysEFLAGS_init, i32* %CtlSysEFLAGS
  br label %bb_4003E0

exit_fn_4003E0:                                   ; preds = %bb_4003F5
  %2 = load i32, i32* %CtlSysEFLAGS
  store i32 %2, i32* %CtlSysEFLAGS_ptr
  %3 = load i32, i32* %EFLAGS
  store i32 %3, i32* %EFLAGS_ptr
  %4 = load i64, i64* %RAX
  store i64 %4, i64* %RAX_ptr
  %5 = load i64, i64* %RIP
  store i64 %5, i64* %RIP_ptr
  %6 = load i64, i64* %RSP
  store i64 %6, i64* %RSP_ptr
  ret void

bb_4003E0:                                        ; preds = %entry_fn_4003E0
  %RIP_1 = add i64 4195296, 4
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %RSP_0 = load i64, i64* %RSP
  %RSP_1 = sub i64 %RSP_0, 8
  %ESP_0 = trunc i64 %RSP_1 to i32
  %SP_0 = trunc i64 %RSP_1 to i16
  %SPL_0 = trunc i64 %RSP_1 to i8
  %EFLAGS_0 = load i32, i32* %EFLAGS
  %RIP_2 = add i64 %RIP_1, 7
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  %7 = add i64 %RIP_2, 2100237
  %8 = inttoptr i64 %7 to i64*
  %RAX_0 = load i64, i64* %8, align 1
  %EAX_0 = trunc i64 %RAX_0 to i32
  %AX_0 = trunc i64 %RAX_0 to i16
  %AL_0 = trunc i64 %RAX_0 to i8
  %9 = lshr i64 %RAX_0, 8
  %AH_0 = trunc i64 %9 to i8
  %RIP_3 = add i64 %RIP_2, 3
  %EIP_2 = trunc i64 %RIP_3 to i32
  %IP_2 = trunc i64 %RIP_3 to i16
  %10 = and i64 %RAX_0, %RAX_0
  %CC_A_0 = icmp ugt i64 %10, 0
  %CC_AE_0 = icmp uge i64 %10, 0
  %CC_B_0 = icmp ult i64 %10, 0
  %CC_BE_0 = icmp ule i64 %10, 0
  %CC_L_0 = icmp slt i64 %10, 0
  %CC_LE_0 = icmp sle i64 %10, 0
  %CC_G_0 = icmp sgt i64 %10, 0
  %CC_GE_0 = icmp sge i64 %10, 0
  %CC_E_0 = icmp eq i64 %10, 0
  %CC_NE_0 = icmp ne i64 %10, 0
  %11 = sub i64 %10, 0
  %ZF_0 = icmp eq i64 %11, 0
  %SF_0 = icmp slt i64 %11, 0
  %12 = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 %10, i64 0)
  %OF_0 = extractvalue { i64, i1 } %12, 1
  %13 = call { i64, i1 } @llvm.usub.with.overflow.i64(i64 %10, i64 0)
  %CF_0 = extractvalue { i64, i1 } %13, 1
  %14 = trunc i64 %11 to i8
  %15 = call i8 @llvm.ctpop.i8(i8 %14)
  %16 = trunc i8 %15 to i1
  %PF_0 = icmp eq i1 %16, false
  %CtlSysEFLAGS_0 = load i32, i32* %CtlSysEFLAGS
  %17 = zext i1 %CF_0 to i32
  %18 = shl i32 %17, 0
  %19 = or i32 %18, %CtlSysEFLAGS_0
  %20 = zext i1 %PF_0 to i32
  %21 = shl i32 %20, 2
  %22 = or i32 %21, %19
  %23 = zext i1 false to i32
  %24 = shl i32 %23, 4
  %25 = or i32 %24, %22
  %26 = zext i1 %ZF_0 to i32
  %27 = shl i32 %26, 6
  %28 = or i32 %27, %25
  %29 = zext i1 %SF_0 to i32
  %30 = shl i32 %29, 7
  %31 = or i32 %30, %28
  %32 = zext i1 %OF_0 to i32
  %33 = shl i32 %32, 11
  %EFLAGS_1 = or i32 %33, %31
  %RIP_4 = add i64 %RIP_3, 2
  %EIP_3 = trunc i64 %RIP_4 to i32
  %IP_3 = trunc i64 %RIP_4 to i16
  store i8 %AH_0, i8* %AH
  store i8 %AL_0, i8* %AL
  store i16 %AX_0, i16* %AX
  store i32 %CtlSysEFLAGS_0, i32* %CtlSysEFLAGS
  store i32 %EAX_0, i32* %EAX
  store i32 %EFLAGS_1, i32* %EFLAGS
  store i32 4195317, i32* %EIP
  store i32 %ESP_0, i32* %ESP
  store i16 1013, i16* %IP
  store i64 %RAX_0, i64* %RAX
  store i64 4195317, i64* %RIP
  store i64 %RSP_1, i64* %RSP
  store i16 %SP_0, i16* %SP
  store i8 %SPL_0, i8* %SPL
  br i1 %CC_E_0, label %bb_4003F5, label %bb_4003F0

bb_4003F0:                                        ; preds = %bb_4003E0
  %RIP_7 = add i64 4195312, 5
  %EIP_5 = trunc i64 %RIP_7 to i32
  %IP_5 = trunc i64 %RIP_7 to i16
  %RSP_2 = load i64, i64* %RSP
  %RSP_3 = sub i64 %RSP_2, 8
  %34 = inttoptr i64 %RSP_3 to i64*
  store i64 4195317, i64* %34
  %ESP_1 = trunc i64 %RSP_3 to i32
  %SP_1 = trunc i64 %RSP_3 to i16
  %SPL_1 = trunc i64 %RSP_3 to i8
  store i32 %EIP_5, i32* %EIP
  store i32 %ESP_1, i32* %ESP
  store i16 %IP_5, i16* %IP
  store i64 %RIP_7, i64* %RIP
  store i64 %RSP_3, i64* %RSP
  store i16 %SP_1, i16* %SP
  store i8 %SPL_1, i8* %SPL
  %35 = load i32, i32* %CtlSysEFLAGS
  store i32 %35, i32* %CtlSysEFLAGS_ptr
  %36 = load i32, i32* %EFLAGS
  store i32 %36, i32* %EFLAGS_ptr
  %37 = load i64, i64* %RAX
  store i64 %37, i64* %RAX_ptr
  %38 = load i64, i64* %RIP
  store i64 %38, i64* %RIP_ptr
  %39 = load i64, i64* %RSP
  store i64 %39, i64* %RSP_ptr
  call void @fn_400430(%regset* %0)
  %40 = load i32, i32* %CtlSysEFLAGS_ptr
  store i32 %40, i32* %CtlSysEFLAGS
  %41 = load i32, i32* %EFLAGS_ptr
  store i32 %41, i32* %EFLAGS
  %42 = load i64, i64* %RAX_ptr
  store i64 %42, i64* %RAX
  %43 = load i64, i64* %RIP_ptr
  store i64 %43, i64* %RIP
  %44 = load i64, i64* %RSP_ptr
  store i64 %44, i64* %RSP
  br label %bb_4003F5

bb_4003F5:                                        ; preds = %bb_4003F0, %bb_4003E0
  %RIP_9 = add i64 4195317, 4
  %EIP_6 = trunc i64 %RIP_9 to i32
  %IP_6 = trunc i64 %RIP_9 to i16
  %RSP_4 = load i64, i64* %RSP
  %RSP_5 = add i64 %RSP_4, 8
  %ESP_2 = trunc i64 %RSP_5 to i32
  %SP_2 = trunc i64 %RSP_5 to i16
  %SPL_2 = trunc i64 %RSP_5 to i8
  %EFLAGS_2 = load i32, i32* %EFLAGS
  %RIP_10 = add i64 %RIP_9, 1
  %EIP_7 = trunc i64 %RIP_10 to i32
  %IP_7 = trunc i64 %RIP_10 to i16
  %RSP_6 = add i64 %RSP_5, 8
  %45 = inttoptr i64 %RSP_5 to i64*
  %RIP_11 = load i64, i64* %45
  %ESP_3 = trunc i64 %RSP_6 to i32
  %SP_3 = trunc i64 %RSP_6 to i16
  %SPL_3 = trunc i64 %RSP_6 to i8
  %EIP_8 = trunc i64 %RIP_11 to i32
  %IP_8 = trunc i64 %RIP_11 to i16
  %ZF_01 = icmp eq i64 %RSP_5, 0
  %SF_02 = icmp slt i64 %RSP_5, 0
  %46 = call { i64, i1 } @llvm.sadd.with.overflow.i64(i64 %RSP_4, i64 8)
  %OF_03 = extractvalue { i64, i1 } %46, 1
  %47 = call { i64, i1 } @llvm.uadd.with.overflow.i64(i64 %RSP_4, i64 8)
  %CF_04 = extractvalue { i64, i1 } %47, 1
  %48 = trunc i64 %RSP_5 to i8
  %49 = call i8 @llvm.ctpop.i8(i8 %48)
  %50 = trunc i8 %49 to i1
  %PF_05 = icmp eq i1 %50, false
  %CtlSysEFLAGS_1 = load i32, i32* %CtlSysEFLAGS
  %51 = zext i1 %CF_04 to i32
  %52 = shl i32 %51, 0
  %53 = or i32 %52, %CtlSysEFLAGS_1
  %54 = zext i1 %PF_05 to i32
  %55 = shl i32 %54, 2
  %56 = or i32 %55, %53
  %57 = zext i1 false to i32
  %58 = shl i32 %57, 4
  %59 = or i32 %58, %56
  %60 = zext i1 %ZF_01 to i32
  %61 = shl i32 %60, 6
  %62 = or i32 %61, %59
  %63 = zext i1 %SF_02 to i32
  %64 = shl i32 %63, 7
  %65 = or i32 %64, %62
  %66 = zext i1 %OF_03 to i32
  %67 = shl i32 %66, 11
  %EFLAGS_3 = or i32 %67, %65
  store i32 %CtlSysEFLAGS_1, i32* %CtlSysEFLAGS
  store i32 %EFLAGS_3, i32* %EFLAGS
  store i32 %EIP_8, i32* %EIP
  store i32 %ESP_3, i32* %ESP
  store i16 %IP_8, i16* %IP
  store i64 %RIP_11, i64* %RIP
  store i64 %RSP_6, i64* %RSP
  store i16 %SP_3, i16* %SP
  store i8 %SPL_3, i8* %SPL
  br label %exit_fn_4003E0
}

define void @fn_400440(%regset* noalias nocapture) {
entry_fn_400440:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  %RBP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 9
  %RBP_init = load i64, i64* %RBP_ptr
  %RBP = alloca i64
  store i64 %RBP_init, i64* %RBP
  %EBP_init = trunc i64 %RBP_init to i32
  %EBP = alloca i32
  store i32 %EBP_init, i32* %EBP
  %BP_init = trunc i64 %RBP_init to i16
  %BP = alloca i16
  store i16 %BP_init, i16* %BP
  %BPL_init = trunc i64 %RBP_init to i8
  %BPL = alloca i8
  store i8 %BPL_init, i8* %BPL
  %EFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 3
  %EFLAGS_init = load i32, i32* %EFLAGS_ptr
  %EFLAGS = alloca i32
  store i32 %EFLAGS_init, i32* %EFLAGS
  %RDX_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 13
  %RDX_init = load i64, i64* %RDX_ptr
  %RDX = alloca i64
  store i64 %RDX_init, i64* %RDX
  %R9_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 70
  %R9_init = load i64, i64* %R9_ptr
  %R9 = alloca i64
  store i64 %R9_init, i64* %R9
  %R9D_init = trunc i64 %R9_init to i32
  %R9D = alloca i32
  store i32 %R9D_init, i32* %R9D
  %R9W_init = trunc i64 %R9_init to i16
  %R9W = alloca i16
  store i16 %R9W_init, i16* %R9W
  %R9B_init = trunc i64 %R9_init to i8
  %R9B = alloca i8
  store i8 %R9B_init, i8* %R9B
  %RSP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 16
  %RSP_init = load i64, i64* %RSP_ptr
  %RSP = alloca i64
  store i64 %RSP_init, i64* %RSP
  %ESP_init = trunc i64 %RSP_init to i32
  %ESP = alloca i32
  store i32 %ESP_init, i32* %ESP
  %SP_init = trunc i64 %RSP_init to i16
  %SP = alloca i16
  store i16 %SP_init, i16* %SP
  %SPL_init = trunc i64 %RSP_init to i8
  %SPL = alloca i8
  store i8 %SPL_init, i8* %SPL
  %RSI_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 15
  %RSI_init = load i64, i64* %RSI_ptr
  %RSI = alloca i64
  store i64 %RSI_init, i64* %RSI
  %ESI_init = trunc i64 %RSI_init to i32
  %ESI = alloca i32
  store i32 %ESI_init, i32* %ESI
  %SI_init = trunc i64 %RSI_init to i16
  %SI = alloca i16
  store i16 %SI_init, i16* %SI
  %SIL_init = trunc i64 %RSI_init to i8
  %SIL = alloca i8
  store i8 %SIL_init, i8* %SIL
  %EDX_init = trunc i64 %RDX_init to i32
  %EDX = alloca i32
  store i32 %EDX_init, i32* %EDX
  %DX_init = trunc i64 %RDX_init to i16
  %DX = alloca i16
  store i16 %DX_init, i16* %DX
  %DL_init = trunc i64 %RDX_init to i8
  %DL = alloca i8
  store i8 %DL_init, i8* %DL
  %1 = lshr i64 %RDX_init, 8
  %DH_init = trunc i64 %1 to i8
  %DH = alloca i8
  store i8 %DH_init, i8* %DH
  %RAX_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 8
  %RAX_init = load i64, i64* %RAX_ptr
  %RAX = alloca i64
  store i64 %RAX_init, i64* %RAX
  %R8_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 69
  %R8_init = load i64, i64* %R8_ptr
  %R8 = alloca i64
  store i64 %R8_init, i64* %R8
  %R8D_init = trunc i64 %R8_init to i32
  %R8D = alloca i32
  store i32 %R8D_init, i32* %R8D
  %R8W_init = trunc i64 %R8_init to i16
  %R8W = alloca i16
  store i16 %R8W_init, i16* %R8W
  %R8B_init = trunc i64 %R8_init to i8
  %R8B = alloca i8
  store i8 %R8B_init, i8* %R8B
  %RCX_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 11
  %RCX_init = load i64, i64* %RCX_ptr
  %RCX = alloca i64
  store i64 %RCX_init, i64* %RCX
  %ECX_init = trunc i64 %RCX_init to i32
  %ECX = alloca i32
  store i32 %ECX_init, i32* %ECX
  %CX_init = trunc i64 %RCX_init to i16
  %CX = alloca i16
  store i16 %CX_init, i16* %CX
  %CL_init = trunc i64 %RCX_init to i8
  %CL = alloca i8
  store i8 %CL_init, i8* %CL
  %2 = lshr i64 %RCX_init, 8
  %CH_init = trunc i64 %2 to i8
  %CH = alloca i8
  store i8 %CH_init, i8* %CH
  %RDI_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 12
  %RDI_init = load i64, i64* %RDI_ptr
  %RDI = alloca i64
  store i64 %RDI_init, i64* %RDI
  %EDI_init = trunc i64 %RDI_init to i32
  %EDI = alloca i32
  store i32 %EDI_init, i32* %EDI
  %DI_init = trunc i64 %RDI_init to i16
  %DI = alloca i16
  store i16 %DI_init, i16* %DI
  %DIL_init = trunc i64 %RDI_init to i8
  %DIL = alloca i8
  store i8 %DIL_init, i8* %DIL
  %CtlSysEFLAGS_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 1
  %CtlSysEFLAGS_init = load i32, i32* %CtlSysEFLAGS_ptr
  %CtlSysEFLAGS = alloca i32
  store i32 %CtlSysEFLAGS_init, i32* %CtlSysEFLAGS
  %EAX_init = trunc i64 %RAX_init to i32
  %EAX = alloca i32
  store i32 %EAX_init, i32* %EAX
  %AX_init = trunc i64 %RAX_init to i16
  %AX = alloca i16
  store i16 %AX_init, i16* %AX
  %AL_init = trunc i64 %RAX_init to i8
  %AL = alloca i8
  store i8 %AL_init, i8* %AL
  %3 = lshr i64 %RAX_init, 8
  %AH_init = trunc i64 %3 to i8
  %AH = alloca i8
  store i8 %AH_init, i8* %AH
  br label %bb_400440

exit_fn_400440:                                   ; preds = %bb_400491, %bb_400485
  %4 = load i32, i32* %CtlSysEFLAGS
  store i32 %4, i32* %CtlSysEFLAGS_ptr
  %5 = load i32, i32* %EFLAGS
  store i32 %5, i32* %EFLAGS_ptr
  %6 = load i64, i64* %RAX
  store i64 %6, i64* %RAX_ptr
  %7 = load i64, i64* %RBP
  store i64 %7, i64* %RBP_ptr
  %8 = load i64, i64* %RCX
  store i64 %8, i64* %RCX_ptr
  %9 = load i64, i64* %RDI
  store i64 %9, i64* %RDI_ptr
  %10 = load i64, i64* %RDX
  store i64 %10, i64* %RDX_ptr
  %11 = load i64, i64* %RIP
  store i64 %11, i64* %RIP_ptr
  %12 = load i64, i64* %RSI
  store i64 %12, i64* %RSI_ptr
  %13 = load i64, i64* %RSP
  store i64 %13, i64* %RSP_ptr
  %14 = load i64, i64* %R8
  store i64 %14, i64* %R8_ptr
  %15 = load i64, i64* %R9
  store i64 %15, i64* %R9_ptr
  ret void

bb_400440:                                        ; preds = %entry_fn_400440
  %RIP_1 = add i64 4195392, 2
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %RBP_0 = load i64, i64* %RBP
  %EBP_0 = trunc i64 %RBP_0 to i32
  %EBP_1 = xor i32 %EBP_0, %EBP_0
  %RBP_1 = zext i32 %EBP_1 to i64
  %BP_0 = trunc i32 %EBP_1 to i16
  %BPL_0 = trunc i32 %EBP_1 to i8
  %EFLAGS_0 = load i32, i32* %EFLAGS
  %RIP_2 = add i64 %RIP_1, 3
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  %RDX_0 = load i64, i64* %RDX
  %R9D_0 = trunc i64 %RDX_0 to i32
  %R9W_0 = trunc i64 %RDX_0 to i16
  %R9B_0 = trunc i64 %RDX_0 to i8
  %RIP_3 = add i64 %RIP_2, 1
  %EIP_2 = trunc i64 %RIP_3 to i32
  %IP_2 = trunc i64 %RIP_3 to i16
  %RSP_0 = load i64, i64* %RSP
  %RSP_1 = add i64 %RSP_0, 8
  %ESP_0 = trunc i64 %RSP_1 to i32
  %SP_0 = trunc i64 %RSP_1 to i16
  %SPL_0 = trunc i64 %RSP_1 to i8
  %16 = sub i64 %RSP_1, 8
  %17 = inttoptr i64 %16 to i64*
  %RSI_0 = load i64, i64* %17, align 1
  %ESI_0 = trunc i64 %RSI_0 to i32
  %SI_0 = trunc i64 %RSI_0 to i16
  %SIL_0 = trunc i64 %RSI_0 to i8
  %RIP_4 = add i64 %RIP_3, 3
  %EIP_3 = trunc i64 %RIP_4 to i32
  %IP_3 = trunc i64 %RIP_4 to i16
  %EDX_0 = trunc i64 %RSP_1 to i32
  %DX_0 = trunc i64 %RSP_1 to i16
  %DL_0 = trunc i64 %RSP_1 to i8
  %18 = lshr i64 %RSP_1, 8
  %DH_0 = trunc i64 %18 to i8
  %RIP_5 = add i64 %RIP_4, 4
  %EIP_4 = trunc i64 %RIP_5 to i32
  %IP_4 = trunc i64 %RIP_5 to i16
  %RSP_2 = and i64 %RSP_1, -16
  %ESP_1 = trunc i64 %RSP_2 to i32
  %SP_1 = trunc i64 %RSP_2 to i16
  %SPL_1 = trunc i64 %RSP_2 to i8
  %RIP_6 = add i64 %RIP_5, 1
  %EIP_5 = trunc i64 %RIP_6 to i32
  %IP_5 = trunc i64 %RIP_6 to i16
  %RAX_0 = load i64, i64* %RAX
  %19 = sub i64 %RSP_2, 8
  %20 = inttoptr i64 %19 to i64*
  store i64 %RAX_0, i64* %20, align 1
  %RSP_3 = sub i64 %RSP_2, 8
  %ESP_2 = trunc i64 %RSP_3 to i32
  %SP_2 = trunc i64 %RSP_3 to i16
  %SPL_2 = trunc i64 %RSP_3 to i8
  %RIP_7 = add i64 %RIP_6, 1
  %EIP_6 = trunc i64 %RIP_7 to i32
  %IP_6 = trunc i64 %RIP_7 to i16
  %21 = sub i64 %RSP_3, 8
  %22 = inttoptr i64 %21 to i64*
  store i64 %RSP_3, i64* %22, align 1
  %RSP_4 = sub i64 %RSP_3, 8
  %ESP_3 = trunc i64 %RSP_4 to i32
  %SP_3 = trunc i64 %RSP_4 to i16
  %SPL_3 = trunc i64 %RSP_4 to i8
  %RIP_8 = add i64 %RIP_7, 7
  %EIP_7 = trunc i64 %RIP_8 to i32
  %IP_7 = trunc i64 %RIP_8 to i16
  %RIP_9 = add i64 %RIP_8, 7
  %EIP_8 = trunc i64 %RIP_9 to i32
  %IP_8 = trunc i64 %RIP_9 to i16
  %RIP_10 = add i64 %RIP_9, 7
  %EIP_9 = trunc i64 %RIP_10 to i32
  %IP_9 = trunc i64 %RIP_10 to i16
  %RIP_11 = add i64 %RIP_10, 5
  %EIP_10 = trunc i64 %RIP_11 to i32
  %IP_10 = trunc i64 %RIP_11 to i16
  %RSP_5 = sub i64 %RSP_4, 8
  %23 = inttoptr i64 %RSP_5 to i64*
  store i64 4195433, i64* %23
  %ESP_4 = trunc i64 %RSP_5 to i32
  %SP_4 = trunc i64 %RSP_5 to i16
  %SPL_4 = trunc i64 %RSP_5 to i8
  store i16 %BP_0, i16* %BP
  store i8 %BPL_0, i8* %BPL
  store i8 6, i8* %CH
  store i8 -48, i8* %CL
  store i16 1744, i16* %CX
  store i8 %DH_0, i8* %DH
  store i16 1360, i16* %DI
  store i8 80, i8* %DIL
  store i8 %DL_0, i8* %DL
  store i16 %DX_0, i16* %DX
  store i32 %EBP_1, i32* %EBP
  store i32 4196048, i32* %ECX
  store i32 4195664, i32* %EDI
  store i32 %EDX_0, i32* %EDX
  %ZF_0 = icmp eq i64 %RSP_2, 0
  %SF_0 = icmp slt i64 %RSP_2, 0
  %24 = trunc i64 %RSP_2 to i8
  %25 = call i8 @llvm.ctpop.i8(i8 %24)
  %26 = trunc i8 %25 to i1
  %PF_0 = icmp eq i1 %26, false
  %CtlSysEFLAGS_0 = load i32, i32* %CtlSysEFLAGS
  %27 = zext i1 false to i32
  %28 = shl i32 %27, 0
  %29 = or i32 %28, %CtlSysEFLAGS_0
  %30 = zext i1 %PF_0 to i32
  %31 = shl i32 %30, 2
  %32 = or i32 %31, %29
  %33 = zext i1 false to i32
  %34 = shl i32 %33, 4
  %35 = or i32 %34, %32
  %36 = zext i1 %ZF_0 to i32
  %37 = shl i32 %36, 6
  %38 = or i32 %37, %35
  %39 = zext i1 %SF_0 to i32
  %40 = shl i32 %39, 7
  %41 = or i32 %40, %38
  %42 = zext i1 false to i32
  %43 = shl i32 %42, 11
  %EFLAGS_1 = or i32 %43, %41
  store i32 %EFLAGS_1, i32* %EFLAGS
  store i32 %EIP_10, i32* %EIP
  store i32 %ESI_0, i32* %ESI
  store i32 %ESP_4, i32* %ESP
  store i16 %IP_10, i16* %IP
  store i64 %RAX_0, i64* %RAX
  store i64 %RBP_1, i64* %RBP
  store i64 4196048, i64* %RCX
  store i64 4195664, i64* %RDI
  store i64 %RSP_1, i64* %RDX
  store i64 %RIP_11, i64* %RIP
  store i64 %RSI_0, i64* %RSI
  store i64 %RSP_5, i64* %RSP
  store i16 %SI_0, i16* %SI
  store i8 %SIL_0, i8* %SIL
  store i16 %SP_4, i16* %SP
  store i8 %SPL_4, i8* %SPL
  store i64 4196160, i64* %R8
  store i64 %RDX_0, i64* %R9
  store i8 64, i8* %R8B
  store i8 %R9B_0, i8* %R9B
  store i32 4196160, i32* %R8D
  store i32 %R9D_0, i32* %R9D
  store i16 1856, i16* %R8W
  store i16 %R9W_0, i16* %R9W
  %44 = load i32, i32* %CtlSysEFLAGS
  store i32 %44, i32* %CtlSysEFLAGS_ptr
  %45 = load i32, i32* %EFLAGS
  store i32 %45, i32* %EFLAGS_ptr
  %46 = load i64, i64* %RAX
  store i64 %46, i64* %RAX_ptr
  %47 = load i64, i64* %RBP
  store i64 %47, i64* %RBP_ptr
  %48 = load i64, i64* %RCX
  store i64 %48, i64* %RCX_ptr
  %49 = load i64, i64* %RDI
  store i64 %49, i64* %RDI_ptr
  %50 = load i64, i64* %RDX
  store i64 %50, i64* %RDX_ptr
  %51 = load i64, i64* %RIP
  store i64 %51, i64* %RIP_ptr
  %52 = load i64, i64* %RSI
  store i64 %52, i64* %RSI_ptr
  %53 = load i64, i64* %RSP
  store i64 %53, i64* %RSP_ptr
  %54 = load i64, i64* %R8
  store i64 %54, i64* %R8_ptr
  %55 = load i64, i64* %R9
  store i64 %55, i64* %R9_ptr
  call void @fn_400420(%regset* %0)
  %56 = load i32, i32* %CtlSysEFLAGS_ptr
  store i32 %56, i32* %CtlSysEFLAGS
  %57 = load i32, i32* %EFLAGS_ptr
  store i32 %57, i32* %EFLAGS
  %58 = load i64, i64* %RAX_ptr
  store i64 %58, i64* %RAX
  %59 = load i64, i64* %RBP_ptr
  store i64 %59, i64* %RBP
  %60 = load i64, i64* %RCX_ptr
  store i64 %60, i64* %RCX
  %61 = load i64, i64* %RDI_ptr
  store i64 %61, i64* %RDI
  %62 = load i64, i64* %RDX_ptr
  store i64 %62, i64* %RDX
  %63 = load i64, i64* %RIP_ptr
  store i64 %63, i64* %RIP
  %64 = load i64, i64* %RSI_ptr
  store i64 %64, i64* %RSI
  %65 = load i64, i64* %RSP_ptr
  store i64 %65, i64* %RSP
  %66 = load i64, i64* %R8_ptr
  store i64 %66, i64* %R8
  %67 = load i64, i64* %R9_ptr
  store i64 %67, i64* %R9
  %RIP_12 = load i64, i64* %RIP
  %RIP_13 = add i64 %RIP_12, 1
  %EIP_11 = trunc i64 %RIP_13 to i32
  %IP_11 = trunc i64 %RIP_13 to i16
  call void @llvm.trap()
  %RIP_14 = add i64 %RIP_13, 6
  %EIP_12 = trunc i64 %RIP_14 to i32
  %IP_12 = trunc i64 %RIP_14 to i16
  %RIP_15 = add i64 %RIP_14, 5
  %EIP_13 = trunc i64 %RIP_15 to i32
  %IP_13 = trunc i64 %RIP_15 to i16
  %RAX_1 = load i64, i64* %RAX
  %RIP_16 = add i64 %RIP_15, 1
  %EIP_14 = trunc i64 %RIP_16 to i32
  %IP_14 = trunc i64 %RIP_16 to i16
  %RBP_2 = load i64, i64* %RBP
  %RSP_6 = load i64, i64* %RSP
  %68 = sub i64 %RSP_6, 8
  %69 = inttoptr i64 %68 to i64*
  store i64 %RBP_2, i64* %69, align 1
  %RSP_7 = sub i64 %RSP_6, 8
  %ESP_5 = trunc i64 %RSP_7 to i32
  %SP_5 = trunc i64 %RSP_7 to i16
  %SPL_5 = trunc i64 %RSP_7 to i8
  %RIP_17 = add i64 %RIP_16, 6
  %EIP_15 = trunc i64 %RIP_17 to i32
  %IP_15 = trunc i64 %RIP_17 to i16
  %RAX_3 = sub i64 6295623, 6295616
  %EAX_1 = trunc i64 %RAX_3 to i32
  %AX_1 = trunc i64 %RAX_3 to i16
  %AL_1 = trunc i64 %RAX_3 to i8
  %70 = lshr i64 %RAX_3, 8
  %AH_1 = trunc i64 %70 to i8
  %EFLAGS_2 = load i32, i32* %EFLAGS
  %RIP_18 = add i64 %RIP_17, 4
  %EIP_16 = trunc i64 %RIP_18 to i32
  %IP_16 = trunc i64 %RIP_18 to i16
  %CC_A_0 = icmp ugt i64 %RAX_3, 14
  %CC_AE_0 = icmp uge i64 %RAX_3, 14
  %CC_B_0 = icmp ult i64 %RAX_3, 14
  %CC_BE_0 = icmp ule i64 %RAX_3, 14
  %CC_L_0 = icmp slt i64 %RAX_3, 14
  %CC_LE_0 = icmp sle i64 %RAX_3, 14
  %CC_G_0 = icmp sgt i64 %RAX_3, 14
  %CC_GE_0 = icmp sge i64 %RAX_3, 14
  %CC_E_0 = icmp eq i64 %RAX_3, 14
  %CC_NE_0 = icmp ne i64 %RAX_3, 14
  %71 = sub i64 %RAX_3, 14
  %ZF_1 = icmp eq i64 %71, 0
  %SF_1 = icmp slt i64 %71, 0
  %72 = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 %RAX_3, i64 14)
  %OF_1 = extractvalue { i64, i1 } %72, 1
  %73 = call { i64, i1 } @llvm.usub.with.overflow.i64(i64 %RAX_3, i64 14)
  %CF_1 = extractvalue { i64, i1 } %73, 1
  %74 = trunc i64 %71 to i8
  %75 = call i8 @llvm.ctpop.i8(i8 %74)
  %76 = trunc i8 %75 to i1
  %PF_1 = icmp eq i1 %76, false
  %77 = zext i1 %CF_1 to i32
  %78 = shl i32 %77, 0
  %79 = or i32 %78, %CtlSysEFLAGS_0
  %80 = zext i1 %PF_1 to i32
  %81 = shl i32 %80, 2
  %82 = or i32 %81, %79
  %83 = zext i1 false to i32
  %84 = shl i32 %83, 4
  %85 = or i32 %84, %82
  %86 = zext i1 %ZF_1 to i32
  %87 = shl i32 %86, 6
  %88 = or i32 %87, %85
  %89 = zext i1 %SF_1 to i32
  %90 = shl i32 %89, 7
  %91 = or i32 %90, %88
  %92 = zext i1 %OF_1 to i32
  %93 = shl i32 %92, 11
  %EFLAGS_3 = or i32 %93, %91
  %RIP_19 = add i64 %RIP_18, 3
  %EIP_17 = trunc i64 %RIP_19 to i32
  %IP_17 = trunc i64 %RIP_19 to i16
  %EBP_2 = trunc i64 %RSP_7 to i32
  %BP_1 = trunc i64 %RSP_7 to i16
  %BPL_1 = trunc i64 %RSP_7 to i8
  %RIP_20 = add i64 %RIP_19, 2
  %EIP_18 = trunc i64 %RIP_20 to i32
  %IP_18 = trunc i64 %RIP_20 to i16
  store i8 %AH_1, i8* %AH
  store i8 %AL_1, i8* %AL
  store i16 %AX_1, i16* %AX
  store i16 %BP_1, i16* %BP
  store i8 %BPL_1, i8* %BPL
  store i32 %CtlSysEFLAGS_0, i32* %CtlSysEFLAGS
  store i32 %EAX_1, i32* %EAX
  store i32 %EBP_2, i32* %EBP
  store i32 %EFLAGS_3, i32* %EFLAGS
  store i32 4195463, i32* %EIP
  store i32 %ESP_5, i32* %ESP
  store i16 1159, i16* %IP
  store i64 %RAX_3, i64* %RAX
  store i64 %RSP_7, i64* %RBP
  store i64 4195463, i64* %RIP
  store i64 %RSP_7, i64* %RSP
  store i16 %SP_5, i16* %SP
  store i8 %SPL_5, i8* %SPL
  br i1 %CC_A_0, label %bb_400487, label %bb_400485

bb_400485:                                        ; preds = %bb_400487, %bb_400440
  %RIP_23 = add i64 4195461, 1
  %EIP_20 = trunc i64 %RIP_23 to i32
  %IP_20 = trunc i64 %RIP_23 to i16
  %RSP_8 = load i64, i64* %RSP
  %RSP_9 = add i64 %RSP_8, 8
  %ESP_6 = trunc i64 %RSP_9 to i32
  %SP_6 = trunc i64 %RSP_9 to i16
  %SPL_6 = trunc i64 %RSP_9 to i8
  %94 = sub i64 %RSP_9, 8
  %95 = inttoptr i64 %94 to i64*
  %RBP_3 = load i64, i64* %95, align 1
  %EBP_3 = trunc i64 %RBP_3 to i32
  %BP_2 = trunc i64 %RBP_3 to i16
  %BPL_2 = trunc i64 %RBP_3 to i8
  %RIP_24 = add i64 %RIP_23, 1
  %EIP_21 = trunc i64 %RIP_24 to i32
  %IP_21 = trunc i64 %RIP_24 to i16
  %RSP_10 = add i64 %RSP_9, 8
  %96 = inttoptr i64 %RSP_9 to i64*
  %RIP_25 = load i64, i64* %96
  %ESP_7 = trunc i64 %RSP_10 to i32
  %SP_7 = trunc i64 %RSP_10 to i16
  %SPL_7 = trunc i64 %RSP_10 to i8
  %EIP_22 = trunc i64 %RIP_25 to i32
  %IP_22 = trunc i64 %RIP_25 to i16
  store i16 %BP_2, i16* %BP
  store i8 %BPL_2, i8* %BPL
  store i32 %EBP_3, i32* %EBP
  store i32 %EIP_22, i32* %EIP
  store i32 %ESP_7, i32* %ESP
  store i16 %IP_22, i16* %IP
  store i64 %RBP_3, i64* %RBP
  store i64 %RIP_25, i64* %RIP
  store i64 %RSP_10, i64* %RSP
  store i16 %SP_7, i16* %SP
  store i8 %SPL_7, i8* %SPL
  br label %exit_fn_400440

bb_400487:                                        ; preds = %bb_400440
  %RIP_27 = add i64 4195463, 5
  %EIP_23 = trunc i64 %RIP_27 to i32
  %IP_23 = trunc i64 %RIP_27 to i16
  %RAX_4 = load i64, i64* %RAX
  %RIP_28 = add i64 %RIP_27, 3
  %EIP_24 = trunc i64 %RIP_28 to i32
  %IP_24 = trunc i64 %RIP_28 to i16
  %97 = and i64 0, 0
  %CC_A_01 = icmp ugt i64 %97, 0
  %CC_AE_02 = icmp uge i64 %97, 0
  %CC_B_03 = icmp ult i64 %97, 0
  %CC_BE_04 = icmp ule i64 %97, 0
  %CC_L_05 = icmp slt i64 %97, 0
  %CC_LE_06 = icmp sle i64 %97, 0
  %CC_G_07 = icmp sgt i64 %97, 0
  %CC_GE_08 = icmp sge i64 %97, 0
  %CC_E_09 = icmp eq i64 %97, 0
  %CC_NE_010 = icmp ne i64 %97, 0
  %98 = sub i64 %97, 0
  %ZF_011 = icmp eq i64 %98, 0
  %SF_012 = icmp slt i64 %98, 0
  %99 = call { i64, i1 } @llvm.ssub.with.overflow.i64(i64 %97, i64 0)
  %OF_0 = extractvalue { i64, i1 } %99, 1
  %100 = call { i64, i1 } @llvm.usub.with.overflow.i64(i64 %97, i64 0)
  %CF_0 = extractvalue { i64, i1 } %100, 1
  %101 = trunc i64 %98 to i8
  %102 = call i8 @llvm.ctpop.i8(i8 %101)
  %103 = trunc i8 %102 to i1
  %PF_013 = icmp eq i1 %103, false
  %CtlSysEFLAGS_1 = load i32, i32* %CtlSysEFLAGS
  %104 = zext i1 %CF_0 to i32
  %105 = shl i32 %104, 0
  %106 = or i32 %105, %CtlSysEFLAGS_1
  %107 = zext i1 %PF_013 to i32
  %108 = shl i32 %107, 2
  %109 = or i32 %108, %106
  %110 = zext i1 false to i32
  %111 = shl i32 %110, 4
  %112 = or i32 %111, %109
  %113 = zext i1 %ZF_011 to i32
  %114 = shl i32 %113, 6
  %115 = or i32 %114, %112
  %116 = zext i1 %SF_012 to i32
  %117 = shl i32 %116, 7
  %118 = or i32 %117, %115
  %119 = zext i1 %OF_0 to i32
  %120 = shl i32 %119, 11
  %EFLAGS_4 = or i32 %120, %118
  %RIP_29 = add i64 %RIP_28, 2
  %EIP_25 = trunc i64 %RIP_29 to i32
  %IP_25 = trunc i64 %RIP_29 to i16
  store i8 0, i8* %AH
  store i8 0, i8* %AL
  store i16 0, i16* %AX
  store i32 %CtlSysEFLAGS_1, i32* %CtlSysEFLAGS
  store i32 0, i32* %EAX
  store i32 %EFLAGS_4, i32* %EFLAGS
  store i32 4195461, i32* %EIP
  store i16 1157, i16* %IP
  store i64 0, i64* %RAX
  store i64 4195461, i64* %RIP
  br i1 %CC_E_09, label %bb_400485, label %bb_400491

bb_400491:                                        ; preds = %bb_400487
  %RIP_32 = add i64 4195473, 1
  %EIP_27 = trunc i64 %RIP_32 to i32
  %IP_27 = trunc i64 %RIP_32 to i16
  %RSP_11 = load i64, i64* %RSP
  %RSP_12 = add i64 %RSP_11, 8
  %ESP_8 = trunc i64 %RSP_12 to i32
  %SP_8 = trunc i64 %RSP_12 to i16
  %SPL_8 = trunc i64 %RSP_12 to i8
  %121 = sub i64 %RSP_12, 8
  %122 = inttoptr i64 %121 to i64*
  %RBP_4 = load i64, i64* %122, align 1
  %EBP_4 = trunc i64 %RBP_4 to i32
  %BP_3 = trunc i64 %RBP_4 to i16
  %BPL_3 = trunc i64 %RBP_4 to i8
  %RIP_33 = add i64 %RIP_32, 5
  %EIP_28 = trunc i64 %RIP_33 to i32
  %IP_28 = trunc i64 %RIP_33 to i16
  %RDI_1 = load i64, i64* %RDI
  %RIP_34 = add i64 %RIP_33, 2
  %EIP_29 = trunc i64 %RIP_34 to i32
  %IP_29 = trunc i64 %RIP_34 to i16
  %RAX_6 = load i64, i64* %RAX
  %EIP_30 = trunc i64 %RAX_6 to i32
  %IP_30 = trunc i64 %RAX_6 to i16
  %123 = inttoptr i64 %RAX_6 to i8*
  %124 = call i8* @llvm.dc.translate.at(i8* %123)
  %125 = bitcast i8* %124 to void (%regset*)*
  store i16 %BP_3, i16* %BP
  store i8 %BPL_3, i8* %BPL
  store i16 4160, i16* %DI
  store i8 64, i8* %DIL
  store i32 %EBP_4, i32* %EBP
  store i32 6295616, i32* %EDI
  store i32 %EIP_30, i32* %EIP
  store i32 %ESP_8, i32* %ESP
  store i16 %IP_30, i16* %IP
  store i64 %RAX_6, i64* %RAX
  store i64 %RBP_4, i64* %RBP
  store i64 6295616, i64* %RDI
  store i64 %RAX_6, i64* %RIP
  store i64 %RSP_12, i64* %RSP
  store i16 %SP_8, i16* %SP
  store i8 %SPL_8, i8* %SPL
  %126 = load i32, i32* %CtlSysEFLAGS
  store i32 %126, i32* %CtlSysEFLAGS_ptr
  %127 = load i32, i32* %EFLAGS
  store i32 %127, i32* %EFLAGS_ptr
  %128 = load i64, i64* %RAX
  store i64 %128, i64* %RAX_ptr
  %129 = load i64, i64* %RBP
  store i64 %129, i64* %RBP_ptr
  %130 = load i64, i64* %RCX
  store i64 %130, i64* %RCX_ptr
  %131 = load i64, i64* %RDI
  store i64 %131, i64* %RDI_ptr
  %132 = load i64, i64* %RDX
  store i64 %132, i64* %RDX_ptr
  %133 = load i64, i64* %RIP
  store i64 %133, i64* %RIP_ptr
  %134 = load i64, i64* %RSI
  store i64 %134, i64* %RSI_ptr
  %135 = load i64, i64* %RSP
  store i64 %135, i64* %RSP_ptr
  %136 = load i64, i64* %R8
  store i64 %136, i64* %R8_ptr
  %137 = load i64, i64* %R9
  store i64 %137, i64* %R9_ptr
  call void %125(%regset* %0)
  %138 = load i32, i32* %CtlSysEFLAGS_ptr
  store i32 %138, i32* %CtlSysEFLAGS
  %139 = load i32, i32* %EFLAGS_ptr
  store i32 %139, i32* %EFLAGS
  %140 = load i64, i64* %RAX_ptr
  store i64 %140, i64* %RAX
  %141 = load i64, i64* %RBP_ptr
  store i64 %141, i64* %RBP
  %142 = load i64, i64* %RCX_ptr
  store i64 %142, i64* %RCX
  %143 = load i64, i64* %RDI_ptr
  store i64 %143, i64* %RDI
  %144 = load i64, i64* %RDX_ptr
  store i64 %144, i64* %RDX
  %145 = load i64, i64* %RIP_ptr
  store i64 %145, i64* %RIP
  %146 = load i64, i64* %RSI_ptr
  store i64 %146, i64* %RSI
  %147 = load i64, i64* %RSP_ptr
  store i64 %147, i64* %RSP
  %148 = load i64, i64* %R8_ptr
  store i64 %148, i64* %R8
  %149 = load i64, i64* %R9_ptr
  store i64 %149, i64* %R9
  br label %exit_fn_400440
}

define void @fn_400420(%regset* noalias nocapture) {
entry_fn_400420:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  br label %bb_400420

exit_fn_400420:                                   ; preds = %bb_400420
  %1 = load i64, i64* %RIP
  store i64 %1, i64* %RIP_ptr
  ret void

bb_400420:                                        ; preds = %entry_fn_400420
  %RIP_1 = add i64 4195360, 6
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %2 = add i64 %RIP_1, 2100218
  %3 = inttoptr i64 %2 to i64*
  %RIP_2 = load i64, i64* %3, align 1
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  %4 = inttoptr i64 %RIP_2 to i8*
  %5 = call i8* @llvm.dc.translate.at(i8* %4)
  %6 = bitcast i8* %5 to void (%regset*)*
  store i32 %EIP_1, i32* %EIP
  store i16 %IP_1, i16* %IP
  store i64 %RIP_2, i64* %RIP
  %7 = load i64, i64* %RIP
  store i64 %7, i64* %RIP_ptr
  call void %6(%regset* %0)
  %8 = load i64, i64* %RIP_ptr
  store i64 %8, i64* %RIP
  br label %exit_fn_400420
}

define void @fn_400430(%regset* noalias nocapture) {
entry_fn_400430:
  %RIP_ptr = getelementptr inbounds %regset, %regset* %0, i32 0, i32 14
  %RIP_init = load i64, i64* %RIP_ptr
  %RIP = alloca i64
  store i64 %RIP_init, i64* %RIP
  %EIP_init = trunc i64 %RIP_init to i32
  %EIP = alloca i32
  store i32 %EIP_init, i32* %EIP
  %IP_init = trunc i64 %RIP_init to i16
  %IP = alloca i16
  store i16 %IP_init, i16* %IP
  br label %bb_400430

exit_fn_400430:                                   ; preds = %bb_400430
  %1 = load i64, i64* %RIP
  store i64 %1, i64* %RIP_ptr
  ret void

bb_400430:                                        ; preds = %entry_fn_400430
  %RIP_1 = add i64 4195376, 6
  %EIP_0 = trunc i64 %RIP_1 to i32
  %IP_0 = trunc i64 %RIP_1 to i16
  %2 = add i64 %RIP_1, 2100210
  %3 = inttoptr i64 %2 to i64*
  %RIP_2 = load i64, i64* %3, align 1
  %EIP_1 = trunc i64 %RIP_2 to i32
  %IP_1 = trunc i64 %RIP_2 to i16
  %4 = inttoptr i64 %RIP_2 to i8*
  %5 = call i8* @llvm.dc.translate.at(i8* %4)
  %6 = bitcast i8* %5 to void (%regset*)*
  store i32 %EIP_1, i32* %EIP
  store i16 %IP_1, i16* %IP
  store i64 %RIP_2, i64* %RIP
  %7 = load i64, i64* %RIP
  store i64 %7, i64* %RIP_ptr
  call void %6(%regset* %0)
  %8 = load i64, i64* %RIP_ptr
  store i64 %8, i64* %RIP
  br label %exit_fn_400430
}

attributes #0 = { noreturn nounwind }
attributes #1 = { nounwind readnone speculatable }
attributes #2 = { nounwind }
